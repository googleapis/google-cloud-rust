// Copyright 2025 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     https://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//
// Code generated by sidekick. DO NOT EDIT.

#![allow(rustdoc::redundant_explicit_links)]
#![allow(rustdoc::broken_intra_doc_links)]
#![no_implicit_prelude]
extern crate std;
extern crate async_trait;
extern crate bytes;
extern crate gax;
extern crate gaxi;
extern crate lazy_static;
extern crate longrunning;
extern crate lro;
extern crate reqwest;
extern crate serde;
extern crate serde_json;
extern crate serde_with;
extern crate tracing;
extern crate wkt;

mod debug;
mod deserialize;
mod serialize;

/// The top-level message sent by the client for the `ListVoices` method.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct ListVoicesRequest {

    /// Optional. Recommended.
    /// [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.
    /// If not specified, the API will return all supported voices.
    /// If specified, the ListVoices call will only return voices that can be used
    /// to synthesize this language_code. For example, if you specify `"en-NZ"`,
    /// all `"en-NZ"` voices will be returned. If you specify `"no"`, both
    /// `"no-\*"` (Norwegian) and `"nb-\*"` (Norwegian Bokmal) voices will be
    /// returned.
    pub language_code: std::string::String,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl ListVoicesRequest {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [language_code][crate::model::ListVoicesRequest::language_code].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::ListVoicesRequest;
    /// let x = ListVoicesRequest::new().set_language_code("example");
    /// ```
    pub fn set_language_code<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.language_code = v.into();
        self
    }
}

impl wkt::message::Message for ListVoicesRequest {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.ListVoicesRequest"
    }
}

/// The message returned to the client by the `ListVoices` method.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct ListVoicesResponse {

    /// The list of voices.
    pub voices: std::vec::Vec<crate::model::Voice>,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl ListVoicesResponse {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [voices][crate::model::ListVoicesResponse::voices].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::ListVoicesResponse;
    /// use google_cloud_texttospeech_v1::model::Voice;
    /// let x = ListVoicesResponse::new()
    ///     .set_voices([
    ///         Voice::default()/* use setters */,
    ///         Voice::default()/* use (different) setters */,
    ///     ]);
    /// ```
    pub fn set_voices<T, V>(mut self, v: T) -> Self
    where
        T: std::iter::IntoIterator<Item = V>,
        V: std::convert::Into<crate::model::Voice>
    {
        use std::iter::Iterator;
        self.voices = v.into_iter().map(|i| i.into()).collect();
        self
    }
}

impl wkt::message::Message for ListVoicesResponse {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.ListVoicesResponse"
    }
}

/// Description of a voice supported by the TTS service.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct Voice {

    /// The languages that this voice supports, expressed as
    /// [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tags (e.g.
    /// "en-US", "es-419", "cmn-tw").
    pub language_codes: std::vec::Vec<std::string::String>,

    /// The name of this voice.  Each distinct voice has a unique name.
    pub name: std::string::String,

    /// The gender of this voice.
    pub ssml_gender: crate::model::SsmlVoiceGender,

    /// The natural sample rate (in hertz) for this voice.
    pub natural_sample_rate_hertz: i32,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl Voice {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [language_codes][crate::model::Voice::language_codes].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::Voice;
    /// let x = Voice::new().set_language_codes(["a", "b", "c"]);
    /// ```
    pub fn set_language_codes<T, V>(mut self, v: T) -> Self
    where
        T: std::iter::IntoIterator<Item = V>,
        V: std::convert::Into<std::string::String>
    {
        use std::iter::Iterator;
        self.language_codes = v.into_iter().map(|i| i.into()).collect();
        self
    }

    /// Sets the value of [name][crate::model::Voice::name].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::Voice;
    /// let x = Voice::new().set_name("example");
    /// ```
    pub fn set_name<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.name = v.into();
        self
    }

    /// Sets the value of [ssml_gender][crate::model::Voice::ssml_gender].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::Voice;
    /// use google_cloud_texttospeech_v1::model::SsmlVoiceGender;
    /// let x0 = Voice::new().set_ssml_gender(SsmlVoiceGender::Male);
    /// let x1 = Voice::new().set_ssml_gender(SsmlVoiceGender::Female);
    /// let x2 = Voice::new().set_ssml_gender(SsmlVoiceGender::Neutral);
    /// ```
    pub fn set_ssml_gender<T: std::convert::Into<crate::model::SsmlVoiceGender>>(mut self, v: T) -> Self {
        self.ssml_gender = v.into();
        self
    }

    /// Sets the value of [natural_sample_rate_hertz][crate::model::Voice::natural_sample_rate_hertz].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::Voice;
    /// let x = Voice::new().set_natural_sample_rate_hertz(42);
    /// ```
    pub fn set_natural_sample_rate_hertz<T: std::convert::Into<i32>>(mut self, v: T) -> Self {
        self.natural_sample_rate_hertz = v.into();
        self
    }
}

impl wkt::message::Message for Voice {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.Voice"
    }
}

/// Used for advanced voice options.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct AdvancedVoiceOptions {

    /// Only for Journey voices. If false, the synthesis is context aware
    /// and has a higher latency.
    pub low_latency_journey_synthesis: std::option::Option<bool>,

    /// Optional. Input only. If true, relaxes safety filters for Gemini TTS. Only
    /// supported for accounts linked to Invoiced (Offline) Cloud billing accounts.
    /// Otherwise, will return result
    /// [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT].
    pub relax_safety_filters: bool,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl AdvancedVoiceOptions {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [low_latency_journey_synthesis][crate::model::AdvancedVoiceOptions::low_latency_journey_synthesis].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::AdvancedVoiceOptions;
    /// let x = AdvancedVoiceOptions::new().set_low_latency_journey_synthesis(true);
    /// ```
    pub fn set_low_latency_journey_synthesis<T>(mut self, v: T) -> Self
    where T: std::convert::Into<bool>
    {
        self.low_latency_journey_synthesis = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [low_latency_journey_synthesis][crate::model::AdvancedVoiceOptions::low_latency_journey_synthesis].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::AdvancedVoiceOptions;
    /// let x = AdvancedVoiceOptions::new().set_or_clear_low_latency_journey_synthesis(Some(false));
    /// let x = AdvancedVoiceOptions::new().set_or_clear_low_latency_journey_synthesis(None::<bool>);
    /// ```
    pub fn set_or_clear_low_latency_journey_synthesis<T>(mut self, v: std::option::Option<T>) -> Self
    where T: std::convert::Into<bool>
    {
        self.low_latency_journey_synthesis = v.map(|x| x.into());
        self
    }

    /// Sets the value of [relax_safety_filters][crate::model::AdvancedVoiceOptions::relax_safety_filters].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::AdvancedVoiceOptions;
    /// let x = AdvancedVoiceOptions::new().set_relax_safety_filters(true);
    /// ```
    pub fn set_relax_safety_filters<T: std::convert::Into<bool>>(mut self, v: T) -> Self {
        self.relax_safety_filters = v.into();
        self
    }
}

impl wkt::message::Message for AdvancedVoiceOptions {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.AdvancedVoiceOptions"
    }
}

/// The top-level message sent by the client for the `SynthesizeSpeech` method.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct SynthesizeSpeechRequest {

    /// Required. The Synthesizer requires either plain text or SSML as input.
    pub input: std::option::Option<crate::model::SynthesisInput>,

    /// Required. The desired voice of the synthesized audio.
    pub voice: std::option::Option<crate::model::VoiceSelectionParams>,

    /// Required. The configuration of the synthesized audio.
    pub audio_config: std::option::Option<crate::model::AudioConfig>,

    /// Advanced voice options.
    pub advanced_voice_options: std::option::Option<crate::model::AdvancedVoiceOptions>,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl SynthesizeSpeechRequest {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [input][crate::model::SynthesizeSpeechRequest::input].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::SynthesizeSpeechRequest;
    /// use google_cloud_texttospeech_v1::model::SynthesisInput;
    /// let x = SynthesizeSpeechRequest::new().set_input(SynthesisInput::default()/* use setters */);
    /// ```
    pub fn set_input<T>(mut self, v: T) -> Self
    where T: std::convert::Into<crate::model::SynthesisInput>
    {
        self.input = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [input][crate::model::SynthesizeSpeechRequest::input].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::SynthesizeSpeechRequest;
    /// use google_cloud_texttospeech_v1::model::SynthesisInput;
    /// let x = SynthesizeSpeechRequest::new().set_or_clear_input(Some(SynthesisInput::default()/* use setters */));
    /// let x = SynthesizeSpeechRequest::new().set_or_clear_input(None::<SynthesisInput>);
    /// ```
    pub fn set_or_clear_input<T>(mut self, v: std::option::Option<T>) -> Self
    where T: std::convert::Into<crate::model::SynthesisInput>
    {
        self.input = v.map(|x| x.into());
        self
    }

    /// Sets the value of [voice][crate::model::SynthesizeSpeechRequest::voice].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::SynthesizeSpeechRequest;
    /// use google_cloud_texttospeech_v1::model::VoiceSelectionParams;
    /// let x = SynthesizeSpeechRequest::new().set_voice(VoiceSelectionParams::default()/* use setters */);
    /// ```
    pub fn set_voice<T>(mut self, v: T) -> Self
    where T: std::convert::Into<crate::model::VoiceSelectionParams>
    {
        self.voice = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [voice][crate::model::SynthesizeSpeechRequest::voice].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::SynthesizeSpeechRequest;
    /// use google_cloud_texttospeech_v1::model::VoiceSelectionParams;
    /// let x = SynthesizeSpeechRequest::new().set_or_clear_voice(Some(VoiceSelectionParams::default()/* use setters */));
    /// let x = SynthesizeSpeechRequest::new().set_or_clear_voice(None::<VoiceSelectionParams>);
    /// ```
    pub fn set_or_clear_voice<T>(mut self, v: std::option::Option<T>) -> Self
    where T: std::convert::Into<crate::model::VoiceSelectionParams>
    {
        self.voice = v.map(|x| x.into());
        self
    }

    /// Sets the value of [audio_config][crate::model::SynthesizeSpeechRequest::audio_config].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::SynthesizeSpeechRequest;
    /// use google_cloud_texttospeech_v1::model::AudioConfig;
    /// let x = SynthesizeSpeechRequest::new().set_audio_config(AudioConfig::default()/* use setters */);
    /// ```
    pub fn set_audio_config<T>(mut self, v: T) -> Self
    where T: std::convert::Into<crate::model::AudioConfig>
    {
        self.audio_config = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [audio_config][crate::model::SynthesizeSpeechRequest::audio_config].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::SynthesizeSpeechRequest;
    /// use google_cloud_texttospeech_v1::model::AudioConfig;
    /// let x = SynthesizeSpeechRequest::new().set_or_clear_audio_config(Some(AudioConfig::default()/* use setters */));
    /// let x = SynthesizeSpeechRequest::new().set_or_clear_audio_config(None::<AudioConfig>);
    /// ```
    pub fn set_or_clear_audio_config<T>(mut self, v: std::option::Option<T>) -> Self
    where T: std::convert::Into<crate::model::AudioConfig>
    {
        self.audio_config = v.map(|x| x.into());
        self
    }

    /// Sets the value of [advanced_voice_options][crate::model::SynthesizeSpeechRequest::advanced_voice_options].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::SynthesizeSpeechRequest;
    /// use google_cloud_texttospeech_v1::model::AdvancedVoiceOptions;
    /// let x = SynthesizeSpeechRequest::new().set_advanced_voice_options(AdvancedVoiceOptions::default()/* use setters */);
    /// ```
    pub fn set_advanced_voice_options<T>(mut self, v: T) -> Self
    where T: std::convert::Into<crate::model::AdvancedVoiceOptions>
    {
        self.advanced_voice_options = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [advanced_voice_options][crate::model::SynthesizeSpeechRequest::advanced_voice_options].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::SynthesizeSpeechRequest;
    /// use google_cloud_texttospeech_v1::model::AdvancedVoiceOptions;
    /// let x = SynthesizeSpeechRequest::new().set_or_clear_advanced_voice_options(Some(AdvancedVoiceOptions::default()/* use setters */));
    /// let x = SynthesizeSpeechRequest::new().set_or_clear_advanced_voice_options(None::<AdvancedVoiceOptions>);
    /// ```
    pub fn set_or_clear_advanced_voice_options<T>(mut self, v: std::option::Option<T>) -> Self
    where T: std::convert::Into<crate::model::AdvancedVoiceOptions>
    {
        self.advanced_voice_options = v.map(|x| x.into());
        self
    }
}

impl wkt::message::Message for SynthesizeSpeechRequest {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.SynthesizeSpeechRequest"
    }
}

/// Pronunciation customization for a phrase.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct CustomPronunciationParams {

    /// The phrase to which the customization is applied.
    /// The phrase can be multiple words, such as proper nouns, but shouldn't span
    /// the length of the sentence.
    pub phrase: std::option::Option<std::string::String>,

    /// The phonetic encoding of the phrase.
    pub phonetic_encoding: std::option::Option<crate::model::custom_pronunciation_params::PhoneticEncoding>,

    /// The pronunciation of the phrase. This must be in the phonetic encoding
    /// specified above.
    pub pronunciation: std::option::Option<std::string::String>,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl CustomPronunciationParams {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [phrase][crate::model::CustomPronunciationParams::phrase].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::CustomPronunciationParams;
    /// let x = CustomPronunciationParams::new().set_phrase("example");
    /// ```
    pub fn set_phrase<T>(mut self, v: T) -> Self
    where T: std::convert::Into<std::string::String>
    {
        self.phrase = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [phrase][crate::model::CustomPronunciationParams::phrase].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::CustomPronunciationParams;
    /// let x = CustomPronunciationParams::new().set_or_clear_phrase(Some("example"));
    /// let x = CustomPronunciationParams::new().set_or_clear_phrase(None::<String>);
    /// ```
    pub fn set_or_clear_phrase<T>(mut self, v: std::option::Option<T>) -> Self
    where T: std::convert::Into<std::string::String>
    {
        self.phrase = v.map(|x| x.into());
        self
    }

    /// Sets the value of [phonetic_encoding][crate::model::CustomPronunciationParams::phonetic_encoding].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::CustomPronunciationParams;
    /// use google_cloud_texttospeech_v1::model::custom_pronunciation_params::PhoneticEncoding;
    /// let x0 = CustomPronunciationParams::new().set_phonetic_encoding(PhoneticEncoding::Ipa);
    /// let x1 = CustomPronunciationParams::new().set_phonetic_encoding(PhoneticEncoding::XSampa);
    /// let x2 = CustomPronunciationParams::new().set_phonetic_encoding(PhoneticEncoding::JapaneseYomigana);
    /// ```
    pub fn set_phonetic_encoding<T>(mut self, v: T) -> Self
    where T: std::convert::Into<crate::model::custom_pronunciation_params::PhoneticEncoding>
    {
        self.phonetic_encoding = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [phonetic_encoding][crate::model::CustomPronunciationParams::phonetic_encoding].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::CustomPronunciationParams;
    /// use google_cloud_texttospeech_v1::model::custom_pronunciation_params::PhoneticEncoding;
    /// let x0 = CustomPronunciationParams::new().set_or_clear_phonetic_encoding(Some(PhoneticEncoding::Ipa));
    /// let x1 = CustomPronunciationParams::new().set_or_clear_phonetic_encoding(Some(PhoneticEncoding::XSampa));
    /// let x2 = CustomPronunciationParams::new().set_or_clear_phonetic_encoding(Some(PhoneticEncoding::JapaneseYomigana));
    /// let x_none = CustomPronunciationParams::new().set_or_clear_phonetic_encoding(None::<PhoneticEncoding>);
    /// ```
    pub fn set_or_clear_phonetic_encoding<T>(mut self, v: std::option::Option<T>) -> Self
    where T: std::convert::Into<crate::model::custom_pronunciation_params::PhoneticEncoding>
    {
        self.phonetic_encoding = v.map(|x| x.into());
        self
    }

    /// Sets the value of [pronunciation][crate::model::CustomPronunciationParams::pronunciation].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::CustomPronunciationParams;
    /// let x = CustomPronunciationParams::new().set_pronunciation("example");
    /// ```
    pub fn set_pronunciation<T>(mut self, v: T) -> Self
    where T: std::convert::Into<std::string::String>
    {
        self.pronunciation = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [pronunciation][crate::model::CustomPronunciationParams::pronunciation].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::CustomPronunciationParams;
    /// let x = CustomPronunciationParams::new().set_or_clear_pronunciation(Some("example"));
    /// let x = CustomPronunciationParams::new().set_or_clear_pronunciation(None::<String>);
    /// ```
    pub fn set_or_clear_pronunciation<T>(mut self, v: std::option::Option<T>) -> Self
    where T: std::convert::Into<std::string::String>
    {
        self.pronunciation = v.map(|x| x.into());
        self
    }
}

impl wkt::message::Message for CustomPronunciationParams {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.CustomPronunciationParams"
    }
}

/// Defines additional types related to [CustomPronunciationParams].
pub mod custom_pronunciation_params {
    #[allow(unused_imports)]
    use super::*;


    /// The phonetic encoding of the phrase.
    ///
    /// # Working with unknown values
    ///
    /// This enum is defined as `#[non_exhaustive]` because Google Cloud may add
    /// additional enum variants at any time. Adding new variants is not considered
    /// a breaking change. Applications should write their code in anticipation of:
    ///
    /// - New values appearing in future releases of the client library, **and**
    /// - New values received dynamically, without application changes.
    ///
    /// Please consult the [Working with enums] section in the user guide for some
    /// guidelines.
    ///
    /// [Working with enums]: https://google-cloud-rust.github.io/working_with_enums.html
    #[derive(Clone, Debug, PartialEq)]
    #[non_exhaustive]
    pub enum PhoneticEncoding {
        /// Not specified.
        Unspecified,
        /// IPA, such as apple -> ˈæpəl.
        /// <https://en.wikipedia.org/wiki/International_Phonetic_Alphabet>
        Ipa,
        /// X-SAMPA, such as apple -> "{p@l".
        /// <https://en.wikipedia.org/wiki/X-SAMPA>
        XSampa,
        /// For reading-to-pron conversion to work well, the `pronunciation` field
        /// should only contain Kanji, Hiragana, and Katakana.
        ///
        /// The pronunciation can also contain pitch accents.
        /// The start of a pitch phrase is specified with `^` and the down-pitch
        /// position is specified with `!`, for example:
        ///
        /// ```norust
        /// phrase:端  pronunciation:^はし
        /// phrase:箸  pronunciation:^は!し
        /// phrase:橋  pronunciation:^はし!
        /// ```
        ///
        /// We currently only support the Tokyo dialect, which allows at most one
        /// down-pitch per phrase (i.e. at most one `!` between `^`).
        JapaneseYomigana,
        /// Used to specify pronunciations for Mandarin words. See
        /// <https://en.wikipedia.org/wiki/Pinyin>.
        ///
        /// For example: 朝阳, the pronunciation is "chao2 yang2". The number
        /// represents the tone, and there is a space between syllables. Neutral
        /// tones are represented by 5, for example 孩子 "hai2 zi5".
        Pinyin,
        /// If set, the enum was initialized with an unknown value.
        ///
        /// Applications can examine the value using [PhoneticEncoding::value] or
        /// [PhoneticEncoding::name].
        UnknownValue(phonetic_encoding::UnknownValue),
    }

    #[doc(hidden)]
    pub mod phonetic_encoding {
        #[allow(unused_imports)]
        use super::*;
        #[derive(Clone, Debug, PartialEq)]
        pub struct UnknownValue(pub(crate) wkt::internal::UnknownEnumValue);
    }

    impl PhoneticEncoding {
        /// Gets the enum value.
        ///
        /// Returns `None` if the enum contains an unknown value deserialized from
        /// the string representation of enums.
        pub fn value(&self) -> std::option::Option<i32> {
            match self {
                Self::Unspecified => std::option::Option::Some(0),
                Self::Ipa => std::option::Option::Some(1),
                Self::XSampa => std::option::Option::Some(2),
                Self::JapaneseYomigana => std::option::Option::Some(3),
                Self::Pinyin => std::option::Option::Some(4),
                Self::UnknownValue(u) => u.0.value(),
            }
        }

        /// Gets the enum value as a string.
        ///
        /// Returns `None` if the enum contains an unknown value deserialized from
        /// the integer representation of enums.
        pub fn name(&self) -> std::option::Option<&str> {
            match self {
                Self::Unspecified => std::option::Option::Some("PHONETIC_ENCODING_UNSPECIFIED"),
                Self::Ipa => std::option::Option::Some("PHONETIC_ENCODING_IPA"),
                Self::XSampa => std::option::Option::Some("PHONETIC_ENCODING_X_SAMPA"),
                Self::JapaneseYomigana => std::option::Option::Some("PHONETIC_ENCODING_JAPANESE_YOMIGANA"),
                Self::Pinyin => std::option::Option::Some("PHONETIC_ENCODING_PINYIN"),
                Self::UnknownValue(u) => u.0.name(),
            }
        }
    }

    impl std::default::Default for PhoneticEncoding {
        fn default() -> Self {
            use std::convert::From;
            Self::from(0)
        }
    }

    impl std::fmt::Display for PhoneticEncoding {
        fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::result::Result<(), std::fmt::Error> {
            wkt::internal::display_enum(f, self.name(), self.value())
        }
    }

    impl std::convert::From<i32> for PhoneticEncoding {
        fn from(value: i32) -> Self {
            match value {
                0 => Self::Unspecified,
                1 => Self::Ipa,
                2 => Self::XSampa,
                3 => Self::JapaneseYomigana,
                4 => Self::Pinyin,
                _ => Self::UnknownValue(phonetic_encoding::UnknownValue(wkt::internal::UnknownEnumValue::Integer(value))),
            }
        }
    }

    impl std::convert::From<&str> for PhoneticEncoding {
        fn from(value: &str) -> Self {
            use std::string::ToString;
            match value {
                "PHONETIC_ENCODING_UNSPECIFIED" => Self::Unspecified,
                "PHONETIC_ENCODING_IPA" => Self::Ipa,
                "PHONETIC_ENCODING_X_SAMPA" => Self::XSampa,
                "PHONETIC_ENCODING_JAPANESE_YOMIGANA" => Self::JapaneseYomigana,
                "PHONETIC_ENCODING_PINYIN" => Self::Pinyin,
                _ => Self::UnknownValue(phonetic_encoding::UnknownValue(wkt::internal::UnknownEnumValue::String(value.to_string()))),
            }
        }
    }

    impl serde::ser::Serialize for PhoneticEncoding {
        fn serialize<S>(&self, serializer: S) -> std::result::Result<S::Ok, S::Error>
        where
            S: serde::Serializer,
        {
            match self {
                Self::Unspecified => serializer.serialize_i32(0),
                Self::Ipa => serializer.serialize_i32(1),
                Self::XSampa => serializer.serialize_i32(2),
                Self::JapaneseYomigana => serializer.serialize_i32(3),
                Self::Pinyin => serializer.serialize_i32(4),
                Self::UnknownValue(u) => u.0.serialize(serializer),
            }
        }
    }

    impl<'de> serde::de::Deserialize<'de> for PhoneticEncoding {
        fn deserialize<D>(deserializer: D) -> std::result::Result<Self, D::Error>
        where
            D: serde::Deserializer<'de>,
        {
            deserializer.deserialize_any(wkt::internal::EnumVisitor::<PhoneticEncoding>::new(
                ".google.cloud.texttospeech.v1.CustomPronunciationParams.PhoneticEncoding"))
        }
    }
}

/// A collection of pronunciation customizations.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct CustomPronunciations {

    /// The pronunciation customizations are applied.
    pub pronunciations: std::vec::Vec<crate::model::CustomPronunciationParams>,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl CustomPronunciations {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [pronunciations][crate::model::CustomPronunciations::pronunciations].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::CustomPronunciations;
    /// use google_cloud_texttospeech_v1::model::CustomPronunciationParams;
    /// let x = CustomPronunciations::new()
    ///     .set_pronunciations([
    ///         CustomPronunciationParams::default()/* use setters */,
    ///         CustomPronunciationParams::default()/* use (different) setters */,
    ///     ]);
    /// ```
    pub fn set_pronunciations<T, V>(mut self, v: T) -> Self
    where
        T: std::iter::IntoIterator<Item = V>,
        V: std::convert::Into<crate::model::CustomPronunciationParams>
    {
        use std::iter::Iterator;
        self.pronunciations = v.into_iter().map(|i| i.into()).collect();
        self
    }
}

impl wkt::message::Message for CustomPronunciations {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.CustomPronunciations"
    }
}

/// A collection of turns for multi-speaker synthesis.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct MultiSpeakerMarkup {

    /// Required. Speaker turns.
    pub turns: std::vec::Vec<crate::model::multi_speaker_markup::Turn>,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl MultiSpeakerMarkup {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [turns][crate::model::MultiSpeakerMarkup::turns].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::MultiSpeakerMarkup;
    /// use google_cloud_texttospeech_v1::model::multi_speaker_markup::Turn;
    /// let x = MultiSpeakerMarkup::new()
    ///     .set_turns([
    ///         Turn::default()/* use setters */,
    ///         Turn::default()/* use (different) setters */,
    ///     ]);
    /// ```
    pub fn set_turns<T, V>(mut self, v: T) -> Self
    where
        T: std::iter::IntoIterator<Item = V>,
        V: std::convert::Into<crate::model::multi_speaker_markup::Turn>
    {
        use std::iter::Iterator;
        self.turns = v.into_iter().map(|i| i.into()).collect();
        self
    }
}

impl wkt::message::Message for MultiSpeakerMarkup {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.MultiSpeakerMarkup"
    }
}

/// Defines additional types related to [MultiSpeakerMarkup].
pub mod multi_speaker_markup {
    #[allow(unused_imports)]
    use super::*;


    /// A multi-speaker turn.
    #[derive(Clone, Default, PartialEq)]
    #[non_exhaustive]
    pub struct Turn {

        /// Required. The speaker of the turn, for example, 'O' or 'Q'. Please refer
        /// to documentation for available speakers.
        pub speaker: std::string::String,

        /// Required. The text to speak.
        pub text: std::string::String,

        pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
    }

    impl Turn {
        pub fn new() -> Self {
            std::default::Default::default()
        }

        /// Sets the value of [speaker][crate::model::multi_speaker_markup::Turn::speaker].
        ///
        /// # Example
        /// ```ignore,no_run
        /// # use google_cloud_texttospeech_v1::model::multi_speaker_markup::Turn;
        /// let x = Turn::new().set_speaker("example");
        /// ```
        pub fn set_speaker<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
            self.speaker = v.into();
            self
        }

        /// Sets the value of [text][crate::model::multi_speaker_markup::Turn::text].
        ///
        /// # Example
        /// ```ignore,no_run
        /// # use google_cloud_texttospeech_v1::model::multi_speaker_markup::Turn;
        /// let x = Turn::new().set_text("example");
        /// ```
        pub fn set_text<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
            self.text = v.into();
            self
        }
    }

    impl wkt::message::Message for Turn {
        fn typename() -> &'static str {
            "type.googleapis.com/google.cloud.texttospeech.v1.MultiSpeakerMarkup.Turn"
        }
    }
}

/// Configuration for a single speaker in a Gemini TTS multi-speaker setup.
/// Enables dialogue between two speakers.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct MultispeakerPrebuiltVoice {

    /// Required. The speaker alias of the voice. This is the user-chosen speaker
    /// name that is used in the multispeaker text input, such as "Speaker1".
    pub speaker_alias: std::string::String,

    /// Required. The speaker ID of the voice. See
    /// <https://cloud.google.com/text-to-speech/docs/gemini-tts#voice_options>
    /// for available values.
    pub speaker_id: std::string::String,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl MultispeakerPrebuiltVoice {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [speaker_alias][crate::model::MultispeakerPrebuiltVoice::speaker_alias].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::MultispeakerPrebuiltVoice;
    /// let x = MultispeakerPrebuiltVoice::new().set_speaker_alias("example");
    /// ```
    pub fn set_speaker_alias<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.speaker_alias = v.into();
        self
    }

    /// Sets the value of [speaker_id][crate::model::MultispeakerPrebuiltVoice::speaker_id].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::MultispeakerPrebuiltVoice;
    /// let x = MultispeakerPrebuiltVoice::new().set_speaker_id("example");
    /// ```
    pub fn set_speaker_id<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.speaker_id = v.into();
        self
    }
}

impl wkt::message::Message for MultispeakerPrebuiltVoice {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.MultispeakerPrebuiltVoice"
    }
}

/// Configuration for a multi-speaker text-to-speech setup. Enables the use of up
/// to two distinct voices in a single synthesis request.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct MultiSpeakerVoiceConfig {

    /// Required. A list of configurations for the voices of the speakers. Exactly
    /// two speaker voice configurations must be provided.
    pub speaker_voice_configs: std::vec::Vec<crate::model::MultispeakerPrebuiltVoice>,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl MultiSpeakerVoiceConfig {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [speaker_voice_configs][crate::model::MultiSpeakerVoiceConfig::speaker_voice_configs].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::MultiSpeakerVoiceConfig;
    /// use google_cloud_texttospeech_v1::model::MultispeakerPrebuiltVoice;
    /// let x = MultiSpeakerVoiceConfig::new()
    ///     .set_speaker_voice_configs([
    ///         MultispeakerPrebuiltVoice::default()/* use setters */,
    ///         MultispeakerPrebuiltVoice::default()/* use (different) setters */,
    ///     ]);
    /// ```
    pub fn set_speaker_voice_configs<T, V>(mut self, v: T) -> Self
    where
        T: std::iter::IntoIterator<Item = V>,
        V: std::convert::Into<crate::model::MultispeakerPrebuiltVoice>
    {
        use std::iter::Iterator;
        self.speaker_voice_configs = v.into_iter().map(|i| i.into()).collect();
        self
    }
}

impl wkt::message::Message for MultiSpeakerVoiceConfig {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.MultiSpeakerVoiceConfig"
    }
}

/// Contains text input to be synthesized. Either `text` or `ssml` must be
/// supplied. Supplying both or neither returns
/// [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]. The
/// input size is limited to 5000 bytes.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct SynthesisInput {

    /// This system instruction is supported only for controllable/promptable voice
    /// models. If this system instruction is used, we pass the unedited text to
    /// Gemini-TTS. Otherwise, a default system instruction is used. AI Studio
    /// calls this system instruction, Style Instructions.
    pub prompt: std::option::Option<std::string::String>,

    /// Optional. The pronunciation customizations are applied to the input. If
    /// this is set, the input is synthesized using the given pronunciation
    /// customizations.
    ///
    /// The initial support is for en-us, with plans to expand to other locales in
    /// the future. Instant Clone voices aren't supported.
    ///
    /// In order to customize the pronunciation of a phrase, there must be an exact
    /// match of the phrase in the input types. If using SSML, the phrase must not
    /// be inside a phoneme tag.
    pub custom_pronunciations: std::option::Option<crate::model::CustomPronunciations>,

    /// The input source, which is either plain text or SSML.
    pub input_source: std::option::Option<crate::model::synthesis_input::InputSource>,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl SynthesisInput {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [prompt][crate::model::SynthesisInput::prompt].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::SynthesisInput;
    /// let x = SynthesisInput::new().set_prompt("example");
    /// ```
    pub fn set_prompt<T>(mut self, v: T) -> Self
    where T: std::convert::Into<std::string::String>
    {
        self.prompt = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [prompt][crate::model::SynthesisInput::prompt].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::SynthesisInput;
    /// let x = SynthesisInput::new().set_or_clear_prompt(Some("example"));
    /// let x = SynthesisInput::new().set_or_clear_prompt(None::<String>);
    /// ```
    pub fn set_or_clear_prompt<T>(mut self, v: std::option::Option<T>) -> Self
    where T: std::convert::Into<std::string::String>
    {
        self.prompt = v.map(|x| x.into());
        self
    }

    /// Sets the value of [custom_pronunciations][crate::model::SynthesisInput::custom_pronunciations].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::SynthesisInput;
    /// use google_cloud_texttospeech_v1::model::CustomPronunciations;
    /// let x = SynthesisInput::new().set_custom_pronunciations(CustomPronunciations::default()/* use setters */);
    /// ```
    pub fn set_custom_pronunciations<T>(mut self, v: T) -> Self
    where T: std::convert::Into<crate::model::CustomPronunciations>
    {
        self.custom_pronunciations = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [custom_pronunciations][crate::model::SynthesisInput::custom_pronunciations].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::SynthesisInput;
    /// use google_cloud_texttospeech_v1::model::CustomPronunciations;
    /// let x = SynthesisInput::new().set_or_clear_custom_pronunciations(Some(CustomPronunciations::default()/* use setters */));
    /// let x = SynthesisInput::new().set_or_clear_custom_pronunciations(None::<CustomPronunciations>);
    /// ```
    pub fn set_or_clear_custom_pronunciations<T>(mut self, v: std::option::Option<T>) -> Self
    where T: std::convert::Into<crate::model::CustomPronunciations>
    {
        self.custom_pronunciations = v.map(|x| x.into());
        self
    }

    /// Sets the value of [input_source][crate::model::SynthesisInput::input_source].
    ///
    /// Note that all the setters affecting `input_source` are mutually
    /// exclusive.
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::SynthesisInput;
    /// use google_cloud_texttospeech_v1::model::synthesis_input::InputSource;
    /// let x = SynthesisInput::new().set_input_source(Some(InputSource::Text("example".to_string())));
    /// ```
    pub fn set_input_source<T: std::convert::Into<std::option::Option<crate::model::synthesis_input::InputSource>>>(mut self, v: T) -> Self
    {
        self.input_source = v.into();
        self
    }

    /// The value of [input_source][crate::model::SynthesisInput::input_source]
    /// if it holds a `Text`, `None` if the field is not set or
    /// holds a different branch.
    pub fn text(&self) -> std::option::Option<&std::string::String> {
        #[allow(unreachable_patterns)]
        self.input_source.as_ref().and_then(|v| match v {
            crate::model::synthesis_input::InputSource::Text(v) => std::option::Option::Some(v),
            _ => std::option::Option::None,
        })
    }

    /// Sets the value of [input_source][crate::model::SynthesisInput::input_source]
    /// to hold a `Text`.
    ///
    /// Note that all the setters affecting `input_source` are
    /// mutually exclusive.
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::SynthesisInput;
    /// let x = SynthesisInput::new().set_text("example");
    /// assert!(x.text().is_some());
    /// assert!(x.markup().is_none());
    /// assert!(x.ssml().is_none());
    /// assert!(x.multi_speaker_markup().is_none());
    /// ```
    pub fn set_text<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.input_source = std::option::Option::Some(
            crate::model::synthesis_input::InputSource::Text(
                v.into()
            )
        );
        self
    }

    /// The value of [input_source][crate::model::SynthesisInput::input_source]
    /// if it holds a `Markup`, `None` if the field is not set or
    /// holds a different branch.
    pub fn markup(&self) -> std::option::Option<&std::string::String> {
        #[allow(unreachable_patterns)]
        self.input_source.as_ref().and_then(|v| match v {
            crate::model::synthesis_input::InputSource::Markup(v) => std::option::Option::Some(v),
            _ => std::option::Option::None,
        })
    }

    /// Sets the value of [input_source][crate::model::SynthesisInput::input_source]
    /// to hold a `Markup`.
    ///
    /// Note that all the setters affecting `input_source` are
    /// mutually exclusive.
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::SynthesisInput;
    /// let x = SynthesisInput::new().set_markup("example");
    /// assert!(x.markup().is_some());
    /// assert!(x.text().is_none());
    /// assert!(x.ssml().is_none());
    /// assert!(x.multi_speaker_markup().is_none());
    /// ```
    pub fn set_markup<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.input_source = std::option::Option::Some(
            crate::model::synthesis_input::InputSource::Markup(
                v.into()
            )
        );
        self
    }

    /// The value of [input_source][crate::model::SynthesisInput::input_source]
    /// if it holds a `Ssml`, `None` if the field is not set or
    /// holds a different branch.
    pub fn ssml(&self) -> std::option::Option<&std::string::String> {
        #[allow(unreachable_patterns)]
        self.input_source.as_ref().and_then(|v| match v {
            crate::model::synthesis_input::InputSource::Ssml(v) => std::option::Option::Some(v),
            _ => std::option::Option::None,
        })
    }

    /// Sets the value of [input_source][crate::model::SynthesisInput::input_source]
    /// to hold a `Ssml`.
    ///
    /// Note that all the setters affecting `input_source` are
    /// mutually exclusive.
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::SynthesisInput;
    /// let x = SynthesisInput::new().set_ssml("example");
    /// assert!(x.ssml().is_some());
    /// assert!(x.text().is_none());
    /// assert!(x.markup().is_none());
    /// assert!(x.multi_speaker_markup().is_none());
    /// ```
    pub fn set_ssml<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.input_source = std::option::Option::Some(
            crate::model::synthesis_input::InputSource::Ssml(
                v.into()
            )
        );
        self
    }

    /// The value of [input_source][crate::model::SynthesisInput::input_source]
    /// if it holds a `MultiSpeakerMarkup`, `None` if the field is not set or
    /// holds a different branch.
    pub fn multi_speaker_markup(&self) -> std::option::Option<&std::boxed::Box<crate::model::MultiSpeakerMarkup>> {
        #[allow(unreachable_patterns)]
        self.input_source.as_ref().and_then(|v| match v {
            crate::model::synthesis_input::InputSource::MultiSpeakerMarkup(v) => std::option::Option::Some(v),
            _ => std::option::Option::None,
        })
    }

    /// Sets the value of [input_source][crate::model::SynthesisInput::input_source]
    /// to hold a `MultiSpeakerMarkup`.
    ///
    /// Note that all the setters affecting `input_source` are
    /// mutually exclusive.
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::SynthesisInput;
    /// use google_cloud_texttospeech_v1::model::MultiSpeakerMarkup;
    /// let x = SynthesisInput::new().set_multi_speaker_markup(MultiSpeakerMarkup::default()/* use setters */);
    /// assert!(x.multi_speaker_markup().is_some());
    /// assert!(x.text().is_none());
    /// assert!(x.markup().is_none());
    /// assert!(x.ssml().is_none());
    /// ```
    pub fn set_multi_speaker_markup<T: std::convert::Into<std::boxed::Box<crate::model::MultiSpeakerMarkup>>>(mut self, v: T) -> Self {
        self.input_source = std::option::Option::Some(
            crate::model::synthesis_input::InputSource::MultiSpeakerMarkup(
                v.into()
            )
        );
        self
    }
}

impl wkt::message::Message for SynthesisInput {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.SynthesisInput"
    }
}

/// Defines additional types related to [SynthesisInput].
pub mod synthesis_input {
    #[allow(unused_imports)]
    use super::*;


    /// The input source, which is either plain text or SSML.
    #[derive(Clone, Debug, PartialEq)]
    #[non_exhaustive]
    pub enum InputSource {
        /// The raw text to be synthesized.
        Text(std::string::String),
        /// Markup for HD voices specifically. This field may not be used with any
        /// other voices.
        Markup(std::string::String),
        /// The SSML document to be synthesized. The SSML document must be valid
        /// and well-formed. Otherwise the RPC will fail and return
        /// [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]. For
        /// more information, see
        /// [SSML](https://cloud.google.com/text-to-speech/docs/ssml).
        Ssml(std::string::String),
        /// The multi-speaker input to be synthesized. Only applicable for
        /// multi-speaker synthesis.
        MultiSpeakerMarkup(std::boxed::Box<crate::model::MultiSpeakerMarkup>),
    }
}

/// Description of which voice to use for a synthesis request.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct VoiceSelectionParams {

    /// Required. The language (and potentially also the region) of the voice
    /// expressed as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt)
    /// language tag, e.g. "en-US". This should not include a script tag (e.g. use
    /// "cmn-cn" rather than "cmn-Hant-cn"), because the script will be inferred
    /// from the input provided in the SynthesisInput.  The TTS service
    /// will use this parameter to help choose an appropriate voice.  Note that
    /// the TTS service may choose a voice with a slightly different language code
    /// than the one selected; it may substitute a different region
    /// (e.g. using en-US rather than en-CA if there isn't a Canadian voice
    /// available), or even a different language, e.g. using "nb" (Norwegian
    /// Bokmal) instead of "no" (Norwegian)".
    pub language_code: std::string::String,

    /// The name of the voice. If both the name and the gender are not set,
    /// the service will choose a voice based on the other parameters such as
    /// language_code.
    pub name: std::string::String,

    /// The preferred gender of the voice. If not set, the service will
    /// choose a voice based on the other parameters such as language_code and
    /// name. Note that this is only a preference, not requirement; if a
    /// voice of the appropriate gender is not available, the synthesizer should
    /// substitute a voice with a different gender rather than failing the request.
    pub ssml_gender: crate::model::SsmlVoiceGender,

    /// The configuration for a custom voice. If [CustomVoiceParams.model] is set,
    /// the service will choose the custom voice matching the specified
    /// configuration.
    pub custom_voice: std::option::Option<crate::model::CustomVoiceParams>,

    /// Optional. The configuration for a voice clone. If
    /// [VoiceCloneParams.voice_clone_key] is set, the service chooses the voice
    /// clone matching the specified configuration.
    pub voice_clone: std::option::Option<crate::model::VoiceCloneParams>,

    /// Optional. The name of the model. If set, the service will choose the model
    /// matching the specified configuration.
    pub model_name: std::string::String,

    /// Optional. The configuration for a Gemini multi-speaker text-to-speech
    /// setup. Enables the use of two distinct voices in a single synthesis
    /// request.
    pub multi_speaker_voice_config: std::option::Option<crate::model::MultiSpeakerVoiceConfig>,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl VoiceSelectionParams {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [language_code][crate::model::VoiceSelectionParams::language_code].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::VoiceSelectionParams;
    /// let x = VoiceSelectionParams::new().set_language_code("example");
    /// ```
    pub fn set_language_code<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.language_code = v.into();
        self
    }

    /// Sets the value of [name][crate::model::VoiceSelectionParams::name].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::VoiceSelectionParams;
    /// let x = VoiceSelectionParams::new().set_name("example");
    /// ```
    pub fn set_name<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.name = v.into();
        self
    }

    /// Sets the value of [ssml_gender][crate::model::VoiceSelectionParams::ssml_gender].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::VoiceSelectionParams;
    /// use google_cloud_texttospeech_v1::model::SsmlVoiceGender;
    /// let x0 = VoiceSelectionParams::new().set_ssml_gender(SsmlVoiceGender::Male);
    /// let x1 = VoiceSelectionParams::new().set_ssml_gender(SsmlVoiceGender::Female);
    /// let x2 = VoiceSelectionParams::new().set_ssml_gender(SsmlVoiceGender::Neutral);
    /// ```
    pub fn set_ssml_gender<T: std::convert::Into<crate::model::SsmlVoiceGender>>(mut self, v: T) -> Self {
        self.ssml_gender = v.into();
        self
    }

    /// Sets the value of [custom_voice][crate::model::VoiceSelectionParams::custom_voice].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::VoiceSelectionParams;
    /// use google_cloud_texttospeech_v1::model::CustomVoiceParams;
    /// let x = VoiceSelectionParams::new().set_custom_voice(CustomVoiceParams::default()/* use setters */);
    /// ```
    pub fn set_custom_voice<T>(mut self, v: T) -> Self
    where T: std::convert::Into<crate::model::CustomVoiceParams>
    {
        self.custom_voice = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [custom_voice][crate::model::VoiceSelectionParams::custom_voice].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::VoiceSelectionParams;
    /// use google_cloud_texttospeech_v1::model::CustomVoiceParams;
    /// let x = VoiceSelectionParams::new().set_or_clear_custom_voice(Some(CustomVoiceParams::default()/* use setters */));
    /// let x = VoiceSelectionParams::new().set_or_clear_custom_voice(None::<CustomVoiceParams>);
    /// ```
    pub fn set_or_clear_custom_voice<T>(mut self, v: std::option::Option<T>) -> Self
    where T: std::convert::Into<crate::model::CustomVoiceParams>
    {
        self.custom_voice = v.map(|x| x.into());
        self
    }

    /// Sets the value of [voice_clone][crate::model::VoiceSelectionParams::voice_clone].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::VoiceSelectionParams;
    /// use google_cloud_texttospeech_v1::model::VoiceCloneParams;
    /// let x = VoiceSelectionParams::new().set_voice_clone(VoiceCloneParams::default()/* use setters */);
    /// ```
    pub fn set_voice_clone<T>(mut self, v: T) -> Self
    where T: std::convert::Into<crate::model::VoiceCloneParams>
    {
        self.voice_clone = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [voice_clone][crate::model::VoiceSelectionParams::voice_clone].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::VoiceSelectionParams;
    /// use google_cloud_texttospeech_v1::model::VoiceCloneParams;
    /// let x = VoiceSelectionParams::new().set_or_clear_voice_clone(Some(VoiceCloneParams::default()/* use setters */));
    /// let x = VoiceSelectionParams::new().set_or_clear_voice_clone(None::<VoiceCloneParams>);
    /// ```
    pub fn set_or_clear_voice_clone<T>(mut self, v: std::option::Option<T>) -> Self
    where T: std::convert::Into<crate::model::VoiceCloneParams>
    {
        self.voice_clone = v.map(|x| x.into());
        self
    }

    /// Sets the value of [model_name][crate::model::VoiceSelectionParams::model_name].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::VoiceSelectionParams;
    /// let x = VoiceSelectionParams::new().set_model_name("example");
    /// ```
    pub fn set_model_name<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.model_name = v.into();
        self
    }

    /// Sets the value of [multi_speaker_voice_config][crate::model::VoiceSelectionParams::multi_speaker_voice_config].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::VoiceSelectionParams;
    /// use google_cloud_texttospeech_v1::model::MultiSpeakerVoiceConfig;
    /// let x = VoiceSelectionParams::new().set_multi_speaker_voice_config(MultiSpeakerVoiceConfig::default()/* use setters */);
    /// ```
    pub fn set_multi_speaker_voice_config<T>(mut self, v: T) -> Self
    where T: std::convert::Into<crate::model::MultiSpeakerVoiceConfig>
    {
        self.multi_speaker_voice_config = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [multi_speaker_voice_config][crate::model::VoiceSelectionParams::multi_speaker_voice_config].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::VoiceSelectionParams;
    /// use google_cloud_texttospeech_v1::model::MultiSpeakerVoiceConfig;
    /// let x = VoiceSelectionParams::new().set_or_clear_multi_speaker_voice_config(Some(MultiSpeakerVoiceConfig::default()/* use setters */));
    /// let x = VoiceSelectionParams::new().set_or_clear_multi_speaker_voice_config(None::<MultiSpeakerVoiceConfig>);
    /// ```
    pub fn set_or_clear_multi_speaker_voice_config<T>(mut self, v: std::option::Option<T>) -> Self
    where T: std::convert::Into<crate::model::MultiSpeakerVoiceConfig>
    {
        self.multi_speaker_voice_config = v.map(|x| x.into());
        self
    }
}

impl wkt::message::Message for VoiceSelectionParams {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.VoiceSelectionParams"
    }
}

/// Description of audio data to be synthesized.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct AudioConfig {

    /// Required. The format of the audio byte stream.
    pub audio_encoding: crate::model::AudioEncoding,

    /// Optional. Input only. Speaking rate/speed, in the range [0.25, 2.0]. 1.0 is
    /// the normal native speed supported by the specific voice. 2.0 is twice as
    /// fast, and 0.5 is half as fast. If unset(0.0), defaults to the native 1.0
    /// speed. Any other values < 0.25 or > 2.0 will return an error.
    pub speaking_rate: f64,

    /// Optional. Input only. Speaking pitch, in the range [-20.0, 20.0]. 20 means
    /// increase 20 semitones from the original pitch. -20 means decrease 20
    /// semitones from the original pitch.
    pub pitch: f64,

    /// Optional. Input only. Volume gain (in dB) of the normal native volume
    /// supported by the specific voice, in the range [-96.0, 16.0]. If unset, or
    /// set to a value of 0.0 (dB), will play at normal native signal amplitude. A
    /// value of -6.0 (dB) will play at approximately half the amplitude of the
    /// normal native signal amplitude. A value of +6.0 (dB) will play at
    /// approximately twice the amplitude of the normal native signal amplitude.
    /// Strongly recommend not to exceed +10 (dB) as there's usually no effective
    /// increase in loudness for any value greater than that.
    pub volume_gain_db: f64,

    /// Optional. The synthesis sample rate (in hertz) for this audio. When this is
    /// specified in SynthesizeSpeechRequest, if this is different from the voice's
    /// natural sample rate, then the synthesizer will honor this request by
    /// converting to the desired sample rate (which might result in worse audio
    /// quality), unless the specified sample rate is not supported for the
    /// encoding chosen, in which case it will fail the request and return
    /// [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT].
    pub sample_rate_hertz: i32,

    /// Optional. Input only. An identifier which selects 'audio effects' profiles
    /// that are applied on (post synthesized) text to speech. Effects are applied
    /// on top of each other in the order they are given. See
    /// [audio
    /// profiles](https://cloud.google.com/text-to-speech/docs/audio-profiles) for
    /// current supported profile ids.
    pub effects_profile_id: std::vec::Vec<std::string::String>,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl AudioConfig {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [audio_encoding][crate::model::AudioConfig::audio_encoding].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::AudioConfig;
    /// use google_cloud_texttospeech_v1::model::AudioEncoding;
    /// let x0 = AudioConfig::new().set_audio_encoding(AudioEncoding::Linear16);
    /// let x1 = AudioConfig::new().set_audio_encoding(AudioEncoding::Mp3);
    /// let x2 = AudioConfig::new().set_audio_encoding(AudioEncoding::OggOpus);
    /// ```
    pub fn set_audio_encoding<T: std::convert::Into<crate::model::AudioEncoding>>(mut self, v: T) -> Self {
        self.audio_encoding = v.into();
        self
    }

    /// Sets the value of [speaking_rate][crate::model::AudioConfig::speaking_rate].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::AudioConfig;
    /// let x = AudioConfig::new().set_speaking_rate(42.0);
    /// ```
    pub fn set_speaking_rate<T: std::convert::Into<f64>>(mut self, v: T) -> Self {
        self.speaking_rate = v.into();
        self
    }

    /// Sets the value of [pitch][crate::model::AudioConfig::pitch].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::AudioConfig;
    /// let x = AudioConfig::new().set_pitch(42.0);
    /// ```
    pub fn set_pitch<T: std::convert::Into<f64>>(mut self, v: T) -> Self {
        self.pitch = v.into();
        self
    }

    /// Sets the value of [volume_gain_db][crate::model::AudioConfig::volume_gain_db].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::AudioConfig;
    /// let x = AudioConfig::new().set_volume_gain_db(42.0);
    /// ```
    pub fn set_volume_gain_db<T: std::convert::Into<f64>>(mut self, v: T) -> Self {
        self.volume_gain_db = v.into();
        self
    }

    /// Sets the value of [sample_rate_hertz][crate::model::AudioConfig::sample_rate_hertz].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::AudioConfig;
    /// let x = AudioConfig::new().set_sample_rate_hertz(42);
    /// ```
    pub fn set_sample_rate_hertz<T: std::convert::Into<i32>>(mut self, v: T) -> Self {
        self.sample_rate_hertz = v.into();
        self
    }

    /// Sets the value of [effects_profile_id][crate::model::AudioConfig::effects_profile_id].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::AudioConfig;
    /// let x = AudioConfig::new().set_effects_profile_id(["a", "b", "c"]);
    /// ```
    pub fn set_effects_profile_id<T, V>(mut self, v: T) -> Self
    where
        T: std::iter::IntoIterator<Item = V>,
        V: std::convert::Into<std::string::String>
    {
        use std::iter::Iterator;
        self.effects_profile_id = v.into_iter().map(|i| i.into()).collect();
        self
    }
}

impl wkt::message::Message for AudioConfig {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.AudioConfig"
    }
}

/// Description of the custom voice to be synthesized.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct CustomVoiceParams {

    /// Required. The name of the AutoML model that synthesizes the custom voice.
    pub model: std::string::String,

    /// Optional. Deprecated. The usage of the synthesized audio to be reported.
    #[deprecated]
    pub reported_usage: crate::model::custom_voice_params::ReportedUsage,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl CustomVoiceParams {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [model][crate::model::CustomVoiceParams::model].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::CustomVoiceParams;
    /// let x = CustomVoiceParams::new().set_model("example");
    /// ```
    pub fn set_model<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.model = v.into();
        self
    }

    /// Sets the value of [reported_usage][crate::model::CustomVoiceParams::reported_usage].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::CustomVoiceParams;
    /// use google_cloud_texttospeech_v1::model::custom_voice_params::ReportedUsage;
    /// let x0 = CustomVoiceParams::new().set_reported_usage(ReportedUsage::Realtime);
    /// let x1 = CustomVoiceParams::new().set_reported_usage(ReportedUsage::Offline);
    /// ```
    #[deprecated]
    pub fn set_reported_usage<T: std::convert::Into<crate::model::custom_voice_params::ReportedUsage>>(mut self, v: T) -> Self {
        self.reported_usage = v.into();
        self
    }
}

impl wkt::message::Message for CustomVoiceParams {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.CustomVoiceParams"
    }
}

/// Defines additional types related to [CustomVoiceParams].
pub mod custom_voice_params {
    #[allow(unused_imports)]
    use super::*;


    /// Deprecated. The usage of the synthesized audio. Usage does not affect
    /// billing.
    ///
    /// # Working with unknown values
    ///
    /// This enum is defined as `#[non_exhaustive]` because Google Cloud may add
    /// additional enum variants at any time. Adding new variants is not considered
    /// a breaking change. Applications should write their code in anticipation of:
    ///
    /// - New values appearing in future releases of the client library, **and**
    /// - New values received dynamically, without application changes.
    ///
    /// Please consult the [Working with enums] section in the user guide for some
    /// guidelines.
    ///
    /// [Working with enums]: https://google-cloud-rust.github.io/working_with_enums.html
    #[derive(Clone, Debug, PartialEq)]
    #[non_exhaustive]
    pub enum ReportedUsage {
        /// Request with reported usage unspecified will be rejected.
        Unspecified,
        /// For scenarios where the synthesized audio is not downloadable and can
        /// only be used once. For example, real-time request in IVR system.
        Realtime,
        /// For scenarios where the synthesized audio is downloadable and can be
        /// reused. For example, the synthesized audio is downloaded, stored in
        /// customer service system and played repeatedly.
        Offline,
        /// If set, the enum was initialized with an unknown value.
        ///
        /// Applications can examine the value using [ReportedUsage::value] or
        /// [ReportedUsage::name].
        UnknownValue(reported_usage::UnknownValue),
    }

    #[doc(hidden)]
    pub mod reported_usage {
        #[allow(unused_imports)]
        use super::*;
        #[derive(Clone, Debug, PartialEq)]
        pub struct UnknownValue(pub(crate) wkt::internal::UnknownEnumValue);
    }

    impl ReportedUsage {
        /// Gets the enum value.
        ///
        /// Returns `None` if the enum contains an unknown value deserialized from
        /// the string representation of enums.
        pub fn value(&self) -> std::option::Option<i32> {
            match self {
                Self::Unspecified => std::option::Option::Some(0),
                Self::Realtime => std::option::Option::Some(1),
                Self::Offline => std::option::Option::Some(2),
                Self::UnknownValue(u) => u.0.value(),
            }
        }

        /// Gets the enum value as a string.
        ///
        /// Returns `None` if the enum contains an unknown value deserialized from
        /// the integer representation of enums.
        pub fn name(&self) -> std::option::Option<&str> {
            match self {
                Self::Unspecified => std::option::Option::Some("REPORTED_USAGE_UNSPECIFIED"),
                Self::Realtime => std::option::Option::Some("REALTIME"),
                Self::Offline => std::option::Option::Some("OFFLINE"),
                Self::UnknownValue(u) => u.0.name(),
            }
        }
    }

    impl std::default::Default for ReportedUsage {
        fn default() -> Self {
            use std::convert::From;
            Self::from(0)
        }
    }

    impl std::fmt::Display for ReportedUsage {
        fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::result::Result<(), std::fmt::Error> {
            wkt::internal::display_enum(f, self.name(), self.value())
        }
    }

    impl std::convert::From<i32> for ReportedUsage {
        fn from(value: i32) -> Self {
            match value {
                0 => Self::Unspecified,
                1 => Self::Realtime,
                2 => Self::Offline,
                _ => Self::UnknownValue(reported_usage::UnknownValue(wkt::internal::UnknownEnumValue::Integer(value))),
            }
        }
    }

    impl std::convert::From<&str> for ReportedUsage {
        fn from(value: &str) -> Self {
            use std::string::ToString;
            match value {
                "REPORTED_USAGE_UNSPECIFIED" => Self::Unspecified,
                "REALTIME" => Self::Realtime,
                "OFFLINE" => Self::Offline,
                _ => Self::UnknownValue(reported_usage::UnknownValue(wkt::internal::UnknownEnumValue::String(value.to_string()))),
            }
        }
    }

    impl serde::ser::Serialize for ReportedUsage {
        fn serialize<S>(&self, serializer: S) -> std::result::Result<S::Ok, S::Error>
        where
            S: serde::Serializer,
        {
            match self {
                Self::Unspecified => serializer.serialize_i32(0),
                Self::Realtime => serializer.serialize_i32(1),
                Self::Offline => serializer.serialize_i32(2),
                Self::UnknownValue(u) => u.0.serialize(serializer),
            }
        }
    }

    impl<'de> serde::de::Deserialize<'de> for ReportedUsage {
        fn deserialize<D>(deserializer: D) -> std::result::Result<Self, D::Error>
        where
            D: serde::Deserializer<'de>,
        {
            deserializer.deserialize_any(wkt::internal::EnumVisitor::<ReportedUsage>::new(
                ".google.cloud.texttospeech.v1.CustomVoiceParams.ReportedUsage"))
        }
    }
}

/// The configuration of Voice Clone feature.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct VoiceCloneParams {

    /// Required. Created by GenerateVoiceCloningKey.
    pub voice_cloning_key: std::string::String,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl VoiceCloneParams {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [voice_cloning_key][crate::model::VoiceCloneParams::voice_cloning_key].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::VoiceCloneParams;
    /// let x = VoiceCloneParams::new().set_voice_cloning_key("example");
    /// ```
    pub fn set_voice_cloning_key<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.voice_cloning_key = v.into();
        self
    }
}

impl wkt::message::Message for VoiceCloneParams {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.VoiceCloneParams"
    }
}

/// The message returned to the client by the `SynthesizeSpeech` method.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct SynthesizeSpeechResponse {

    /// The audio data bytes encoded as specified in the request, including the
    /// header for encodings that are wrapped in containers (e.g. MP3, OGG_OPUS).
    /// For LINEAR16 audio, we include the WAV header. Note: as
    /// with all bytes fields, protobuffers use a pure binary representation,
    /// whereas JSON representations use base64.
    pub audio_content: ::bytes::Bytes,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl SynthesizeSpeechResponse {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [audio_content][crate::model::SynthesizeSpeechResponse::audio_content].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::SynthesizeSpeechResponse;
    /// let x = SynthesizeSpeechResponse::new().set_audio_content(bytes::Bytes::from_static(b"example"));
    /// ```
    pub fn set_audio_content<T: std::convert::Into<::bytes::Bytes>>(mut self, v: T) -> Self {
        self.audio_content = v.into();
        self
    }
}

impl wkt::message::Message for SynthesizeSpeechResponse {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.SynthesizeSpeechResponse"
    }
}

/// Description of the desired output audio data.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct StreamingAudioConfig {

    /// Required. The format of the audio byte stream.
    /// Streaming supports PCM, ALAW, MULAW and OGG_OPUS. All other encodings
    /// return an error.
    pub audio_encoding: crate::model::AudioEncoding,

    /// Optional. The synthesis sample rate (in hertz) for this audio.
    pub sample_rate_hertz: i32,

    /// Optional. Input only. Speaking rate/speed, in the range [0.25, 2.0]. 1.0 is
    /// the normal native speed supported by the specific voice. 2.0 is twice as
    /// fast, and 0.5 is half as fast. If unset(0.0), defaults to the native 1.0
    /// speed. Any other values < 0.25 or > 2.0 will return an error.
    pub speaking_rate: f64,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl StreamingAudioConfig {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [audio_encoding][crate::model::StreamingAudioConfig::audio_encoding].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::StreamingAudioConfig;
    /// use google_cloud_texttospeech_v1::model::AudioEncoding;
    /// let x0 = StreamingAudioConfig::new().set_audio_encoding(AudioEncoding::Linear16);
    /// let x1 = StreamingAudioConfig::new().set_audio_encoding(AudioEncoding::Mp3);
    /// let x2 = StreamingAudioConfig::new().set_audio_encoding(AudioEncoding::OggOpus);
    /// ```
    pub fn set_audio_encoding<T: std::convert::Into<crate::model::AudioEncoding>>(mut self, v: T) -> Self {
        self.audio_encoding = v.into();
        self
    }

    /// Sets the value of [sample_rate_hertz][crate::model::StreamingAudioConfig::sample_rate_hertz].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::StreamingAudioConfig;
    /// let x = StreamingAudioConfig::new().set_sample_rate_hertz(42);
    /// ```
    pub fn set_sample_rate_hertz<T: std::convert::Into<i32>>(mut self, v: T) -> Self {
        self.sample_rate_hertz = v.into();
        self
    }

    /// Sets the value of [speaking_rate][crate::model::StreamingAudioConfig::speaking_rate].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::StreamingAudioConfig;
    /// let x = StreamingAudioConfig::new().set_speaking_rate(42.0);
    /// ```
    pub fn set_speaking_rate<T: std::convert::Into<f64>>(mut self, v: T) -> Self {
        self.speaking_rate = v.into();
        self
    }
}

impl wkt::message::Message for StreamingAudioConfig {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.StreamingAudioConfig"
    }
}

/// Provides configuration information for the StreamingSynthesize request.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct StreamingSynthesizeConfig {

    /// Required. The desired voice of the synthesized audio.
    pub voice: std::option::Option<crate::model::VoiceSelectionParams>,

    /// Optional. The configuration of the synthesized audio.
    pub streaming_audio_config: std::option::Option<crate::model::StreamingAudioConfig>,

    /// Optional. The pronunciation customizations are applied to the input. If
    /// this is set, the input is synthesized using the given pronunciation
    /// customizations.
    ///
    /// The initial support is for en-us, with plans to expand to other locales in
    /// the future. Instant Clone voices aren't supported.
    ///
    /// In order to customize the pronunciation of a phrase, there must be an exact
    /// match of the phrase in the input types. If using SSML, the phrase must not
    /// be inside a phoneme tag.
    pub custom_pronunciations: std::option::Option<crate::model::CustomPronunciations>,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl StreamingSynthesizeConfig {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [voice][crate::model::StreamingSynthesizeConfig::voice].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::StreamingSynthesizeConfig;
    /// use google_cloud_texttospeech_v1::model::VoiceSelectionParams;
    /// let x = StreamingSynthesizeConfig::new().set_voice(VoiceSelectionParams::default()/* use setters */);
    /// ```
    pub fn set_voice<T>(mut self, v: T) -> Self
    where T: std::convert::Into<crate::model::VoiceSelectionParams>
    {
        self.voice = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [voice][crate::model::StreamingSynthesizeConfig::voice].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::StreamingSynthesizeConfig;
    /// use google_cloud_texttospeech_v1::model::VoiceSelectionParams;
    /// let x = StreamingSynthesizeConfig::new().set_or_clear_voice(Some(VoiceSelectionParams::default()/* use setters */));
    /// let x = StreamingSynthesizeConfig::new().set_or_clear_voice(None::<VoiceSelectionParams>);
    /// ```
    pub fn set_or_clear_voice<T>(mut self, v: std::option::Option<T>) -> Self
    where T: std::convert::Into<crate::model::VoiceSelectionParams>
    {
        self.voice = v.map(|x| x.into());
        self
    }

    /// Sets the value of [streaming_audio_config][crate::model::StreamingSynthesizeConfig::streaming_audio_config].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::StreamingSynthesizeConfig;
    /// use google_cloud_texttospeech_v1::model::StreamingAudioConfig;
    /// let x = StreamingSynthesizeConfig::new().set_streaming_audio_config(StreamingAudioConfig::default()/* use setters */);
    /// ```
    pub fn set_streaming_audio_config<T>(mut self, v: T) -> Self
    where T: std::convert::Into<crate::model::StreamingAudioConfig>
    {
        self.streaming_audio_config = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [streaming_audio_config][crate::model::StreamingSynthesizeConfig::streaming_audio_config].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::StreamingSynthesizeConfig;
    /// use google_cloud_texttospeech_v1::model::StreamingAudioConfig;
    /// let x = StreamingSynthesizeConfig::new().set_or_clear_streaming_audio_config(Some(StreamingAudioConfig::default()/* use setters */));
    /// let x = StreamingSynthesizeConfig::new().set_or_clear_streaming_audio_config(None::<StreamingAudioConfig>);
    /// ```
    pub fn set_or_clear_streaming_audio_config<T>(mut self, v: std::option::Option<T>) -> Self
    where T: std::convert::Into<crate::model::StreamingAudioConfig>
    {
        self.streaming_audio_config = v.map(|x| x.into());
        self
    }

    /// Sets the value of [custom_pronunciations][crate::model::StreamingSynthesizeConfig::custom_pronunciations].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::StreamingSynthesizeConfig;
    /// use google_cloud_texttospeech_v1::model::CustomPronunciations;
    /// let x = StreamingSynthesizeConfig::new().set_custom_pronunciations(CustomPronunciations::default()/* use setters */);
    /// ```
    pub fn set_custom_pronunciations<T>(mut self, v: T) -> Self
    where T: std::convert::Into<crate::model::CustomPronunciations>
    {
        self.custom_pronunciations = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [custom_pronunciations][crate::model::StreamingSynthesizeConfig::custom_pronunciations].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::StreamingSynthesizeConfig;
    /// use google_cloud_texttospeech_v1::model::CustomPronunciations;
    /// let x = StreamingSynthesizeConfig::new().set_or_clear_custom_pronunciations(Some(CustomPronunciations::default()/* use setters */));
    /// let x = StreamingSynthesizeConfig::new().set_or_clear_custom_pronunciations(None::<CustomPronunciations>);
    /// ```
    pub fn set_or_clear_custom_pronunciations<T>(mut self, v: std::option::Option<T>) -> Self
    where T: std::convert::Into<crate::model::CustomPronunciations>
    {
        self.custom_pronunciations = v.map(|x| x.into());
        self
    }
}

impl wkt::message::Message for StreamingSynthesizeConfig {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.StreamingSynthesizeConfig"
    }
}

/// Input to be synthesized.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct StreamingSynthesisInput {

    /// This is system instruction supported only for controllable voice models.
    pub prompt: std::option::Option<std::string::String>,

    pub input_source: std::option::Option<crate::model::streaming_synthesis_input::InputSource>,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl StreamingSynthesisInput {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [prompt][crate::model::StreamingSynthesisInput::prompt].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::StreamingSynthesisInput;
    /// let x = StreamingSynthesisInput::new().set_prompt("example");
    /// ```
    pub fn set_prompt<T>(mut self, v: T) -> Self
    where T: std::convert::Into<std::string::String>
    {
        self.prompt = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [prompt][crate::model::StreamingSynthesisInput::prompt].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::StreamingSynthesisInput;
    /// let x = StreamingSynthesisInput::new().set_or_clear_prompt(Some("example"));
    /// let x = StreamingSynthesisInput::new().set_or_clear_prompt(None::<String>);
    /// ```
    pub fn set_or_clear_prompt<T>(mut self, v: std::option::Option<T>) -> Self
    where T: std::convert::Into<std::string::String>
    {
        self.prompt = v.map(|x| x.into());
        self
    }

    /// Sets the value of [input_source][crate::model::StreamingSynthesisInput::input_source].
    ///
    /// Note that all the setters affecting `input_source` are mutually
    /// exclusive.
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::StreamingSynthesisInput;
    /// use google_cloud_texttospeech_v1::model::streaming_synthesis_input::InputSource;
    /// let x = StreamingSynthesisInput::new().set_input_source(Some(InputSource::Text("example".to_string())));
    /// ```
    pub fn set_input_source<T: std::convert::Into<std::option::Option<crate::model::streaming_synthesis_input::InputSource>>>(mut self, v: T) -> Self
    {
        self.input_source = v.into();
        self
    }

    /// The value of [input_source][crate::model::StreamingSynthesisInput::input_source]
    /// if it holds a `Text`, `None` if the field is not set or
    /// holds a different branch.
    pub fn text(&self) -> std::option::Option<&std::string::String> {
        #[allow(unreachable_patterns)]
        self.input_source.as_ref().and_then(|v| match v {
            crate::model::streaming_synthesis_input::InputSource::Text(v) => std::option::Option::Some(v),
            _ => std::option::Option::None,
        })
    }

    /// Sets the value of [input_source][crate::model::StreamingSynthesisInput::input_source]
    /// to hold a `Text`.
    ///
    /// Note that all the setters affecting `input_source` are
    /// mutually exclusive.
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::StreamingSynthesisInput;
    /// let x = StreamingSynthesisInput::new().set_text("example");
    /// assert!(x.text().is_some());
    /// assert!(x.markup().is_none());
    /// assert!(x.multi_speaker_markup().is_none());
    /// ```
    pub fn set_text<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.input_source = std::option::Option::Some(
            crate::model::streaming_synthesis_input::InputSource::Text(
                v.into()
            )
        );
        self
    }

    /// The value of [input_source][crate::model::StreamingSynthesisInput::input_source]
    /// if it holds a `Markup`, `None` if the field is not set or
    /// holds a different branch.
    pub fn markup(&self) -> std::option::Option<&std::string::String> {
        #[allow(unreachable_patterns)]
        self.input_source.as_ref().and_then(|v| match v {
            crate::model::streaming_synthesis_input::InputSource::Markup(v) => std::option::Option::Some(v),
            _ => std::option::Option::None,
        })
    }

    /// Sets the value of [input_source][crate::model::StreamingSynthesisInput::input_source]
    /// to hold a `Markup`.
    ///
    /// Note that all the setters affecting `input_source` are
    /// mutually exclusive.
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::StreamingSynthesisInput;
    /// let x = StreamingSynthesisInput::new().set_markup("example");
    /// assert!(x.markup().is_some());
    /// assert!(x.text().is_none());
    /// assert!(x.multi_speaker_markup().is_none());
    /// ```
    pub fn set_markup<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.input_source = std::option::Option::Some(
            crate::model::streaming_synthesis_input::InputSource::Markup(
                v.into()
            )
        );
        self
    }

    /// The value of [input_source][crate::model::StreamingSynthesisInput::input_source]
    /// if it holds a `MultiSpeakerMarkup`, `None` if the field is not set or
    /// holds a different branch.
    pub fn multi_speaker_markup(&self) -> std::option::Option<&std::boxed::Box<crate::model::MultiSpeakerMarkup>> {
        #[allow(unreachable_patterns)]
        self.input_source.as_ref().and_then(|v| match v {
            crate::model::streaming_synthesis_input::InputSource::MultiSpeakerMarkup(v) => std::option::Option::Some(v),
            _ => std::option::Option::None,
        })
    }

    /// Sets the value of [input_source][crate::model::StreamingSynthesisInput::input_source]
    /// to hold a `MultiSpeakerMarkup`.
    ///
    /// Note that all the setters affecting `input_source` are
    /// mutually exclusive.
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::StreamingSynthesisInput;
    /// use google_cloud_texttospeech_v1::model::MultiSpeakerMarkup;
    /// let x = StreamingSynthesisInput::new().set_multi_speaker_markup(MultiSpeakerMarkup::default()/* use setters */);
    /// assert!(x.multi_speaker_markup().is_some());
    /// assert!(x.text().is_none());
    /// assert!(x.markup().is_none());
    /// ```
    pub fn set_multi_speaker_markup<T: std::convert::Into<std::boxed::Box<crate::model::MultiSpeakerMarkup>>>(mut self, v: T) -> Self {
        self.input_source = std::option::Option::Some(
            crate::model::streaming_synthesis_input::InputSource::MultiSpeakerMarkup(
                v.into()
            )
        );
        self
    }
}

impl wkt::message::Message for StreamingSynthesisInput {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.StreamingSynthesisInput"
    }
}

/// Defines additional types related to [StreamingSynthesisInput].
pub mod streaming_synthesis_input {
    #[allow(unused_imports)]
    use super::*;


    #[derive(Clone, Debug, PartialEq)]
    #[non_exhaustive]
    pub enum InputSource {
        /// The raw text to be synthesized. It is recommended that each input
        /// contains complete, terminating sentences, which results in better prosody
        /// in the output audio.
        Text(std::string::String),
        /// Markup for HD voices specifically. This field may not be used with any
        /// other voices.
        Markup(std::string::String),
        /// Multi-speaker markup for Gemini TTS. This field may not
        /// be used with any other voices.
        MultiSpeakerMarkup(std::boxed::Box<crate::model::MultiSpeakerMarkup>),
    }
}

/// Request message for the `StreamingSynthesize` method. Multiple
/// `StreamingSynthesizeRequest` messages are sent in one call.
/// The first message must contain a `streaming_config` that
/// fully specifies the request configuration and must not contain `input`. All
/// subsequent messages must only have `input` set.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct StreamingSynthesizeRequest {

    /// The request to be sent, either a StreamingSynthesizeConfig or
    /// StreamingSynthesisInput.
    pub streaming_request: std::option::Option<crate::model::streaming_synthesize_request::StreamingRequest>,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl StreamingSynthesizeRequest {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [streaming_request][crate::model::StreamingSynthesizeRequest::streaming_request].
    ///
    /// Note that all the setters affecting `streaming_request` are mutually
    /// exclusive.
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::StreamingSynthesizeRequest;
    /// use google_cloud_texttospeech_v1::model::StreamingSynthesizeConfig;
    /// let x = StreamingSynthesizeRequest::new().set_streaming_request(Some(
    ///     google_cloud_texttospeech_v1::model::streaming_synthesize_request::StreamingRequest::StreamingConfig(StreamingSynthesizeConfig::default().into())));
    /// ```
    pub fn set_streaming_request<T: std::convert::Into<std::option::Option<crate::model::streaming_synthesize_request::StreamingRequest>>>(mut self, v: T) -> Self
    {
        self.streaming_request = v.into();
        self
    }

    /// The value of [streaming_request][crate::model::StreamingSynthesizeRequest::streaming_request]
    /// if it holds a `StreamingConfig`, `None` if the field is not set or
    /// holds a different branch.
    pub fn streaming_config(&self) -> std::option::Option<&std::boxed::Box<crate::model::StreamingSynthesizeConfig>> {
        #[allow(unreachable_patterns)]
        self.streaming_request.as_ref().and_then(|v| match v {
            crate::model::streaming_synthesize_request::StreamingRequest::StreamingConfig(v) => std::option::Option::Some(v),
            _ => std::option::Option::None,
        })
    }

    /// Sets the value of [streaming_request][crate::model::StreamingSynthesizeRequest::streaming_request]
    /// to hold a `StreamingConfig`.
    ///
    /// Note that all the setters affecting `streaming_request` are
    /// mutually exclusive.
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::StreamingSynthesizeRequest;
    /// use google_cloud_texttospeech_v1::model::StreamingSynthesizeConfig;
    /// let x = StreamingSynthesizeRequest::new().set_streaming_config(StreamingSynthesizeConfig::default()/* use setters */);
    /// assert!(x.streaming_config().is_some());
    /// assert!(x.input().is_none());
    /// ```
    pub fn set_streaming_config<T: std::convert::Into<std::boxed::Box<crate::model::StreamingSynthesizeConfig>>>(mut self, v: T) -> Self {
        self.streaming_request = std::option::Option::Some(
            crate::model::streaming_synthesize_request::StreamingRequest::StreamingConfig(
                v.into()
            )
        );
        self
    }

    /// The value of [streaming_request][crate::model::StreamingSynthesizeRequest::streaming_request]
    /// if it holds a `Input`, `None` if the field is not set or
    /// holds a different branch.
    pub fn input(&self) -> std::option::Option<&std::boxed::Box<crate::model::StreamingSynthesisInput>> {
        #[allow(unreachable_patterns)]
        self.streaming_request.as_ref().and_then(|v| match v {
            crate::model::streaming_synthesize_request::StreamingRequest::Input(v) => std::option::Option::Some(v),
            _ => std::option::Option::None,
        })
    }

    /// Sets the value of [streaming_request][crate::model::StreamingSynthesizeRequest::streaming_request]
    /// to hold a `Input`.
    ///
    /// Note that all the setters affecting `streaming_request` are
    /// mutually exclusive.
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::StreamingSynthesizeRequest;
    /// use google_cloud_texttospeech_v1::model::StreamingSynthesisInput;
    /// let x = StreamingSynthesizeRequest::new().set_input(StreamingSynthesisInput::default()/* use setters */);
    /// assert!(x.input().is_some());
    /// assert!(x.streaming_config().is_none());
    /// ```
    pub fn set_input<T: std::convert::Into<std::boxed::Box<crate::model::StreamingSynthesisInput>>>(mut self, v: T) -> Self {
        self.streaming_request = std::option::Option::Some(
            crate::model::streaming_synthesize_request::StreamingRequest::Input(
                v.into()
            )
        );
        self
    }
}

impl wkt::message::Message for StreamingSynthesizeRequest {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.StreamingSynthesizeRequest"
    }
}

/// Defines additional types related to [StreamingSynthesizeRequest].
pub mod streaming_synthesize_request {
    #[allow(unused_imports)]
    use super::*;


    /// The request to be sent, either a StreamingSynthesizeConfig or
    /// StreamingSynthesisInput.
    #[derive(Clone, Debug, PartialEq)]
    #[non_exhaustive]
    pub enum StreamingRequest {
        /// StreamingSynthesizeConfig to be used in this streaming attempt. Only
        /// specified in the first message sent in a `StreamingSynthesize` call.
        StreamingConfig(std::boxed::Box<crate::model::StreamingSynthesizeConfig>),
        /// Input to synthesize. Specified in all messages but the first in a
        /// `StreamingSynthesize` call.
        Input(std::boxed::Box<crate::model::StreamingSynthesisInput>),
    }
}

/// `StreamingSynthesizeResponse` is the only message returned to the
/// client by `StreamingSynthesize` method. A series of zero or more
/// `StreamingSynthesizeResponse` messages are streamed back to the client.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct StreamingSynthesizeResponse {

    /// The audio data bytes encoded as specified in the request. This is
    /// headerless LINEAR16 audio with a sample rate of 24000.
    pub audio_content: ::bytes::Bytes,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl StreamingSynthesizeResponse {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [audio_content][crate::model::StreamingSynthesizeResponse::audio_content].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::StreamingSynthesizeResponse;
    /// let x = StreamingSynthesizeResponse::new().set_audio_content(bytes::Bytes::from_static(b"example"));
    /// ```
    pub fn set_audio_content<T: std::convert::Into<::bytes::Bytes>>(mut self, v: T) -> Self {
        self.audio_content = v.into();
        self
    }
}

impl wkt::message::Message for StreamingSynthesizeResponse {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.StreamingSynthesizeResponse"
    }
}

/// The top-level message sent by the client for the
/// `SynthesizeLongAudio` method.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct SynthesizeLongAudioRequest {

    /// The resource states of the request in the form of
    /// `projects/*/locations/*`.
    pub parent: std::string::String,

    /// Required. The Synthesizer requires either plain text or SSML as input.
    pub input: std::option::Option<crate::model::SynthesisInput>,

    /// Required. The configuration of the synthesized audio.
    pub audio_config: std::option::Option<crate::model::AudioConfig>,

    /// Required. Specifies a Cloud Storage URI for the synthesis results. Must be
    /// specified in the format: `gs://bucket_name/object_name`, and the bucket
    /// must already exist.
    pub output_gcs_uri: std::string::String,

    /// Required. The desired voice of the synthesized audio.
    pub voice: std::option::Option<crate::model::VoiceSelectionParams>,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl SynthesizeLongAudioRequest {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [parent][crate::model::SynthesizeLongAudioRequest::parent].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::SynthesizeLongAudioRequest;
    /// let x = SynthesizeLongAudioRequest::new().set_parent("example");
    /// ```
    pub fn set_parent<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.parent = v.into();
        self
    }

    /// Sets the value of [input][crate::model::SynthesizeLongAudioRequest::input].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::SynthesizeLongAudioRequest;
    /// use google_cloud_texttospeech_v1::model::SynthesisInput;
    /// let x = SynthesizeLongAudioRequest::new().set_input(SynthesisInput::default()/* use setters */);
    /// ```
    pub fn set_input<T>(mut self, v: T) -> Self
    where T: std::convert::Into<crate::model::SynthesisInput>
    {
        self.input = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [input][crate::model::SynthesizeLongAudioRequest::input].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::SynthesizeLongAudioRequest;
    /// use google_cloud_texttospeech_v1::model::SynthesisInput;
    /// let x = SynthesizeLongAudioRequest::new().set_or_clear_input(Some(SynthesisInput::default()/* use setters */));
    /// let x = SynthesizeLongAudioRequest::new().set_or_clear_input(None::<SynthesisInput>);
    /// ```
    pub fn set_or_clear_input<T>(mut self, v: std::option::Option<T>) -> Self
    where T: std::convert::Into<crate::model::SynthesisInput>
    {
        self.input = v.map(|x| x.into());
        self
    }

    /// Sets the value of [audio_config][crate::model::SynthesizeLongAudioRequest::audio_config].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::SynthesizeLongAudioRequest;
    /// use google_cloud_texttospeech_v1::model::AudioConfig;
    /// let x = SynthesizeLongAudioRequest::new().set_audio_config(AudioConfig::default()/* use setters */);
    /// ```
    pub fn set_audio_config<T>(mut self, v: T) -> Self
    where T: std::convert::Into<crate::model::AudioConfig>
    {
        self.audio_config = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [audio_config][crate::model::SynthesizeLongAudioRequest::audio_config].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::SynthesizeLongAudioRequest;
    /// use google_cloud_texttospeech_v1::model::AudioConfig;
    /// let x = SynthesizeLongAudioRequest::new().set_or_clear_audio_config(Some(AudioConfig::default()/* use setters */));
    /// let x = SynthesizeLongAudioRequest::new().set_or_clear_audio_config(None::<AudioConfig>);
    /// ```
    pub fn set_or_clear_audio_config<T>(mut self, v: std::option::Option<T>) -> Self
    where T: std::convert::Into<crate::model::AudioConfig>
    {
        self.audio_config = v.map(|x| x.into());
        self
    }

    /// Sets the value of [output_gcs_uri][crate::model::SynthesizeLongAudioRequest::output_gcs_uri].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::SynthesizeLongAudioRequest;
    /// let x = SynthesizeLongAudioRequest::new().set_output_gcs_uri("example");
    /// ```
    pub fn set_output_gcs_uri<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.output_gcs_uri = v.into();
        self
    }

    /// Sets the value of [voice][crate::model::SynthesizeLongAudioRequest::voice].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::SynthesizeLongAudioRequest;
    /// use google_cloud_texttospeech_v1::model::VoiceSelectionParams;
    /// let x = SynthesizeLongAudioRequest::new().set_voice(VoiceSelectionParams::default()/* use setters */);
    /// ```
    pub fn set_voice<T>(mut self, v: T) -> Self
    where T: std::convert::Into<crate::model::VoiceSelectionParams>
    {
        self.voice = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [voice][crate::model::SynthesizeLongAudioRequest::voice].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::SynthesizeLongAudioRequest;
    /// use google_cloud_texttospeech_v1::model::VoiceSelectionParams;
    /// let x = SynthesizeLongAudioRequest::new().set_or_clear_voice(Some(VoiceSelectionParams::default()/* use setters */));
    /// let x = SynthesizeLongAudioRequest::new().set_or_clear_voice(None::<VoiceSelectionParams>);
    /// ```
    pub fn set_or_clear_voice<T>(mut self, v: std::option::Option<T>) -> Self
    where T: std::convert::Into<crate::model::VoiceSelectionParams>
    {
        self.voice = v.map(|x| x.into());
        self
    }
}

impl wkt::message::Message for SynthesizeLongAudioRequest {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.SynthesizeLongAudioRequest"
    }
}

/// The message returned to the client by the `SynthesizeLongAudio` method.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct SynthesizeLongAudioResponse {

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl SynthesizeLongAudioResponse {
    pub fn new() -> Self {
        std::default::Default::default()
    }
}

impl wkt::message::Message for SynthesizeLongAudioResponse {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.SynthesizeLongAudioResponse"
    }
}

/// Metadata for response returned by the `SynthesizeLongAudio` method.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct SynthesizeLongAudioMetadata {

    /// Time when the request was received.
    pub start_time: std::option::Option<wkt::Timestamp>,

    /// Deprecated. Do not use.
    #[deprecated]
    pub last_update_time: std::option::Option<wkt::Timestamp>,

    /// The progress of the most recent processing update in percentage, ie. 70.0%.
    pub progress_percentage: f64,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl SynthesizeLongAudioMetadata {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [start_time][crate::model::SynthesizeLongAudioMetadata::start_time].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::SynthesizeLongAudioMetadata;
    /// use wkt::Timestamp;
    /// let x = SynthesizeLongAudioMetadata::new().set_start_time(Timestamp::default()/* use setters */);
    /// ```
    pub fn set_start_time<T>(mut self, v: T) -> Self
    where T: std::convert::Into<wkt::Timestamp>
    {
        self.start_time = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [start_time][crate::model::SynthesizeLongAudioMetadata::start_time].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::SynthesizeLongAudioMetadata;
    /// use wkt::Timestamp;
    /// let x = SynthesizeLongAudioMetadata::new().set_or_clear_start_time(Some(Timestamp::default()/* use setters */));
    /// let x = SynthesizeLongAudioMetadata::new().set_or_clear_start_time(None::<Timestamp>);
    /// ```
    pub fn set_or_clear_start_time<T>(mut self, v: std::option::Option<T>) -> Self
    where T: std::convert::Into<wkt::Timestamp>
    {
        self.start_time = v.map(|x| x.into());
        self
    }

    /// Sets the value of [last_update_time][crate::model::SynthesizeLongAudioMetadata::last_update_time].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::SynthesizeLongAudioMetadata;
    /// use wkt::Timestamp;
    /// let x = SynthesizeLongAudioMetadata::new().set_last_update_time(Timestamp::default()/* use setters */);
    /// ```
    #[deprecated]
    pub fn set_last_update_time<T>(mut self, v: T) -> Self
    where T: std::convert::Into<wkt::Timestamp>
    {
        self.last_update_time = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [last_update_time][crate::model::SynthesizeLongAudioMetadata::last_update_time].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::SynthesizeLongAudioMetadata;
    /// use wkt::Timestamp;
    /// let x = SynthesizeLongAudioMetadata::new().set_or_clear_last_update_time(Some(Timestamp::default()/* use setters */));
    /// let x = SynthesizeLongAudioMetadata::new().set_or_clear_last_update_time(None::<Timestamp>);
    /// ```
    #[deprecated]
    pub fn set_or_clear_last_update_time<T>(mut self, v: std::option::Option<T>) -> Self
    where T: std::convert::Into<wkt::Timestamp>
    {
        self.last_update_time = v.map(|x| x.into());
        self
    }

    /// Sets the value of [progress_percentage][crate::model::SynthesizeLongAudioMetadata::progress_percentage].
    ///
    /// # Example
    /// ```ignore,no_run
    /// # use google_cloud_texttospeech_v1::model::SynthesizeLongAudioMetadata;
    /// let x = SynthesizeLongAudioMetadata::new().set_progress_percentage(42.0);
    /// ```
    pub fn set_progress_percentage<T: std::convert::Into<f64>>(mut self, v: T) -> Self {
        self.progress_percentage = v.into();
        self
    }
}

impl wkt::message::Message for SynthesizeLongAudioMetadata {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.SynthesizeLongAudioMetadata"
    }
}

/// Gender of the voice as described in
/// [SSML voice element](https://www.w3.org/TR/speech-synthesis11/#edef_voice).
///
/// # Working with unknown values
///
/// This enum is defined as `#[non_exhaustive]` because Google Cloud may add
/// additional enum variants at any time. Adding new variants is not considered
/// a breaking change. Applications should write their code in anticipation of:
///
/// - New values appearing in future releases of the client library, **and**
/// - New values received dynamically, without application changes.
///
/// Please consult the [Working with enums] section in the user guide for some
/// guidelines.
///
/// [Working with enums]: https://google-cloud-rust.github.io/working_with_enums.html
#[derive(Clone, Debug, PartialEq)]
#[non_exhaustive]
pub enum SsmlVoiceGender {
    /// An unspecified gender.
    /// In VoiceSelectionParams, this means that the client doesn't care which
    /// gender the selected voice will have. In the Voice field of
    /// ListVoicesResponse, this may mean that the voice doesn't fit any of the
    /// other categories in this enum, or that the gender of the voice isn't known.
    Unspecified,
    /// A male voice.
    Male,
    /// A female voice.
    Female,
    /// A gender-neutral voice. This voice is not yet supported.
    Neutral,
    /// If set, the enum was initialized with an unknown value.
    ///
    /// Applications can examine the value using [SsmlVoiceGender::value] or
    /// [SsmlVoiceGender::name].
    UnknownValue(ssml_voice_gender::UnknownValue),
}

#[doc(hidden)]
pub mod ssml_voice_gender {
    #[allow(unused_imports)]
    use super::*;
    #[derive(Clone, Debug, PartialEq)]
    pub struct UnknownValue(pub(crate) wkt::internal::UnknownEnumValue);
}

impl SsmlVoiceGender {
    /// Gets the enum value.
    ///
    /// Returns `None` if the enum contains an unknown value deserialized from
    /// the string representation of enums.
    pub fn value(&self) -> std::option::Option<i32> {
        match self {
            Self::Unspecified => std::option::Option::Some(0),
            Self::Male => std::option::Option::Some(1),
            Self::Female => std::option::Option::Some(2),
            Self::Neutral => std::option::Option::Some(3),
            Self::UnknownValue(u) => u.0.value(),
        }
    }

    /// Gets the enum value as a string.
    ///
    /// Returns `None` if the enum contains an unknown value deserialized from
    /// the integer representation of enums.
    pub fn name(&self) -> std::option::Option<&str> {
        match self {
            Self::Unspecified => std::option::Option::Some("SSML_VOICE_GENDER_UNSPECIFIED"),
            Self::Male => std::option::Option::Some("MALE"),
            Self::Female => std::option::Option::Some("FEMALE"),
            Self::Neutral => std::option::Option::Some("NEUTRAL"),
            Self::UnknownValue(u) => u.0.name(),
        }
    }
}

impl std::default::Default for SsmlVoiceGender {
    fn default() -> Self {
        use std::convert::From;
        Self::from(0)
    }
}

impl std::fmt::Display for SsmlVoiceGender {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::result::Result<(), std::fmt::Error> {
        wkt::internal::display_enum(f, self.name(), self.value())
    }
}

impl std::convert::From<i32> for SsmlVoiceGender {
    fn from(value: i32) -> Self {
        match value {
            0 => Self::Unspecified,
            1 => Self::Male,
            2 => Self::Female,
            3 => Self::Neutral,
            _ => Self::UnknownValue(ssml_voice_gender::UnknownValue(wkt::internal::UnknownEnumValue::Integer(value))),
        }
    }
}

impl std::convert::From<&str> for SsmlVoiceGender {
    fn from(value: &str) -> Self {
        use std::string::ToString;
        match value {
            "SSML_VOICE_GENDER_UNSPECIFIED" => Self::Unspecified,
            "MALE" => Self::Male,
            "FEMALE" => Self::Female,
            "NEUTRAL" => Self::Neutral,
            _ => Self::UnknownValue(ssml_voice_gender::UnknownValue(wkt::internal::UnknownEnumValue::String(value.to_string()))),
        }
    }
}

impl serde::ser::Serialize for SsmlVoiceGender {
    fn serialize<S>(&self, serializer: S) -> std::result::Result<S::Ok, S::Error>
    where
        S: serde::Serializer,
    {
        match self {
            Self::Unspecified => serializer.serialize_i32(0),
            Self::Male => serializer.serialize_i32(1),
            Self::Female => serializer.serialize_i32(2),
            Self::Neutral => serializer.serialize_i32(3),
            Self::UnknownValue(u) => u.0.serialize(serializer),
        }
    }
}

impl<'de> serde::de::Deserialize<'de> for SsmlVoiceGender {
    fn deserialize<D>(deserializer: D) -> std::result::Result<Self, D::Error>
    where
        D: serde::Deserializer<'de>,
    {
        deserializer.deserialize_any(wkt::internal::EnumVisitor::<SsmlVoiceGender>::new(
            ".google.cloud.texttospeech.v1.SsmlVoiceGender"))
    }
}

/// Configuration to set up audio encoder. The encoding determines the output
/// audio format that we'd like.
///
/// # Working with unknown values
///
/// This enum is defined as `#[non_exhaustive]` because Google Cloud may add
/// additional enum variants at any time. Adding new variants is not considered
/// a breaking change. Applications should write their code in anticipation of:
///
/// - New values appearing in future releases of the client library, **and**
/// - New values received dynamically, without application changes.
///
/// Please consult the [Working with enums] section in the user guide for some
/// guidelines.
///
/// [Working with enums]: https://google-cloud-rust.github.io/working_with_enums.html
#[derive(Clone, Debug, PartialEq)]
#[non_exhaustive]
pub enum AudioEncoding {
    /// Not specified. Only used by GenerateVoiceCloningKey. Otherwise, will return
    /// result
    /// [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT].
    Unspecified,
    /// Uncompressed 16-bit signed little-endian samples (Linear PCM).
    /// Audio content returned as LINEAR16 also contains a WAV header.
    Linear16,
    /// MP3 audio at 32kbps.
    Mp3,
    /// Opus encoded audio wrapped in an ogg container. The result is a
    /// file which can be played natively on Android, and in browsers (at least
    /// Chrome and Firefox). The quality of the encoding is considerably higher
    /// than MP3 while using approximately the same bitrate.
    OggOpus,
    /// 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
    /// Audio content returned as MULAW also contains a WAV header.
    Mulaw,
    /// 8-bit samples that compand 14-bit audio samples using G.711 PCMU/A-law.
    /// Audio content returned as ALAW also contains a WAV header.
    Alaw,
    /// Uncompressed 16-bit signed little-endian samples (Linear PCM).
    /// Note that as opposed to LINEAR16, audio won't be wrapped in a WAV (or
    /// any other) header.
    Pcm,
    /// M4A audio.
    M4A,
    /// If set, the enum was initialized with an unknown value.
    ///
    /// Applications can examine the value using [AudioEncoding::value] or
    /// [AudioEncoding::name].
    UnknownValue(audio_encoding::UnknownValue),
}

#[doc(hidden)]
pub mod audio_encoding {
    #[allow(unused_imports)]
    use super::*;
    #[derive(Clone, Debug, PartialEq)]
    pub struct UnknownValue(pub(crate) wkt::internal::UnknownEnumValue);
}

impl AudioEncoding {
    /// Gets the enum value.
    ///
    /// Returns `None` if the enum contains an unknown value deserialized from
    /// the string representation of enums.
    pub fn value(&self) -> std::option::Option<i32> {
        match self {
            Self::Unspecified => std::option::Option::Some(0),
            Self::Linear16 => std::option::Option::Some(1),
            Self::Mp3 => std::option::Option::Some(2),
            Self::OggOpus => std::option::Option::Some(3),
            Self::Mulaw => std::option::Option::Some(5),
            Self::Alaw => std::option::Option::Some(6),
            Self::Pcm => std::option::Option::Some(7),
            Self::M4A => std::option::Option::Some(8),
            Self::UnknownValue(u) => u.0.value(),
        }
    }

    /// Gets the enum value as a string.
    ///
    /// Returns `None` if the enum contains an unknown value deserialized from
    /// the integer representation of enums.
    pub fn name(&self) -> std::option::Option<&str> {
        match self {
            Self::Unspecified => std::option::Option::Some("AUDIO_ENCODING_UNSPECIFIED"),
            Self::Linear16 => std::option::Option::Some("LINEAR16"),
            Self::Mp3 => std::option::Option::Some("MP3"),
            Self::OggOpus => std::option::Option::Some("OGG_OPUS"),
            Self::Mulaw => std::option::Option::Some("MULAW"),
            Self::Alaw => std::option::Option::Some("ALAW"),
            Self::Pcm => std::option::Option::Some("PCM"),
            Self::M4A => std::option::Option::Some("M4A"),
            Self::UnknownValue(u) => u.0.name(),
        }
    }
}

impl std::default::Default for AudioEncoding {
    fn default() -> Self {
        use std::convert::From;
        Self::from(0)
    }
}

impl std::fmt::Display for AudioEncoding {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::result::Result<(), std::fmt::Error> {
        wkt::internal::display_enum(f, self.name(), self.value())
    }
}

impl std::convert::From<i32> for AudioEncoding {
    fn from(value: i32) -> Self {
        match value {
            0 => Self::Unspecified,
            1 => Self::Linear16,
            2 => Self::Mp3,
            3 => Self::OggOpus,
            5 => Self::Mulaw,
            6 => Self::Alaw,
            7 => Self::Pcm,
            8 => Self::M4A,
            _ => Self::UnknownValue(audio_encoding::UnknownValue(wkt::internal::UnknownEnumValue::Integer(value))),
        }
    }
}

impl std::convert::From<&str> for AudioEncoding {
    fn from(value: &str) -> Self {
        use std::string::ToString;
        match value {
            "AUDIO_ENCODING_UNSPECIFIED" => Self::Unspecified,
            "LINEAR16" => Self::Linear16,
            "MP3" => Self::Mp3,
            "OGG_OPUS" => Self::OggOpus,
            "MULAW" => Self::Mulaw,
            "ALAW" => Self::Alaw,
            "PCM" => Self::Pcm,
            "M4A" => Self::M4A,
            _ => Self::UnknownValue(audio_encoding::UnknownValue(wkt::internal::UnknownEnumValue::String(value.to_string()))),
        }
    }
}

impl serde::ser::Serialize for AudioEncoding {
    fn serialize<S>(&self, serializer: S) -> std::result::Result<S::Ok, S::Error>
    where
        S: serde::Serializer,
    {
        match self {
            Self::Unspecified => serializer.serialize_i32(0),
            Self::Linear16 => serializer.serialize_i32(1),
            Self::Mp3 => serializer.serialize_i32(2),
            Self::OggOpus => serializer.serialize_i32(3),
            Self::Mulaw => serializer.serialize_i32(5),
            Self::Alaw => serializer.serialize_i32(6),
            Self::Pcm => serializer.serialize_i32(7),
            Self::M4A => serializer.serialize_i32(8),
            Self::UnknownValue(u) => u.0.serialize(serializer),
        }
    }
}

impl<'de> serde::de::Deserialize<'de> for AudioEncoding {
    fn deserialize<D>(deserializer: D) -> std::result::Result<Self, D::Error>
    where
        D: serde::Deserializer<'de>,
    {
        deserializer.deserialize_any(wkt::internal::EnumVisitor::<AudioEncoding>::new(
            ".google.cloud.texttospeech.v1.AudioEncoding"))
    }
}
