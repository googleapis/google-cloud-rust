// Copyright 2025 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     https://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//
// Code generated by sidekick. DO NOT EDIT.

#![allow(rustdoc::redundant_explicit_links)]
#![allow(rustdoc::broken_intra_doc_links)]
#![no_implicit_prelude]
extern crate async_trait;
extern crate bytes;
extern crate gax;
extern crate gaxi;
extern crate lazy_static;
extern crate longrunning;
extern crate lro;
extern crate reqwest;
extern crate serde;
extern crate serde_json;
extern crate serde_with;
extern crate std;
extern crate tracing;
extern crate wkt;

/// The top-level message sent by the client for the `ListVoices` method.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct ListVoicesRequest {
    /// Optional. Recommended.
    /// [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.
    /// If not specified, the API will return all supported voices.
    /// If specified, the ListVoices call will only return voices that can be used
    /// to synthesize this language_code. For example, if you specify `"en-NZ"`,
    /// all `"en-NZ"` voices will be returned. If you specify `"no"`, both
    /// `"no-\*"` (Norwegian) and `"nb-\*"` (Norwegian Bokmal) voices will be
    /// returned.
    #[serde(skip_serializing_if = "std::string::String::is_empty")]
    pub language_code: std::string::String,

    #[serde(flatten, skip_serializing_if = "serde_json::Map::is_empty")]
    _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl ListVoicesRequest {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [language_code][crate::model::ListVoicesRequest::language_code].
    pub fn set_language_code<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.language_code = v.into();
        self
    }
}

impl wkt::message::Message for ListVoicesRequest {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.ListVoicesRequest"
    }
}

/// The message returned to the client by the `ListVoices` method.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct ListVoicesResponse {
    /// The list of voices.
    #[serde(skip_serializing_if = "std::vec::Vec::is_empty")]
    pub voices: std::vec::Vec<crate::model::Voice>,

    #[serde(flatten, skip_serializing_if = "serde_json::Map::is_empty")]
    _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl ListVoicesResponse {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [voices][crate::model::ListVoicesResponse::voices].
    pub fn set_voices<T, V>(mut self, v: T) -> Self
    where
        T: std::iter::IntoIterator<Item = V>,
        V: std::convert::Into<crate::model::Voice>,
    {
        use std::iter::Iterator;
        self.voices = v.into_iter().map(|i| i.into()).collect();
        self
    }
}

impl wkt::message::Message for ListVoicesResponse {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.ListVoicesResponse"
    }
}

/// Description of a voice supported by the TTS service.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct Voice {
    /// The languages that this voice supports, expressed as
    /// [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tags (e.g.
    /// "en-US", "es-419", "cmn-tw").
    #[serde(skip_serializing_if = "std::vec::Vec::is_empty")]
    pub language_codes: std::vec::Vec<std::string::String>,

    /// The name of this voice.  Each distinct voice has a unique name.
    #[serde(skip_serializing_if = "std::string::String::is_empty")]
    pub name: std::string::String,

    /// The gender of this voice.
    pub ssml_gender: crate::model::SsmlVoiceGender,

    /// The natural sample rate (in hertz) for this voice.
    #[serde(skip_serializing_if = "wkt::internal::is_default")]
    pub natural_sample_rate_hertz: i32,

    #[serde(flatten, skip_serializing_if = "serde_json::Map::is_empty")]
    _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl Voice {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [name][crate::model::Voice::name].
    pub fn set_name<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.name = v.into();
        self
    }

    /// Sets the value of [ssml_gender][crate::model::Voice::ssml_gender].
    pub fn set_ssml_gender<T: std::convert::Into<crate::model::SsmlVoiceGender>>(
        mut self,
        v: T,
    ) -> Self {
        self.ssml_gender = v.into();
        self
    }

    /// Sets the value of [natural_sample_rate_hertz][crate::model::Voice::natural_sample_rate_hertz].
    pub fn set_natural_sample_rate_hertz<T: std::convert::Into<i32>>(mut self, v: T) -> Self {
        self.natural_sample_rate_hertz = v.into();
        self
    }

    /// Sets the value of [language_codes][crate::model::Voice::language_codes].
    pub fn set_language_codes<T, V>(mut self, v: T) -> Self
    where
        T: std::iter::IntoIterator<Item = V>,
        V: std::convert::Into<std::string::String>,
    {
        use std::iter::Iterator;
        self.language_codes = v.into_iter().map(|i| i.into()).collect();
        self
    }
}

impl wkt::message::Message for Voice {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.Voice"
    }
}

/// Used for advanced voice options.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct AdvancedVoiceOptions {
    /// Only for Journey voices. If false, the synthesis is context aware
    /// and has a higher latency.
    #[serde(skip_serializing_if = "std::option::Option::is_none")]
    pub low_latency_journey_synthesis: std::option::Option<bool>,

    #[serde(flatten, skip_serializing_if = "serde_json::Map::is_empty")]
    _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl AdvancedVoiceOptions {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [low_latency_journey_synthesis][crate::model::AdvancedVoiceOptions::low_latency_journey_synthesis].
    pub fn set_low_latency_journey_synthesis<T: std::convert::Into<std::option::Option<bool>>>(
        mut self,
        v: T,
    ) -> Self {
        self.low_latency_journey_synthesis = v.into();
        self
    }
}

impl wkt::message::Message for AdvancedVoiceOptions {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.AdvancedVoiceOptions"
    }
}

/// The top-level message sent by the client for the `SynthesizeSpeech` method.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct SynthesizeSpeechRequest {
    /// Required. The Synthesizer requires either plain text or SSML as input.
    #[serde(skip_serializing_if = "std::option::Option::is_none")]
    pub input: std::option::Option<crate::model::SynthesisInput>,

    /// Required. The desired voice of the synthesized audio.
    #[serde(skip_serializing_if = "std::option::Option::is_none")]
    pub voice: std::option::Option<crate::model::VoiceSelectionParams>,

    /// Required. The configuration of the synthesized audio.
    #[serde(skip_serializing_if = "std::option::Option::is_none")]
    pub audio_config: std::option::Option<crate::model::AudioConfig>,

    /// Advanced voice options.
    #[serde(skip_serializing_if = "std::option::Option::is_none")]
    pub advanced_voice_options: std::option::Option<crate::model::AdvancedVoiceOptions>,

    #[serde(flatten, skip_serializing_if = "serde_json::Map::is_empty")]
    _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl SynthesizeSpeechRequest {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [input][crate::model::SynthesizeSpeechRequest::input].
    pub fn set_input<T: std::convert::Into<std::option::Option<crate::model::SynthesisInput>>>(
        mut self,
        v: T,
    ) -> Self {
        self.input = v.into();
        self
    }

    /// Sets the value of [voice][crate::model::SynthesizeSpeechRequest::voice].
    pub fn set_voice<
        T: std::convert::Into<std::option::Option<crate::model::VoiceSelectionParams>>,
    >(
        mut self,
        v: T,
    ) -> Self {
        self.voice = v.into();
        self
    }

    /// Sets the value of [audio_config][crate::model::SynthesizeSpeechRequest::audio_config].
    pub fn set_audio_config<
        T: std::convert::Into<std::option::Option<crate::model::AudioConfig>>,
    >(
        mut self,
        v: T,
    ) -> Self {
        self.audio_config = v.into();
        self
    }

    /// Sets the value of [advanced_voice_options][crate::model::SynthesizeSpeechRequest::advanced_voice_options].
    pub fn set_advanced_voice_options<
        T: std::convert::Into<std::option::Option<crate::model::AdvancedVoiceOptions>>,
    >(
        mut self,
        v: T,
    ) -> Self {
        self.advanced_voice_options = v.into();
        self
    }
}

impl wkt::message::Message for SynthesizeSpeechRequest {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.SynthesizeSpeechRequest"
    }
}

/// Pronunciation customization for a phrase.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct CustomPronunciationParams {
    /// The phrase to which the customization is applied.
    /// The phrase can be multiple words, such as proper nouns, but shouldn't span
    /// the length of the sentence.
    #[serde(skip_serializing_if = "std::option::Option::is_none")]
    pub phrase: std::option::Option<std::string::String>,

    /// The phonetic encoding of the phrase.
    #[serde(skip_serializing_if = "std::option::Option::is_none")]
    pub phonetic_encoding:
        std::option::Option<crate::model::custom_pronunciation_params::PhoneticEncoding>,

    /// The pronunciation of the phrase. This must be in the phonetic encoding
    /// specified above.
    #[serde(skip_serializing_if = "std::option::Option::is_none")]
    pub pronunciation: std::option::Option<std::string::String>,

    #[serde(flatten, skip_serializing_if = "serde_json::Map::is_empty")]
    _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl CustomPronunciationParams {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [phrase][crate::model::CustomPronunciationParams::phrase].
    pub fn set_phrase<T: std::convert::Into<std::option::Option<std::string::String>>>(
        mut self,
        v: T,
    ) -> Self {
        self.phrase = v.into();
        self
    }

    /// Sets the value of [phonetic_encoding][crate::model::CustomPronunciationParams::phonetic_encoding].
    pub fn set_phonetic_encoding<
        T: std::convert::Into<
                std::option::Option<crate::model::custom_pronunciation_params::PhoneticEncoding>,
            >,
    >(
        mut self,
        v: T,
    ) -> Self {
        self.phonetic_encoding = v.into();
        self
    }

    /// Sets the value of [pronunciation][crate::model::CustomPronunciationParams::pronunciation].
    pub fn set_pronunciation<T: std::convert::Into<std::option::Option<std::string::String>>>(
        mut self,
        v: T,
    ) -> Self {
        self.pronunciation = v.into();
        self
    }
}

impl wkt::message::Message for CustomPronunciationParams {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.CustomPronunciationParams"
    }
}

/// Defines additional types related to [CustomPronunciationParams].
pub mod custom_pronunciation_params {
    #[allow(unused_imports)]
    use super::*;

    /// The phonetic encoding of the phrase.
    ///
    /// # Working with unknown values
    ///
    /// This enum is defined as `#[non_exhaustive]` because Google Cloud may add
    /// additional enum variants at any time. Adding new variants is not considered
    /// a breaking change. Applications should write their code in anticipation of:
    ///
    /// - New values appearing in future releases of the client library, **and**
    /// - New values received dynamically, without application changes.
    ///
    /// Please consult the [Working with enums] section in the user guide for some
    /// guidelines.
    ///
    /// [Working with enums]: https://google-cloud-rust.github.io/working_with_enums.html
    #[derive(Clone, Debug, PartialEq)]
    #[non_exhaustive]
    pub enum PhoneticEncoding {
        /// Not specified.
        Unspecified,
        /// IPA, such as apple -> ˈæpəl.
        /// <https://en.wikipedia.org/wiki/International_Phonetic_Alphabet>
        Ipa,
        /// X-SAMPA, such as apple -> "{p@l".
        /// <https://en.wikipedia.org/wiki/X-SAMPA>
        XSampa,
        /// If set, the enum was initialized with an unknown value.
        ///
        /// Applications can examine the value using [PhoneticEncoding::value] or
        /// [PhoneticEncoding::name].
        UnknownValue(phonetic_encoding::UnknownValue),
    }

    #[doc(hidden)]
    pub mod phonetic_encoding {
        #[allow(unused_imports)]
        use super::*;
        #[derive(Clone, Debug, PartialEq)]
        pub struct UnknownValue(pub(crate) wkt::internal::UnknownEnumValue);
    }

    impl PhoneticEncoding {
        /// Gets the enum value.
        ///
        /// Returns `None` if the enum contains an unknown value deserialized from
        /// the string representation of enums.
        pub fn value(&self) -> std::option::Option<i32> {
            match self {
                Self::Unspecified => std::option::Option::Some(0),
                Self::Ipa => std::option::Option::Some(1),
                Self::XSampa => std::option::Option::Some(2),
                Self::UnknownValue(u) => u.0.value(),
            }
        }

        /// Gets the enum value as a string.
        ///
        /// Returns `None` if the enum contains an unknown value deserialized from
        /// the integer representation of enums.
        pub fn name(&self) -> std::option::Option<&str> {
            match self {
                Self::Unspecified => std::option::Option::Some("PHONETIC_ENCODING_UNSPECIFIED"),
                Self::Ipa => std::option::Option::Some("PHONETIC_ENCODING_IPA"),
                Self::XSampa => std::option::Option::Some("PHONETIC_ENCODING_X_SAMPA"),
                Self::UnknownValue(u) => u.0.name(),
            }
        }
    }

    impl std::default::Default for PhoneticEncoding {
        fn default() -> Self {
            use std::convert::From;
            Self::from(0)
        }
    }

    impl std::fmt::Display for PhoneticEncoding {
        fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::result::Result<(), std::fmt::Error> {
            wkt::internal::display_enum(f, self.name(), self.value())
        }
    }

    impl std::convert::From<i32> for PhoneticEncoding {
        fn from(value: i32) -> Self {
            match value {
                0 => Self::Unspecified,
                1 => Self::Ipa,
                2 => Self::XSampa,
                _ => Self::UnknownValue(phonetic_encoding::UnknownValue(
                    wkt::internal::UnknownEnumValue::Integer(value),
                )),
            }
        }
    }

    impl std::convert::From<&str> for PhoneticEncoding {
        fn from(value: &str) -> Self {
            use std::string::ToString;
            match value {
                "PHONETIC_ENCODING_UNSPECIFIED" => Self::Unspecified,
                "PHONETIC_ENCODING_IPA" => Self::Ipa,
                "PHONETIC_ENCODING_X_SAMPA" => Self::XSampa,
                _ => Self::UnknownValue(phonetic_encoding::UnknownValue(
                    wkt::internal::UnknownEnumValue::String(value.to_string()),
                )),
            }
        }
    }

    impl serde::ser::Serialize for PhoneticEncoding {
        fn serialize<S>(&self, serializer: S) -> std::result::Result<S::Ok, S::Error>
        where
            S: serde::Serializer,
        {
            match self {
                Self::Unspecified => serializer.serialize_i32(0),
                Self::Ipa => serializer.serialize_i32(1),
                Self::XSampa => serializer.serialize_i32(2),
                Self::UnknownValue(u) => u.0.serialize(serializer),
            }
        }
    }

    impl<'de> serde::de::Deserialize<'de> for PhoneticEncoding {
        fn deserialize<D>(deserializer: D) -> std::result::Result<Self, D::Error>
        where
            D: serde::Deserializer<'de>,
        {
            deserializer.deserialize_any(wkt::internal::EnumVisitor::<PhoneticEncoding>::new(
                ".google.cloud.texttospeech.v1.CustomPronunciationParams.PhoneticEncoding",
            ))
        }
    }
}

/// A collection of pronunciation customizations.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct CustomPronunciations {
    /// The pronunciation customizations are applied.
    #[serde(skip_serializing_if = "std::vec::Vec::is_empty")]
    pub pronunciations: std::vec::Vec<crate::model::CustomPronunciationParams>,

    #[serde(flatten, skip_serializing_if = "serde_json::Map::is_empty")]
    _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl CustomPronunciations {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [pronunciations][crate::model::CustomPronunciations::pronunciations].
    pub fn set_pronunciations<T, V>(mut self, v: T) -> Self
    where
        T: std::iter::IntoIterator<Item = V>,
        V: std::convert::Into<crate::model::CustomPronunciationParams>,
    {
        use std::iter::Iterator;
        self.pronunciations = v.into_iter().map(|i| i.into()).collect();
        self
    }
}

impl wkt::message::Message for CustomPronunciations {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.CustomPronunciations"
    }
}

/// A collection of turns for multi-speaker synthesis.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct MultiSpeakerMarkup {
    /// Required. Speaker turns.
    #[serde(skip_serializing_if = "std::vec::Vec::is_empty")]
    pub turns: std::vec::Vec<crate::model::multi_speaker_markup::Turn>,

    #[serde(flatten, skip_serializing_if = "serde_json::Map::is_empty")]
    _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl MultiSpeakerMarkup {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [turns][crate::model::MultiSpeakerMarkup::turns].
    pub fn set_turns<T, V>(mut self, v: T) -> Self
    where
        T: std::iter::IntoIterator<Item = V>,
        V: std::convert::Into<crate::model::multi_speaker_markup::Turn>,
    {
        use std::iter::Iterator;
        self.turns = v.into_iter().map(|i| i.into()).collect();
        self
    }
}

impl wkt::message::Message for MultiSpeakerMarkup {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.MultiSpeakerMarkup"
    }
}

/// Defines additional types related to [MultiSpeakerMarkup].
pub mod multi_speaker_markup {
    #[allow(unused_imports)]
    use super::*;

    /// A multi-speaker turn.
    #[serde_with::serde_as]
    #[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
    #[serde(default, rename_all = "camelCase")]
    #[non_exhaustive]
    pub struct Turn {
        /// Required. The speaker of the turn, for example, 'O' or 'Q'. Please refer
        /// to documentation for available speakers.
        #[serde(skip_serializing_if = "std::string::String::is_empty")]
        pub speaker: std::string::String,

        /// Required. The text to speak.
        #[serde(skip_serializing_if = "std::string::String::is_empty")]
        pub text: std::string::String,

        #[serde(flatten, skip_serializing_if = "serde_json::Map::is_empty")]
        _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
    }

    impl Turn {
        pub fn new() -> Self {
            std::default::Default::default()
        }

        /// Sets the value of [speaker][crate::model::multi_speaker_markup::Turn::speaker].
        pub fn set_speaker<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
            self.speaker = v.into();
            self
        }

        /// Sets the value of [text][crate::model::multi_speaker_markup::Turn::text].
        pub fn set_text<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
            self.text = v.into();
            self
        }
    }

    impl wkt::message::Message for Turn {
        fn typename() -> &'static str {
            "type.googleapis.com/google.cloud.texttospeech.v1.MultiSpeakerMarkup.Turn"
        }
    }
}

/// Contains text input to be synthesized. Either `text` or `ssml` must be
/// supplied. Supplying both or neither returns
/// [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]. The
/// input size is limited to 5000 bytes.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct SynthesisInput {
    /// Optional. The pronunciation customizations are applied to the input. If
    /// this is set, the input is synthesized using the given pronunciation
    /// customizations.
    ///
    /// The initial support is for en-us, with plans to expand to other locales in
    /// the future. Instant Clone voices aren't supported.
    ///
    /// In order to customize the pronunciation of a phrase, there must be an exact
    /// match of the phrase in the input types. If using SSML, the phrase must not
    /// be inside a phoneme tag.
    #[serde(skip_serializing_if = "std::option::Option::is_none")]
    pub custom_pronunciations: std::option::Option<crate::model::CustomPronunciations>,

    /// The input source, which is either plain text or SSML.
    #[serde(flatten, skip_serializing_if = "std::option::Option::is_none")]
    pub input_source: std::option::Option<crate::model::synthesis_input::InputSource>,

    #[serde(flatten, skip_serializing_if = "serde_json::Map::is_empty")]
    _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl SynthesisInput {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [custom_pronunciations][crate::model::SynthesisInput::custom_pronunciations].
    pub fn set_custom_pronunciations<
        T: std::convert::Into<std::option::Option<crate::model::CustomPronunciations>>,
    >(
        mut self,
        v: T,
    ) -> Self {
        self.custom_pronunciations = v.into();
        self
    }

    /// Sets the value of [input_source][crate::model::SynthesisInput::input_source].
    ///
    /// Note that all the setters affecting `input_source` are mutually
    /// exclusive.
    pub fn set_input_source<
        T: std::convert::Into<std::option::Option<crate::model::synthesis_input::InputSource>>,
    >(
        mut self,
        v: T,
    ) -> Self {
        self.input_source = v.into();
        self
    }

    /// The value of [input_source][crate::model::SynthesisInput::input_source]
    /// if it holds a `Text`, `None` if the field is not set or
    /// holds a different branch.
    pub fn text(&self) -> std::option::Option<&std::string::String> {
        #[allow(unreachable_patterns)]
        self.input_source.as_ref().and_then(|v| match v {
            crate::model::synthesis_input::InputSource::Text(v) => std::option::Option::Some(v),
            _ => std::option::Option::None,
        })
    }

    /// The value of [input_source][crate::model::SynthesisInput::input_source]
    /// if it holds a `Ssml`, `None` if the field is not set or
    /// holds a different branch.
    pub fn ssml(&self) -> std::option::Option<&std::string::String> {
        #[allow(unreachable_patterns)]
        self.input_source.as_ref().and_then(|v| match v {
            crate::model::synthesis_input::InputSource::Ssml(v) => std::option::Option::Some(v),
            _ => std::option::Option::None,
        })
    }

    /// The value of [input_source][crate::model::SynthesisInput::input_source]
    /// if it holds a `MultiSpeakerMarkup`, `None` if the field is not set or
    /// holds a different branch.
    pub fn multi_speaker_markup(
        &self,
    ) -> std::option::Option<&std::boxed::Box<crate::model::MultiSpeakerMarkup>> {
        #[allow(unreachable_patterns)]
        self.input_source.as_ref().and_then(|v| match v {
            crate::model::synthesis_input::InputSource::MultiSpeakerMarkup(v) => {
                std::option::Option::Some(v)
            }
            _ => std::option::Option::None,
        })
    }

    /// Sets the value of [input_source][crate::model::SynthesisInput::input_source]
    /// to hold a `Text`.
    ///
    /// Note that all the setters affecting `input_source` are
    /// mutually exclusive.
    pub fn set_text<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.input_source =
            std::option::Option::Some(crate::model::synthesis_input::InputSource::Text(v.into()));
        self
    }

    /// Sets the value of [input_source][crate::model::SynthesisInput::input_source]
    /// to hold a `Ssml`.
    ///
    /// Note that all the setters affecting `input_source` are
    /// mutually exclusive.
    pub fn set_ssml<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.input_source =
            std::option::Option::Some(crate::model::synthesis_input::InputSource::Ssml(v.into()));
        self
    }

    /// Sets the value of [input_source][crate::model::SynthesisInput::input_source]
    /// to hold a `MultiSpeakerMarkup`.
    ///
    /// Note that all the setters affecting `input_source` are
    /// mutually exclusive.
    pub fn set_multi_speaker_markup<
        T: std::convert::Into<std::boxed::Box<crate::model::MultiSpeakerMarkup>>,
    >(
        mut self,
        v: T,
    ) -> Self {
        self.input_source = std::option::Option::Some(
            crate::model::synthesis_input::InputSource::MultiSpeakerMarkup(v.into()),
        );
        self
    }
}

impl wkt::message::Message for SynthesisInput {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.SynthesisInput"
    }
}

/// Defines additional types related to [SynthesisInput].
pub mod synthesis_input {
    #[allow(unused_imports)]
    use super::*;

    /// The input source, which is either plain text or SSML.
    #[derive(Clone, Debug, PartialEq, serde::Deserialize, serde::Serialize)]
    #[serde(rename_all = "camelCase")]
    #[non_exhaustive]
    pub enum InputSource {
        /// The raw text to be synthesized.
        Text(std::string::String),
        /// The SSML document to be synthesized. The SSML document must be valid
        /// and well-formed. Otherwise the RPC will fail and return
        /// [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]. For
        /// more information, see
        /// [SSML](https://cloud.google.com/text-to-speech/docs/ssml).
        Ssml(std::string::String),
        /// The multi-speaker input to be synthesized. Only applicable for
        /// multi-speaker synthesis.
        MultiSpeakerMarkup(std::boxed::Box<crate::model::MultiSpeakerMarkup>),
    }
}

/// Description of which voice to use for a synthesis request.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct VoiceSelectionParams {
    /// Required. The language (and potentially also the region) of the voice
    /// expressed as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt)
    /// language tag, e.g. "en-US". This should not include a script tag (e.g. use
    /// "cmn-cn" rather than "cmn-Hant-cn"), because the script will be inferred
    /// from the input provided in the SynthesisInput.  The TTS service
    /// will use this parameter to help choose an appropriate voice.  Note that
    /// the TTS service may choose a voice with a slightly different language code
    /// than the one selected; it may substitute a different region
    /// (e.g. using en-US rather than en-CA if there isn't a Canadian voice
    /// available), or even a different language, e.g. using "nb" (Norwegian
    /// Bokmal) instead of "no" (Norwegian)".
    #[serde(skip_serializing_if = "std::string::String::is_empty")]
    pub language_code: std::string::String,

    /// The name of the voice. If both the name and the gender are not set,
    /// the service will choose a voice based on the other parameters such as
    /// language_code.
    #[serde(skip_serializing_if = "std::string::String::is_empty")]
    pub name: std::string::String,

    /// The preferred gender of the voice. If not set, the service will
    /// choose a voice based on the other parameters such as language_code and
    /// name. Note that this is only a preference, not requirement; if a
    /// voice of the appropriate gender is not available, the synthesizer should
    /// substitute a voice with a different gender rather than failing the request.
    pub ssml_gender: crate::model::SsmlVoiceGender,

    /// The configuration for a custom voice. If [CustomVoiceParams.model] is set,
    /// the service will choose the custom voice matching the specified
    /// configuration.
    #[serde(skip_serializing_if = "std::option::Option::is_none")]
    pub custom_voice: std::option::Option<crate::model::CustomVoiceParams>,

    /// Optional. The configuration for a voice clone. If
    /// [VoiceCloneParams.voice_clone_key] is set, the service chooses the voice
    /// clone matching the specified configuration.
    #[serde(skip_serializing_if = "std::option::Option::is_none")]
    pub voice_clone: std::option::Option<crate::model::VoiceCloneParams>,

    #[serde(flatten, skip_serializing_if = "serde_json::Map::is_empty")]
    _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl VoiceSelectionParams {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [language_code][crate::model::VoiceSelectionParams::language_code].
    pub fn set_language_code<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.language_code = v.into();
        self
    }

    /// Sets the value of [name][crate::model::VoiceSelectionParams::name].
    pub fn set_name<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.name = v.into();
        self
    }

    /// Sets the value of [ssml_gender][crate::model::VoiceSelectionParams::ssml_gender].
    pub fn set_ssml_gender<T: std::convert::Into<crate::model::SsmlVoiceGender>>(
        mut self,
        v: T,
    ) -> Self {
        self.ssml_gender = v.into();
        self
    }

    /// Sets the value of [custom_voice][crate::model::VoiceSelectionParams::custom_voice].
    pub fn set_custom_voice<
        T: std::convert::Into<std::option::Option<crate::model::CustomVoiceParams>>,
    >(
        mut self,
        v: T,
    ) -> Self {
        self.custom_voice = v.into();
        self
    }

    /// Sets the value of [voice_clone][crate::model::VoiceSelectionParams::voice_clone].
    pub fn set_voice_clone<
        T: std::convert::Into<std::option::Option<crate::model::VoiceCloneParams>>,
    >(
        mut self,
        v: T,
    ) -> Self {
        self.voice_clone = v.into();
        self
    }
}

impl wkt::message::Message for VoiceSelectionParams {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.VoiceSelectionParams"
    }
}

/// Description of audio data to be synthesized.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct AudioConfig {
    /// Required. The format of the audio byte stream.
    pub audio_encoding: crate::model::AudioEncoding,

    /// Optional. Input only. Speaking rate/speed, in the range [0.25, 2.0]. 1.0 is
    /// the normal native speed supported by the specific voice. 2.0 is twice as
    /// fast, and 0.5 is half as fast. If unset(0.0), defaults to the native 1.0
    /// speed. Any other values < 0.25 or > 2.0 will return an error.
    #[serde(skip_serializing_if = "wkt::internal::is_default")]
    pub speaking_rate: f64,

    /// Optional. Input only. Speaking pitch, in the range [-20.0, 20.0]. 20 means
    /// increase 20 semitones from the original pitch. -20 means decrease 20
    /// semitones from the original pitch.
    #[serde(skip_serializing_if = "wkt::internal::is_default")]
    pub pitch: f64,

    /// Optional. Input only. Volume gain (in dB) of the normal native volume
    /// supported by the specific voice, in the range [-96.0, 16.0]. If unset, or
    /// set to a value of 0.0 (dB), will play at normal native signal amplitude. A
    /// value of -6.0 (dB) will play at approximately half the amplitude of the
    /// normal native signal amplitude. A value of +6.0 (dB) will play at
    /// approximately twice the amplitude of the normal native signal amplitude.
    /// Strongly recommend not to exceed +10 (dB) as there's usually no effective
    /// increase in loudness for any value greater than that.
    #[serde(skip_serializing_if = "wkt::internal::is_default")]
    pub volume_gain_db: f64,

    /// Optional. The synthesis sample rate (in hertz) for this audio. When this is
    /// specified in SynthesizeSpeechRequest, if this is different from the voice's
    /// natural sample rate, then the synthesizer will honor this request by
    /// converting to the desired sample rate (which might result in worse audio
    /// quality), unless the specified sample rate is not supported for the
    /// encoding chosen, in which case it will fail the request and return
    /// [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT].
    #[serde(skip_serializing_if = "wkt::internal::is_default")]
    pub sample_rate_hertz: i32,

    /// Optional. Input only. An identifier which selects 'audio effects' profiles
    /// that are applied on (post synthesized) text to speech. Effects are applied
    /// on top of each other in the order they are given. See
    /// [audio
    /// profiles](https://cloud.google.com/text-to-speech/docs/audio-profiles) for
    /// current supported profile ids.
    #[serde(skip_serializing_if = "std::vec::Vec::is_empty")]
    pub effects_profile_id: std::vec::Vec<std::string::String>,

    #[serde(flatten, skip_serializing_if = "serde_json::Map::is_empty")]
    _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl AudioConfig {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [audio_encoding][crate::model::AudioConfig::audio_encoding].
    pub fn set_audio_encoding<T: std::convert::Into<crate::model::AudioEncoding>>(
        mut self,
        v: T,
    ) -> Self {
        self.audio_encoding = v.into();
        self
    }

    /// Sets the value of [speaking_rate][crate::model::AudioConfig::speaking_rate].
    pub fn set_speaking_rate<T: std::convert::Into<f64>>(mut self, v: T) -> Self {
        self.speaking_rate = v.into();
        self
    }

    /// Sets the value of [pitch][crate::model::AudioConfig::pitch].
    pub fn set_pitch<T: std::convert::Into<f64>>(mut self, v: T) -> Self {
        self.pitch = v.into();
        self
    }

    /// Sets the value of [volume_gain_db][crate::model::AudioConfig::volume_gain_db].
    pub fn set_volume_gain_db<T: std::convert::Into<f64>>(mut self, v: T) -> Self {
        self.volume_gain_db = v.into();
        self
    }

    /// Sets the value of [sample_rate_hertz][crate::model::AudioConfig::sample_rate_hertz].
    pub fn set_sample_rate_hertz<T: std::convert::Into<i32>>(mut self, v: T) -> Self {
        self.sample_rate_hertz = v.into();
        self
    }

    /// Sets the value of [effects_profile_id][crate::model::AudioConfig::effects_profile_id].
    pub fn set_effects_profile_id<T, V>(mut self, v: T) -> Self
    where
        T: std::iter::IntoIterator<Item = V>,
        V: std::convert::Into<std::string::String>,
    {
        use std::iter::Iterator;
        self.effects_profile_id = v.into_iter().map(|i| i.into()).collect();
        self
    }
}

impl wkt::message::Message for AudioConfig {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.AudioConfig"
    }
}

/// Description of the custom voice to be synthesized.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct CustomVoiceParams {
    /// Required. The name of the AutoML model that synthesizes the custom voice.
    #[serde(skip_serializing_if = "std::string::String::is_empty")]
    pub model: std::string::String,

    /// Optional. Deprecated. The usage of the synthesized audio to be reported.
    #[deprecated]
    pub reported_usage: crate::model::custom_voice_params::ReportedUsage,

    #[serde(flatten, skip_serializing_if = "serde_json::Map::is_empty")]
    _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl CustomVoiceParams {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [model][crate::model::CustomVoiceParams::model].
    pub fn set_model<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.model = v.into();
        self
    }

    /// Sets the value of [reported_usage][crate::model::CustomVoiceParams::reported_usage].
    #[deprecated]
    pub fn set_reported_usage<
        T: std::convert::Into<crate::model::custom_voice_params::ReportedUsage>,
    >(
        mut self,
        v: T,
    ) -> Self {
        self.reported_usage = v.into();
        self
    }
}

impl wkt::message::Message for CustomVoiceParams {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.CustomVoiceParams"
    }
}

/// Defines additional types related to [CustomVoiceParams].
pub mod custom_voice_params {
    #[allow(unused_imports)]
    use super::*;

    /// Deprecated. The usage of the synthesized audio. Usage does not affect
    /// billing.
    ///
    /// # Working with unknown values
    ///
    /// This enum is defined as `#[non_exhaustive]` because Google Cloud may add
    /// additional enum variants at any time. Adding new variants is not considered
    /// a breaking change. Applications should write their code in anticipation of:
    ///
    /// - New values appearing in future releases of the client library, **and**
    /// - New values received dynamically, without application changes.
    ///
    /// Please consult the [Working with enums] section in the user guide for some
    /// guidelines.
    ///
    /// [Working with enums]: https://google-cloud-rust.github.io/working_with_enums.html
    #[derive(Clone, Debug, PartialEq)]
    #[non_exhaustive]
    pub enum ReportedUsage {
        /// Request with reported usage unspecified will be rejected.
        Unspecified,
        /// For scenarios where the synthesized audio is not downloadable and can
        /// only be used once. For example, real-time request in IVR system.
        Realtime,
        /// For scenarios where the synthesized audio is downloadable and can be
        /// reused. For example, the synthesized audio is downloaded, stored in
        /// customer service system and played repeatedly.
        Offline,
        /// If set, the enum was initialized with an unknown value.
        ///
        /// Applications can examine the value using [ReportedUsage::value] or
        /// [ReportedUsage::name].
        UnknownValue(reported_usage::UnknownValue),
    }

    #[doc(hidden)]
    pub mod reported_usage {
        #[allow(unused_imports)]
        use super::*;
        #[derive(Clone, Debug, PartialEq)]
        pub struct UnknownValue(pub(crate) wkt::internal::UnknownEnumValue);
    }

    impl ReportedUsage {
        /// Gets the enum value.
        ///
        /// Returns `None` if the enum contains an unknown value deserialized from
        /// the string representation of enums.
        pub fn value(&self) -> std::option::Option<i32> {
            match self {
                Self::Unspecified => std::option::Option::Some(0),
                Self::Realtime => std::option::Option::Some(1),
                Self::Offline => std::option::Option::Some(2),
                Self::UnknownValue(u) => u.0.value(),
            }
        }

        /// Gets the enum value as a string.
        ///
        /// Returns `None` if the enum contains an unknown value deserialized from
        /// the integer representation of enums.
        pub fn name(&self) -> std::option::Option<&str> {
            match self {
                Self::Unspecified => std::option::Option::Some("REPORTED_USAGE_UNSPECIFIED"),
                Self::Realtime => std::option::Option::Some("REALTIME"),
                Self::Offline => std::option::Option::Some("OFFLINE"),
                Self::UnknownValue(u) => u.0.name(),
            }
        }
    }

    impl std::default::Default for ReportedUsage {
        fn default() -> Self {
            use std::convert::From;
            Self::from(0)
        }
    }

    impl std::fmt::Display for ReportedUsage {
        fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::result::Result<(), std::fmt::Error> {
            wkt::internal::display_enum(f, self.name(), self.value())
        }
    }

    impl std::convert::From<i32> for ReportedUsage {
        fn from(value: i32) -> Self {
            match value {
                0 => Self::Unspecified,
                1 => Self::Realtime,
                2 => Self::Offline,
                _ => Self::UnknownValue(reported_usage::UnknownValue(
                    wkt::internal::UnknownEnumValue::Integer(value),
                )),
            }
        }
    }

    impl std::convert::From<&str> for ReportedUsage {
        fn from(value: &str) -> Self {
            use std::string::ToString;
            match value {
                "REPORTED_USAGE_UNSPECIFIED" => Self::Unspecified,
                "REALTIME" => Self::Realtime,
                "OFFLINE" => Self::Offline,
                _ => Self::UnknownValue(reported_usage::UnknownValue(
                    wkt::internal::UnknownEnumValue::String(value.to_string()),
                )),
            }
        }
    }

    impl serde::ser::Serialize for ReportedUsage {
        fn serialize<S>(&self, serializer: S) -> std::result::Result<S::Ok, S::Error>
        where
            S: serde::Serializer,
        {
            match self {
                Self::Unspecified => serializer.serialize_i32(0),
                Self::Realtime => serializer.serialize_i32(1),
                Self::Offline => serializer.serialize_i32(2),
                Self::UnknownValue(u) => u.0.serialize(serializer),
            }
        }
    }

    impl<'de> serde::de::Deserialize<'de> for ReportedUsage {
        fn deserialize<D>(deserializer: D) -> std::result::Result<Self, D::Error>
        where
            D: serde::Deserializer<'de>,
        {
            deserializer.deserialize_any(wkt::internal::EnumVisitor::<ReportedUsage>::new(
                ".google.cloud.texttospeech.v1.CustomVoiceParams.ReportedUsage",
            ))
        }
    }
}

/// The configuration of Voice Clone feature.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct VoiceCloneParams {
    /// Required. Created by GenerateVoiceCloningKey.
    #[serde(skip_serializing_if = "std::string::String::is_empty")]
    pub voice_cloning_key: std::string::String,

    #[serde(flatten, skip_serializing_if = "serde_json::Map::is_empty")]
    _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl VoiceCloneParams {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [voice_cloning_key][crate::model::VoiceCloneParams::voice_cloning_key].
    pub fn set_voice_cloning_key<T: std::convert::Into<std::string::String>>(
        mut self,
        v: T,
    ) -> Self {
        self.voice_cloning_key = v.into();
        self
    }
}

impl wkt::message::Message for VoiceCloneParams {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.VoiceCloneParams"
    }
}

/// The message returned to the client by the `SynthesizeSpeech` method.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct SynthesizeSpeechResponse {
    /// The audio data bytes encoded as specified in the request, including the
    /// header for encodings that are wrapped in containers (e.g. MP3, OGG_OPUS).
    /// For LINEAR16 audio, we include the WAV header. Note: as
    /// with all bytes fields, protobuffers use a pure binary representation,
    /// whereas JSON representations use base64.
    #[serde(skip_serializing_if = "::bytes::Bytes::is_empty")]
    #[serde_as(as = "serde_with::base64::Base64")]
    pub audio_content: ::bytes::Bytes,

    #[serde(flatten, skip_serializing_if = "serde_json::Map::is_empty")]
    _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl SynthesizeSpeechResponse {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [audio_content][crate::model::SynthesizeSpeechResponse::audio_content].
    pub fn set_audio_content<T: std::convert::Into<::bytes::Bytes>>(mut self, v: T) -> Self {
        self.audio_content = v.into();
        self
    }
}

impl wkt::message::Message for SynthesizeSpeechResponse {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.SynthesizeSpeechResponse"
    }
}

/// Description of the desired output audio data.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct StreamingAudioConfig {
    /// Required. The format of the audio byte stream.
    /// Streaming supports PCM, ALAW, MULAW and OGG_OPUS. All other encodings
    /// return an error.
    pub audio_encoding: crate::model::AudioEncoding,

    /// Optional. The synthesis sample rate (in hertz) for this audio.
    #[serde(skip_serializing_if = "wkt::internal::is_default")]
    pub sample_rate_hertz: i32,

    /// Optional. Input only. Speaking rate/speed, in the range [0.25, 2.0]. 1.0 is
    /// the normal native speed supported by the specific voice. 2.0 is twice as
    /// fast, and 0.5 is half as fast. If unset(0.0), defaults to the native 1.0
    /// speed. Any other values < 0.25 or > 2.0 will return an error.
    #[serde(skip_serializing_if = "wkt::internal::is_default")]
    pub speaking_rate: f64,

    #[serde(flatten, skip_serializing_if = "serde_json::Map::is_empty")]
    _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl StreamingAudioConfig {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [audio_encoding][crate::model::StreamingAudioConfig::audio_encoding].
    pub fn set_audio_encoding<T: std::convert::Into<crate::model::AudioEncoding>>(
        mut self,
        v: T,
    ) -> Self {
        self.audio_encoding = v.into();
        self
    }

    /// Sets the value of [sample_rate_hertz][crate::model::StreamingAudioConfig::sample_rate_hertz].
    pub fn set_sample_rate_hertz<T: std::convert::Into<i32>>(mut self, v: T) -> Self {
        self.sample_rate_hertz = v.into();
        self
    }

    /// Sets the value of [speaking_rate][crate::model::StreamingAudioConfig::speaking_rate].
    pub fn set_speaking_rate<T: std::convert::Into<f64>>(mut self, v: T) -> Self {
        self.speaking_rate = v.into();
        self
    }
}

impl wkt::message::Message for StreamingAudioConfig {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.StreamingAudioConfig"
    }
}

/// Provides configuration information for the StreamingSynthesize request.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct StreamingSynthesizeConfig {
    /// Required. The desired voice of the synthesized audio.
    #[serde(skip_serializing_if = "std::option::Option::is_none")]
    pub voice: std::option::Option<crate::model::VoiceSelectionParams>,

    /// Optional. The configuration of the synthesized audio.
    #[serde(skip_serializing_if = "std::option::Option::is_none")]
    pub streaming_audio_config: std::option::Option<crate::model::StreamingAudioConfig>,

    /// Optional. The pronunciation customizations are applied to the input. If
    /// this is set, the input is synthesized using the given pronunciation
    /// customizations.
    ///
    /// The initial support is for en-us, with plans to expand to other locales in
    /// the future. Instant Clone voices aren't supported.
    ///
    /// In order to customize the pronunciation of a phrase, there must be an exact
    /// match of the phrase in the input types. If using SSML, the phrase must not
    /// be inside a phoneme tag.
    #[serde(skip_serializing_if = "std::option::Option::is_none")]
    pub custom_pronunciations: std::option::Option<crate::model::CustomPronunciations>,

    #[serde(flatten, skip_serializing_if = "serde_json::Map::is_empty")]
    _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl StreamingSynthesizeConfig {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [voice][crate::model::StreamingSynthesizeConfig::voice].
    pub fn set_voice<
        T: std::convert::Into<std::option::Option<crate::model::VoiceSelectionParams>>,
    >(
        mut self,
        v: T,
    ) -> Self {
        self.voice = v.into();
        self
    }

    /// Sets the value of [streaming_audio_config][crate::model::StreamingSynthesizeConfig::streaming_audio_config].
    pub fn set_streaming_audio_config<
        T: std::convert::Into<std::option::Option<crate::model::StreamingAudioConfig>>,
    >(
        mut self,
        v: T,
    ) -> Self {
        self.streaming_audio_config = v.into();
        self
    }

    /// Sets the value of [custom_pronunciations][crate::model::StreamingSynthesizeConfig::custom_pronunciations].
    pub fn set_custom_pronunciations<
        T: std::convert::Into<std::option::Option<crate::model::CustomPronunciations>>,
    >(
        mut self,
        v: T,
    ) -> Self {
        self.custom_pronunciations = v.into();
        self
    }
}

impl wkt::message::Message for StreamingSynthesizeConfig {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.StreamingSynthesizeConfig"
    }
}

/// Input to be synthesized.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct StreamingSynthesisInput {
    #[serde(flatten, skip_serializing_if = "std::option::Option::is_none")]
    pub input_source: std::option::Option<crate::model::streaming_synthesis_input::InputSource>,

    #[serde(flatten, skip_serializing_if = "serde_json::Map::is_empty")]
    _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl StreamingSynthesisInput {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [input_source][crate::model::StreamingSynthesisInput::input_source].
    ///
    /// Note that all the setters affecting `input_source` are mutually
    /// exclusive.
    pub fn set_input_source<
        T: std::convert::Into<
                std::option::Option<crate::model::streaming_synthesis_input::InputSource>,
            >,
    >(
        mut self,
        v: T,
    ) -> Self {
        self.input_source = v.into();
        self
    }

    /// The value of [input_source][crate::model::StreamingSynthesisInput::input_source]
    /// if it holds a `Text`, `None` if the field is not set or
    /// holds a different branch.
    pub fn text(&self) -> std::option::Option<&std::string::String> {
        #[allow(unreachable_patterns)]
        self.input_source.as_ref().and_then(|v| match v {
            crate::model::streaming_synthesis_input::InputSource::Text(v) => {
                std::option::Option::Some(v)
            }
            _ => std::option::Option::None,
        })
    }

    /// Sets the value of [input_source][crate::model::StreamingSynthesisInput::input_source]
    /// to hold a `Text`.
    ///
    /// Note that all the setters affecting `input_source` are
    /// mutually exclusive.
    pub fn set_text<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.input_source = std::option::Option::Some(
            crate::model::streaming_synthesis_input::InputSource::Text(v.into()),
        );
        self
    }
}

impl wkt::message::Message for StreamingSynthesisInput {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.StreamingSynthesisInput"
    }
}

/// Defines additional types related to [StreamingSynthesisInput].
pub mod streaming_synthesis_input {
    #[allow(unused_imports)]
    use super::*;

    #[derive(Clone, Debug, PartialEq, serde::Deserialize, serde::Serialize)]
    #[serde(rename_all = "camelCase")]
    #[non_exhaustive]
    pub enum InputSource {
        /// The raw text to be synthesized. It is recommended that each input
        /// contains complete, terminating sentences, which results in better prosody
        /// in the output audio.
        Text(std::string::String),
    }
}

/// Request message for the `StreamingSynthesize` method. Multiple
/// `StreamingSynthesizeRequest` messages are sent in one call.
/// The first message must contain a `streaming_config` that
/// fully specifies the request configuration and must not contain `input`. All
/// subsequent messages must only have `input` set.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct StreamingSynthesizeRequest {
    /// The request to be sent, either a StreamingSynthesizeConfig or
    /// StreamingSynthesisInput.
    #[serde(flatten, skip_serializing_if = "std::option::Option::is_none")]
    pub streaming_request:
        std::option::Option<crate::model::streaming_synthesize_request::StreamingRequest>,

    #[serde(flatten, skip_serializing_if = "serde_json::Map::is_empty")]
    _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl StreamingSynthesizeRequest {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [streaming_request][crate::model::StreamingSynthesizeRequest::streaming_request].
    ///
    /// Note that all the setters affecting `streaming_request` are mutually
    /// exclusive.
    pub fn set_streaming_request<
        T: std::convert::Into<
                std::option::Option<crate::model::streaming_synthesize_request::StreamingRequest>,
            >,
    >(
        mut self,
        v: T,
    ) -> Self {
        self.streaming_request = v.into();
        self
    }

    /// The value of [streaming_request][crate::model::StreamingSynthesizeRequest::streaming_request]
    /// if it holds a `StreamingConfig`, `None` if the field is not set or
    /// holds a different branch.
    pub fn streaming_config(
        &self,
    ) -> std::option::Option<&std::boxed::Box<crate::model::StreamingSynthesizeConfig>> {
        #[allow(unreachable_patterns)]
        self.streaming_request.as_ref().and_then(|v| match v {
            crate::model::streaming_synthesize_request::StreamingRequest::StreamingConfig(v) => {
                std::option::Option::Some(v)
            }
            _ => std::option::Option::None,
        })
    }

    /// The value of [streaming_request][crate::model::StreamingSynthesizeRequest::streaming_request]
    /// if it holds a `Input`, `None` if the field is not set or
    /// holds a different branch.
    pub fn input(
        &self,
    ) -> std::option::Option<&std::boxed::Box<crate::model::StreamingSynthesisInput>> {
        #[allow(unreachable_patterns)]
        self.streaming_request.as_ref().and_then(|v| match v {
            crate::model::streaming_synthesize_request::StreamingRequest::Input(v) => {
                std::option::Option::Some(v)
            }
            _ => std::option::Option::None,
        })
    }

    /// Sets the value of [streaming_request][crate::model::StreamingSynthesizeRequest::streaming_request]
    /// to hold a `StreamingConfig`.
    ///
    /// Note that all the setters affecting `streaming_request` are
    /// mutually exclusive.
    pub fn set_streaming_config<
        T: std::convert::Into<std::boxed::Box<crate::model::StreamingSynthesizeConfig>>,
    >(
        mut self,
        v: T,
    ) -> Self {
        self.streaming_request = std::option::Option::Some(
            crate::model::streaming_synthesize_request::StreamingRequest::StreamingConfig(v.into()),
        );
        self
    }

    /// Sets the value of [streaming_request][crate::model::StreamingSynthesizeRequest::streaming_request]
    /// to hold a `Input`.
    ///
    /// Note that all the setters affecting `streaming_request` are
    /// mutually exclusive.
    pub fn set_input<
        T: std::convert::Into<std::boxed::Box<crate::model::StreamingSynthesisInput>>,
    >(
        mut self,
        v: T,
    ) -> Self {
        self.streaming_request = std::option::Option::Some(
            crate::model::streaming_synthesize_request::StreamingRequest::Input(v.into()),
        );
        self
    }
}

impl wkt::message::Message for StreamingSynthesizeRequest {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.StreamingSynthesizeRequest"
    }
}

/// Defines additional types related to [StreamingSynthesizeRequest].
pub mod streaming_synthesize_request {
    #[allow(unused_imports)]
    use super::*;

    /// The request to be sent, either a StreamingSynthesizeConfig or
    /// StreamingSynthesisInput.
    #[derive(Clone, Debug, PartialEq, serde::Deserialize, serde::Serialize)]
    #[serde(rename_all = "camelCase")]
    #[non_exhaustive]
    pub enum StreamingRequest {
        /// StreamingSynthesizeConfig to be used in this streaming attempt. Only
        /// specified in the first message sent in a `StreamingSynthesize` call.
        StreamingConfig(std::boxed::Box<crate::model::StreamingSynthesizeConfig>),
        /// Input to synthesize. Specified in all messages but the first in a
        /// `StreamingSynthesize` call.
        Input(std::boxed::Box<crate::model::StreamingSynthesisInput>),
    }
}

/// `StreamingSynthesizeResponse` is the only message returned to the
/// client by `StreamingSynthesize` method. A series of zero or more
/// `StreamingSynthesizeResponse` messages are streamed back to the client.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct StreamingSynthesizeResponse {
    /// The audio data bytes encoded as specified in the request. This is
    /// headerless LINEAR16 audio with a sample rate of 24000.
    #[serde(skip_serializing_if = "::bytes::Bytes::is_empty")]
    #[serde_as(as = "serde_with::base64::Base64")]
    pub audio_content: ::bytes::Bytes,

    #[serde(flatten, skip_serializing_if = "serde_json::Map::is_empty")]
    _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl StreamingSynthesizeResponse {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [audio_content][crate::model::StreamingSynthesizeResponse::audio_content].
    pub fn set_audio_content<T: std::convert::Into<::bytes::Bytes>>(mut self, v: T) -> Self {
        self.audio_content = v.into();
        self
    }
}

impl wkt::message::Message for StreamingSynthesizeResponse {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.StreamingSynthesizeResponse"
    }
}

/// The top-level message sent by the client for the
/// `SynthesizeLongAudio` method.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct SynthesizeLongAudioRequest {
    /// The resource states of the request in the form of
    /// `projects/*/locations/*`.
    #[serde(skip_serializing_if = "std::string::String::is_empty")]
    pub parent: std::string::String,

    /// Required. The Synthesizer requires either plain text or SSML as input.
    #[serde(skip_serializing_if = "std::option::Option::is_none")]
    pub input: std::option::Option<crate::model::SynthesisInput>,

    /// Required. The configuration of the synthesized audio.
    #[serde(skip_serializing_if = "std::option::Option::is_none")]
    pub audio_config: std::option::Option<crate::model::AudioConfig>,

    /// Required. Specifies a Cloud Storage URI for the synthesis results. Must be
    /// specified in the format: `gs://bucket_name/object_name`, and the bucket
    /// must already exist.
    #[serde(skip_serializing_if = "std::string::String::is_empty")]
    pub output_gcs_uri: std::string::String,

    /// Required. The desired voice of the synthesized audio.
    #[serde(skip_serializing_if = "std::option::Option::is_none")]
    pub voice: std::option::Option<crate::model::VoiceSelectionParams>,

    #[serde(flatten, skip_serializing_if = "serde_json::Map::is_empty")]
    _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl SynthesizeLongAudioRequest {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [parent][crate::model::SynthesizeLongAudioRequest::parent].
    pub fn set_parent<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.parent = v.into();
        self
    }

    /// Sets the value of [input][crate::model::SynthesizeLongAudioRequest::input].
    pub fn set_input<T: std::convert::Into<std::option::Option<crate::model::SynthesisInput>>>(
        mut self,
        v: T,
    ) -> Self {
        self.input = v.into();
        self
    }

    /// Sets the value of [audio_config][crate::model::SynthesizeLongAudioRequest::audio_config].
    pub fn set_audio_config<
        T: std::convert::Into<std::option::Option<crate::model::AudioConfig>>,
    >(
        mut self,
        v: T,
    ) -> Self {
        self.audio_config = v.into();
        self
    }

    /// Sets the value of [output_gcs_uri][crate::model::SynthesizeLongAudioRequest::output_gcs_uri].
    pub fn set_output_gcs_uri<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.output_gcs_uri = v.into();
        self
    }

    /// Sets the value of [voice][crate::model::SynthesizeLongAudioRequest::voice].
    pub fn set_voice<
        T: std::convert::Into<std::option::Option<crate::model::VoiceSelectionParams>>,
    >(
        mut self,
        v: T,
    ) -> Self {
        self.voice = v.into();
        self
    }
}

impl wkt::message::Message for SynthesizeLongAudioRequest {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.SynthesizeLongAudioRequest"
    }
}

/// The message returned to the client by the `SynthesizeLongAudio` method.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct SynthesizeLongAudioResponse {
    #[serde(flatten, skip_serializing_if = "serde_json::Map::is_empty")]
    _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl SynthesizeLongAudioResponse {
    pub fn new() -> Self {
        std::default::Default::default()
    }
}

impl wkt::message::Message for SynthesizeLongAudioResponse {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.SynthesizeLongAudioResponse"
    }
}

/// Metadata for response returned by the `SynthesizeLongAudio` method.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct SynthesizeLongAudioMetadata {
    /// Time when the request was received.
    #[serde(skip_serializing_if = "std::option::Option::is_none")]
    pub start_time: std::option::Option<wkt::Timestamp>,

    /// Deprecated. Do not use.
    #[serde(skip_serializing_if = "std::option::Option::is_none")]
    #[deprecated]
    pub last_update_time: std::option::Option<wkt::Timestamp>,

    /// The progress of the most recent processing update in percentage, ie. 70.0%.
    #[serde(skip_serializing_if = "wkt::internal::is_default")]
    pub progress_percentage: f64,

    #[serde(flatten, skip_serializing_if = "serde_json::Map::is_empty")]
    _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl SynthesizeLongAudioMetadata {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [start_time][crate::model::SynthesizeLongAudioMetadata::start_time].
    pub fn set_start_time<T: std::convert::Into<std::option::Option<wkt::Timestamp>>>(
        mut self,
        v: T,
    ) -> Self {
        self.start_time = v.into();
        self
    }

    /// Sets the value of [last_update_time][crate::model::SynthesizeLongAudioMetadata::last_update_time].
    #[deprecated]
    pub fn set_last_update_time<T: std::convert::Into<std::option::Option<wkt::Timestamp>>>(
        mut self,
        v: T,
    ) -> Self {
        self.last_update_time = v.into();
        self
    }

    /// Sets the value of [progress_percentage][crate::model::SynthesizeLongAudioMetadata::progress_percentage].
    pub fn set_progress_percentage<T: std::convert::Into<f64>>(mut self, v: T) -> Self {
        self.progress_percentage = v.into();
        self
    }
}

impl wkt::message::Message for SynthesizeLongAudioMetadata {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.SynthesizeLongAudioMetadata"
    }
}

/// Gender of the voice as described in
/// [SSML voice element](https://www.w3.org/TR/speech-synthesis11/#edef_voice).
///
/// # Working with unknown values
///
/// This enum is defined as `#[non_exhaustive]` because Google Cloud may add
/// additional enum variants at any time. Adding new variants is not considered
/// a breaking change. Applications should write their code in anticipation of:
///
/// - New values appearing in future releases of the client library, **and**
/// - New values received dynamically, without application changes.
///
/// Please consult the [Working with enums] section in the user guide for some
/// guidelines.
///
/// [Working with enums]: https://google-cloud-rust.github.io/working_with_enums.html
#[derive(Clone, Debug, PartialEq)]
#[non_exhaustive]
pub enum SsmlVoiceGender {
    /// An unspecified gender.
    /// In VoiceSelectionParams, this means that the client doesn't care which
    /// gender the selected voice will have. In the Voice field of
    /// ListVoicesResponse, this may mean that the voice doesn't fit any of the
    /// other categories in this enum, or that the gender of the voice isn't known.
    Unspecified,
    /// A male voice.
    Male,
    /// A female voice.
    Female,
    /// A gender-neutral voice. This voice is not yet supported.
    Neutral,
    /// If set, the enum was initialized with an unknown value.
    ///
    /// Applications can examine the value using [SsmlVoiceGender::value] or
    /// [SsmlVoiceGender::name].
    UnknownValue(ssml_voice_gender::UnknownValue),
}

#[doc(hidden)]
pub mod ssml_voice_gender {
    #[allow(unused_imports)]
    use super::*;
    #[derive(Clone, Debug, PartialEq)]
    pub struct UnknownValue(pub(crate) wkt::internal::UnknownEnumValue);
}

impl SsmlVoiceGender {
    /// Gets the enum value.
    ///
    /// Returns `None` if the enum contains an unknown value deserialized from
    /// the string representation of enums.
    pub fn value(&self) -> std::option::Option<i32> {
        match self {
            Self::Unspecified => std::option::Option::Some(0),
            Self::Male => std::option::Option::Some(1),
            Self::Female => std::option::Option::Some(2),
            Self::Neutral => std::option::Option::Some(3),
            Self::UnknownValue(u) => u.0.value(),
        }
    }

    /// Gets the enum value as a string.
    ///
    /// Returns `None` if the enum contains an unknown value deserialized from
    /// the integer representation of enums.
    pub fn name(&self) -> std::option::Option<&str> {
        match self {
            Self::Unspecified => std::option::Option::Some("SSML_VOICE_GENDER_UNSPECIFIED"),
            Self::Male => std::option::Option::Some("MALE"),
            Self::Female => std::option::Option::Some("FEMALE"),
            Self::Neutral => std::option::Option::Some("NEUTRAL"),
            Self::UnknownValue(u) => u.0.name(),
        }
    }
}

impl std::default::Default for SsmlVoiceGender {
    fn default() -> Self {
        use std::convert::From;
        Self::from(0)
    }
}

impl std::fmt::Display for SsmlVoiceGender {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::result::Result<(), std::fmt::Error> {
        wkt::internal::display_enum(f, self.name(), self.value())
    }
}

impl std::convert::From<i32> for SsmlVoiceGender {
    fn from(value: i32) -> Self {
        match value {
            0 => Self::Unspecified,
            1 => Self::Male,
            2 => Self::Female,
            3 => Self::Neutral,
            _ => Self::UnknownValue(ssml_voice_gender::UnknownValue(
                wkt::internal::UnknownEnumValue::Integer(value),
            )),
        }
    }
}

impl std::convert::From<&str> for SsmlVoiceGender {
    fn from(value: &str) -> Self {
        use std::string::ToString;
        match value {
            "SSML_VOICE_GENDER_UNSPECIFIED" => Self::Unspecified,
            "MALE" => Self::Male,
            "FEMALE" => Self::Female,
            "NEUTRAL" => Self::Neutral,
            _ => Self::UnknownValue(ssml_voice_gender::UnknownValue(
                wkt::internal::UnknownEnumValue::String(value.to_string()),
            )),
        }
    }
}

impl serde::ser::Serialize for SsmlVoiceGender {
    fn serialize<S>(&self, serializer: S) -> std::result::Result<S::Ok, S::Error>
    where
        S: serde::Serializer,
    {
        match self {
            Self::Unspecified => serializer.serialize_i32(0),
            Self::Male => serializer.serialize_i32(1),
            Self::Female => serializer.serialize_i32(2),
            Self::Neutral => serializer.serialize_i32(3),
            Self::UnknownValue(u) => u.0.serialize(serializer),
        }
    }
}

impl<'de> serde::de::Deserialize<'de> for SsmlVoiceGender {
    fn deserialize<D>(deserializer: D) -> std::result::Result<Self, D::Error>
    where
        D: serde::Deserializer<'de>,
    {
        deserializer.deserialize_any(wkt::internal::EnumVisitor::<SsmlVoiceGender>::new(
            ".google.cloud.texttospeech.v1.SsmlVoiceGender",
        ))
    }
}

/// Configuration to set up audio encoder. The encoding determines the output
/// audio format that we'd like.
///
/// # Working with unknown values
///
/// This enum is defined as `#[non_exhaustive]` because Google Cloud may add
/// additional enum variants at any time. Adding new variants is not considered
/// a breaking change. Applications should write their code in anticipation of:
///
/// - New values appearing in future releases of the client library, **and**
/// - New values received dynamically, without application changes.
///
/// Please consult the [Working with enums] section in the user guide for some
/// guidelines.
///
/// [Working with enums]: https://google-cloud-rust.github.io/working_with_enums.html
#[derive(Clone, Debug, PartialEq)]
#[non_exhaustive]
pub enum AudioEncoding {
    /// Not specified. Will return result
    /// [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT].
    Unspecified,
    /// Uncompressed 16-bit signed little-endian samples (Linear PCM).
    /// Audio content returned as LINEAR16 also contains a WAV header.
    Linear16,
    /// MP3 audio at 32kbps.
    Mp3,
    /// Opus encoded audio wrapped in an ogg container. The result is a
    /// file which can be played natively on Android, and in browsers (at least
    /// Chrome and Firefox). The quality of the encoding is considerably higher
    /// than MP3 while using approximately the same bitrate.
    OggOpus,
    /// 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
    /// Audio content returned as MULAW also contains a WAV header.
    Mulaw,
    /// 8-bit samples that compand 14-bit audio samples using G.711 PCMU/A-law.
    /// Audio content returned as ALAW also contains a WAV header.
    Alaw,
    /// Uncompressed 16-bit signed little-endian samples (Linear PCM).
    /// Note that as opposed to LINEAR16, audio won't be wrapped in a WAV (or
    /// any other) header.
    Pcm,
    /// If set, the enum was initialized with an unknown value.
    ///
    /// Applications can examine the value using [AudioEncoding::value] or
    /// [AudioEncoding::name].
    UnknownValue(audio_encoding::UnknownValue),
}

#[doc(hidden)]
pub mod audio_encoding {
    #[allow(unused_imports)]
    use super::*;
    #[derive(Clone, Debug, PartialEq)]
    pub struct UnknownValue(pub(crate) wkt::internal::UnknownEnumValue);
}

impl AudioEncoding {
    /// Gets the enum value.
    ///
    /// Returns `None` if the enum contains an unknown value deserialized from
    /// the string representation of enums.
    pub fn value(&self) -> std::option::Option<i32> {
        match self {
            Self::Unspecified => std::option::Option::Some(0),
            Self::Linear16 => std::option::Option::Some(1),
            Self::Mp3 => std::option::Option::Some(2),
            Self::OggOpus => std::option::Option::Some(3),
            Self::Mulaw => std::option::Option::Some(5),
            Self::Alaw => std::option::Option::Some(6),
            Self::Pcm => std::option::Option::Some(7),
            Self::UnknownValue(u) => u.0.value(),
        }
    }

    /// Gets the enum value as a string.
    ///
    /// Returns `None` if the enum contains an unknown value deserialized from
    /// the integer representation of enums.
    pub fn name(&self) -> std::option::Option<&str> {
        match self {
            Self::Unspecified => std::option::Option::Some("AUDIO_ENCODING_UNSPECIFIED"),
            Self::Linear16 => std::option::Option::Some("LINEAR16"),
            Self::Mp3 => std::option::Option::Some("MP3"),
            Self::OggOpus => std::option::Option::Some("OGG_OPUS"),
            Self::Mulaw => std::option::Option::Some("MULAW"),
            Self::Alaw => std::option::Option::Some("ALAW"),
            Self::Pcm => std::option::Option::Some("PCM"),
            Self::UnknownValue(u) => u.0.name(),
        }
    }
}

impl std::default::Default for AudioEncoding {
    fn default() -> Self {
        use std::convert::From;
        Self::from(0)
    }
}

impl std::fmt::Display for AudioEncoding {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::result::Result<(), std::fmt::Error> {
        wkt::internal::display_enum(f, self.name(), self.value())
    }
}

impl std::convert::From<i32> for AudioEncoding {
    fn from(value: i32) -> Self {
        match value {
            0 => Self::Unspecified,
            1 => Self::Linear16,
            2 => Self::Mp3,
            3 => Self::OggOpus,
            5 => Self::Mulaw,
            6 => Self::Alaw,
            7 => Self::Pcm,
            _ => Self::UnknownValue(audio_encoding::UnknownValue(
                wkt::internal::UnknownEnumValue::Integer(value),
            )),
        }
    }
}

impl std::convert::From<&str> for AudioEncoding {
    fn from(value: &str) -> Self {
        use std::string::ToString;
        match value {
            "AUDIO_ENCODING_UNSPECIFIED" => Self::Unspecified,
            "LINEAR16" => Self::Linear16,
            "MP3" => Self::Mp3,
            "OGG_OPUS" => Self::OggOpus,
            "MULAW" => Self::Mulaw,
            "ALAW" => Self::Alaw,
            "PCM" => Self::Pcm,
            _ => Self::UnknownValue(audio_encoding::UnknownValue(
                wkt::internal::UnknownEnumValue::String(value.to_string()),
            )),
        }
    }
}

impl serde::ser::Serialize for AudioEncoding {
    fn serialize<S>(&self, serializer: S) -> std::result::Result<S::Ok, S::Error>
    where
        S: serde::Serializer,
    {
        match self {
            Self::Unspecified => serializer.serialize_i32(0),
            Self::Linear16 => serializer.serialize_i32(1),
            Self::Mp3 => serializer.serialize_i32(2),
            Self::OggOpus => serializer.serialize_i32(3),
            Self::Mulaw => serializer.serialize_i32(5),
            Self::Alaw => serializer.serialize_i32(6),
            Self::Pcm => serializer.serialize_i32(7),
            Self::UnknownValue(u) => u.0.serialize(serializer),
        }
    }
}

impl<'de> serde::de::Deserialize<'de> for AudioEncoding {
    fn deserialize<D>(deserializer: D) -> std::result::Result<Self, D::Error>
    where
        D: serde::Deserializer<'de>,
    {
        deserializer.deserialize_any(wkt::internal::EnumVisitor::<AudioEncoding>::new(
            ".google.cloud.texttospeech.v1.AudioEncoding",
        ))
    }
}
