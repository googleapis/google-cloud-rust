// Copyright 2025 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     https://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//
// Code generated by sidekick. DO NOT EDIT.

#![allow(rustdoc::redundant_explicit_links)]
#![allow(rustdoc::broken_intra_doc_links)]
#![no_implicit_prelude]
extern crate async_trait;
extern crate bytes;
extern crate gax;
extern crate lazy_static;
extern crate longrunning;
extern crate lro;
extern crate reqwest;
extern crate serde;
extern crate serde_json;
extern crate serde_with;
extern crate std;
extern crate tracing;
extern crate wkt;

/// The top-level message sent by the client for the `ListVoices` method.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct ListVoicesRequest {
    /// Optional. Recommended.
    /// [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.
    /// If not specified, the API will return all supported voices.
    /// If specified, the ListVoices call will only return voices that can be used
    /// to synthesize this language_code. For example, if you specify `"en-NZ"`,
    /// all `"en-NZ"` voices will be returned. If you specify `"no"`, both
    /// `"no-\*"` (Norwegian) and `"nb-\*"` (Norwegian Bokmal) voices will be
    /// returned.
    #[serde(skip_serializing_if = "std::string::String::is_empty")]
    pub language_code: std::string::String,
}

impl ListVoicesRequest {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [language_code][crate::model::ListVoicesRequest::language_code].
    pub fn set_language_code<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.language_code = v.into();
        self
    }
}

impl wkt::message::Message for ListVoicesRequest {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.ListVoicesRequest"
    }
}

/// The message returned to the client by the `ListVoices` method.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct ListVoicesResponse {
    /// The list of voices.
    #[serde(skip_serializing_if = "std::vec::Vec::is_empty")]
    pub voices: std::vec::Vec<crate::model::Voice>,
}

impl ListVoicesResponse {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [voices][crate::model::ListVoicesResponse::voices].
    pub fn set_voices<T, V>(mut self, v: T) -> Self
    where
        T: std::iter::IntoIterator<Item = V>,
        V: std::convert::Into<crate::model::Voice>,
    {
        use std::iter::Iterator;
        self.voices = v.into_iter().map(|i| i.into()).collect();
        self
    }
}

impl wkt::message::Message for ListVoicesResponse {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.ListVoicesResponse"
    }
}

/// Description of a voice supported by the TTS service.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct Voice {
    /// The languages that this voice supports, expressed as
    /// [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tags (e.g.
    /// "en-US", "es-419", "cmn-tw").
    #[serde(skip_serializing_if = "std::vec::Vec::is_empty")]
    pub language_codes: std::vec::Vec<std::string::String>,

    /// The name of this voice.  Each distinct voice has a unique name.
    #[serde(skip_serializing_if = "std::string::String::is_empty")]
    pub name: std::string::String,

    /// The gender of this voice.
    pub ssml_gender: crate::model::SsmlVoiceGender,

    /// The natural sample rate (in hertz) for this voice.
    pub natural_sample_rate_hertz: i32,
}

impl Voice {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [name][crate::model::Voice::name].
    pub fn set_name<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.name = v.into();
        self
    }

    /// Sets the value of [ssml_gender][crate::model::Voice::ssml_gender].
    pub fn set_ssml_gender<T: std::convert::Into<crate::model::SsmlVoiceGender>>(
        mut self,
        v: T,
    ) -> Self {
        self.ssml_gender = v.into();
        self
    }

    /// Sets the value of [natural_sample_rate_hertz][crate::model::Voice::natural_sample_rate_hertz].
    pub fn set_natural_sample_rate_hertz<T: std::convert::Into<i32>>(mut self, v: T) -> Self {
        self.natural_sample_rate_hertz = v.into();
        self
    }

    /// Sets the value of [language_codes][crate::model::Voice::language_codes].
    pub fn set_language_codes<T, V>(mut self, v: T) -> Self
    where
        T: std::iter::IntoIterator<Item = V>,
        V: std::convert::Into<std::string::String>,
    {
        use std::iter::Iterator;
        self.language_codes = v.into_iter().map(|i| i.into()).collect();
        self
    }
}

impl wkt::message::Message for Voice {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.Voice"
    }
}

/// Used for advanced voice options.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct AdvancedVoiceOptions {
    /// Only for Journey voices. If false, the synthesis will be context aware
    /// and have higher latency.
    #[serde(skip_serializing_if = "std::option::Option::is_none")]
    pub low_latency_journey_synthesis: std::option::Option<bool>,
}

impl AdvancedVoiceOptions {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [low_latency_journey_synthesis][crate::model::AdvancedVoiceOptions::low_latency_journey_synthesis].
    pub fn set_low_latency_journey_synthesis<T: std::convert::Into<std::option::Option<bool>>>(
        mut self,
        v: T,
    ) -> Self {
        self.low_latency_journey_synthesis = v.into();
        self
    }
}

impl wkt::message::Message for AdvancedVoiceOptions {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.AdvancedVoiceOptions"
    }
}

/// The top-level message sent by the client for the `SynthesizeSpeech` method.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct SynthesizeSpeechRequest {
    /// Required. The Synthesizer requires either plain text or SSML as input.
    #[serde(skip_serializing_if = "std::option::Option::is_none")]
    pub input: std::option::Option<crate::model::SynthesisInput>,

    /// Required. The desired voice of the synthesized audio.
    #[serde(skip_serializing_if = "std::option::Option::is_none")]
    pub voice: std::option::Option<crate::model::VoiceSelectionParams>,

    /// Required. The configuration of the synthesized audio.
    #[serde(skip_serializing_if = "std::option::Option::is_none")]
    pub audio_config: std::option::Option<crate::model::AudioConfig>,

    /// Advanced voice options.
    #[serde(skip_serializing_if = "std::option::Option::is_none")]
    pub advanced_voice_options: std::option::Option<crate::model::AdvancedVoiceOptions>,
}

impl SynthesizeSpeechRequest {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [input][crate::model::SynthesizeSpeechRequest::input].
    pub fn set_input<T: std::convert::Into<std::option::Option<crate::model::SynthesisInput>>>(
        mut self,
        v: T,
    ) -> Self {
        self.input = v.into();
        self
    }

    /// Sets the value of [voice][crate::model::SynthesizeSpeechRequest::voice].
    pub fn set_voice<
        T: std::convert::Into<std::option::Option<crate::model::VoiceSelectionParams>>,
    >(
        mut self,
        v: T,
    ) -> Self {
        self.voice = v.into();
        self
    }

    /// Sets the value of [audio_config][crate::model::SynthesizeSpeechRequest::audio_config].
    pub fn set_audio_config<
        T: std::convert::Into<std::option::Option<crate::model::AudioConfig>>,
    >(
        mut self,
        v: T,
    ) -> Self {
        self.audio_config = v.into();
        self
    }

    /// Sets the value of [advanced_voice_options][crate::model::SynthesizeSpeechRequest::advanced_voice_options].
    pub fn set_advanced_voice_options<
        T: std::convert::Into<std::option::Option<crate::model::AdvancedVoiceOptions>>,
    >(
        mut self,
        v: T,
    ) -> Self {
        self.advanced_voice_options = v.into();
        self
    }
}

impl wkt::message::Message for SynthesizeSpeechRequest {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.SynthesizeSpeechRequest"
    }
}

/// Pronunciation customization for a phrase.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct CustomPronunciationParams {
    /// The phrase to which the customization will be applied.
    /// The phrase can be multiple words (in the case of proper nouns etc), but
    /// should not span to a whole sentence.
    #[serde(skip_serializing_if = "std::option::Option::is_none")]
    pub phrase: std::option::Option<std::string::String>,

    /// The phonetic encoding of the phrase.
    #[serde(skip_serializing_if = "std::option::Option::is_none")]
    pub phonetic_encoding:
        std::option::Option<crate::model::custom_pronunciation_params::PhoneticEncoding>,

    /// The pronunciation of the phrase. This must be in the phonetic encoding
    /// specified above.
    #[serde(skip_serializing_if = "std::option::Option::is_none")]
    pub pronunciation: std::option::Option<std::string::String>,
}

impl CustomPronunciationParams {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [phrase][crate::model::CustomPronunciationParams::phrase].
    pub fn set_phrase<T: std::convert::Into<std::option::Option<std::string::String>>>(
        mut self,
        v: T,
    ) -> Self {
        self.phrase = v.into();
        self
    }

    /// Sets the value of [phonetic_encoding][crate::model::CustomPronunciationParams::phonetic_encoding].
    pub fn set_phonetic_encoding<
        T: std::convert::Into<
            std::option::Option<crate::model::custom_pronunciation_params::PhoneticEncoding>,
        >,
    >(
        mut self,
        v: T,
    ) -> Self {
        self.phonetic_encoding = v.into();
        self
    }

    /// Sets the value of [pronunciation][crate::model::CustomPronunciationParams::pronunciation].
    pub fn set_pronunciation<T: std::convert::Into<std::option::Option<std::string::String>>>(
        mut self,
        v: T,
    ) -> Self {
        self.pronunciation = v.into();
        self
    }
}

impl wkt::message::Message for CustomPronunciationParams {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.CustomPronunciationParams"
    }
}

/// Defines additional types related to CustomPronunciationParams
pub mod custom_pronunciation_params {
    #[allow(unused_imports)]
    use super::*;

    /// The phonetic encoding of the phrase.
    #[derive(Clone, Debug, PartialEq, serde::Deserialize, serde::Serialize)]
    pub struct PhoneticEncoding(std::borrow::Cow<'static, str>);

    impl PhoneticEncoding {
        /// Creates a new PhoneticEncoding instance.
        pub const fn new(v: &'static str) -> Self {
            Self(std::borrow::Cow::Borrowed(v))
        }

        /// Gets the enum value.
        pub fn value(&self) -> &str {
            &self.0
        }
    }

    /// Useful constants to work with [PhoneticEncoding](PhoneticEncoding)
    pub mod phonetic_encoding {
        use super::PhoneticEncoding;

        /// Not specified.
        pub const PHONETIC_ENCODING_UNSPECIFIED: PhoneticEncoding =
            PhoneticEncoding::new("PHONETIC_ENCODING_UNSPECIFIED");

        /// IPA. (e.g. apple -> ˈæpəl )
        /// <https://en.wikipedia.org/wiki/International_Phonetic_Alphabet>
        pub const PHONETIC_ENCODING_IPA: PhoneticEncoding =
            PhoneticEncoding::new("PHONETIC_ENCODING_IPA");

        /// X-SAMPA (e.g. apple -> "{p@l" )
        /// <https://en.wikipedia.org/wiki/X-SAMPA>
        pub const PHONETIC_ENCODING_X_SAMPA: PhoneticEncoding =
            PhoneticEncoding::new("PHONETIC_ENCODING_X_SAMPA");
    }

    impl std::convert::From<std::string::String> for PhoneticEncoding {
        fn from(value: std::string::String) -> Self {
            Self(std::borrow::Cow::Owned(value))
        }
    }

    impl std::default::Default for PhoneticEncoding {
        fn default() -> Self {
            phonetic_encoding::PHONETIC_ENCODING_UNSPECIFIED
        }
    }
}

/// A collection of pronunciation customizations.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct CustomPronunciations {
    /// The pronunciation customizations to be applied.
    #[serde(skip_serializing_if = "std::vec::Vec::is_empty")]
    pub pronunciations: std::vec::Vec<crate::model::CustomPronunciationParams>,
}

impl CustomPronunciations {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [pronunciations][crate::model::CustomPronunciations::pronunciations].
    pub fn set_pronunciations<T, V>(mut self, v: T) -> Self
    where
        T: std::iter::IntoIterator<Item = V>,
        V: std::convert::Into<crate::model::CustomPronunciationParams>,
    {
        use std::iter::Iterator;
        self.pronunciations = v.into_iter().map(|i| i.into()).collect();
        self
    }
}

impl wkt::message::Message for CustomPronunciations {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.CustomPronunciations"
    }
}

/// A collection of turns for multi-speaker synthesis.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct MultiSpeakerMarkup {
    /// Required. Speaker turns.
    #[serde(skip_serializing_if = "std::vec::Vec::is_empty")]
    pub turns: std::vec::Vec<crate::model::multi_speaker_markup::Turn>,
}

impl MultiSpeakerMarkup {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [turns][crate::model::MultiSpeakerMarkup::turns].
    pub fn set_turns<T, V>(mut self, v: T) -> Self
    where
        T: std::iter::IntoIterator<Item = V>,
        V: std::convert::Into<crate::model::multi_speaker_markup::Turn>,
    {
        use std::iter::Iterator;
        self.turns = v.into_iter().map(|i| i.into()).collect();
        self
    }
}

impl wkt::message::Message for MultiSpeakerMarkup {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.MultiSpeakerMarkup"
    }
}

/// Defines additional types related to MultiSpeakerMarkup
pub mod multi_speaker_markup {
    #[allow(unused_imports)]
    use super::*;

    /// A Multi-speaker turn.
    #[serde_with::serde_as]
    #[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
    #[serde(default, rename_all = "camelCase")]
    #[non_exhaustive]
    pub struct Turn {
        /// Required. The speaker of the turn, for example, 'O' or 'Q'. Please refer
        /// to documentation for available speakers.
        #[serde(skip_serializing_if = "std::string::String::is_empty")]
        pub speaker: std::string::String,

        /// Required. The text to speak.
        #[serde(skip_serializing_if = "std::string::String::is_empty")]
        pub text: std::string::String,
    }

    impl Turn {
        pub fn new() -> Self {
            std::default::Default::default()
        }

        /// Sets the value of [speaker][crate::model::multi_speaker_markup::Turn::speaker].
        pub fn set_speaker<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
            self.speaker = v.into();
            self
        }

        /// Sets the value of [text][crate::model::multi_speaker_markup::Turn::text].
        pub fn set_text<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
            self.text = v.into();
            self
        }
    }

    impl wkt::message::Message for Turn {
        fn typename() -> &'static str {
            "type.googleapis.com/google.cloud.texttospeech.v1.MultiSpeakerMarkup.Turn"
        }
    }
}

/// Contains text input to be synthesized. Either `text` or `ssml` must be
/// supplied. Supplying both or neither returns
/// [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]. The
/// input size is limited to 5000 bytes.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct SynthesisInput {
    /// Optional. The pronunciation customizations to be applied to the input. If
    /// this is set, the input will be synthesized using the given pronunciation
    /// customizations.
    ///
    /// The initial support will be for EFIGS (English, French,
    /// Italian, German, Spanish) languages, as provided in
    /// VoiceSelectionParams. Journey and Instant Clone voices are
    /// not supported yet.
    ///
    /// In order to customize the pronunciation of a phrase, there must be an exact
    /// match of the phrase in the input types. If using SSML, the phrase must not
    /// be inside a phoneme tag (entirely or partially).
    #[serde(skip_serializing_if = "std::option::Option::is_none")]
    pub custom_pronunciations: std::option::Option<crate::model::CustomPronunciations>,

    /// The input source, which is either plain text or SSML.
    #[serde(flatten, skip_serializing_if = "std::option::Option::is_none")]
    pub input_source: std::option::Option<crate::model::synthesis_input::InputSource>,
}

impl SynthesisInput {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [custom_pronunciations][crate::model::SynthesisInput::custom_pronunciations].
    pub fn set_custom_pronunciations<
        T: std::convert::Into<std::option::Option<crate::model::CustomPronunciations>>,
    >(
        mut self,
        v: T,
    ) -> Self {
        self.custom_pronunciations = v.into();
        self
    }

    /// Sets the value of `input_source`.
    pub fn set_input_source<
        T: std::convert::Into<std::option::Option<crate::model::synthesis_input::InputSource>>,
    >(
        mut self,
        v: T,
    ) -> Self {
        self.input_source = v.into();
        self
    }

    /// The value of [input_source][crate::model::SynthesisInput::input_source]
    /// if it holds a `Text`, `None` if the field is not set or
    /// holds a different branch.
    pub fn get_text(&self) -> std::option::Option<&std::string::String> {
        #[allow(unreachable_patterns)]
        self.input_source.as_ref().and_then(|v| match v {
            crate::model::synthesis_input::InputSource::Text(v) => std::option::Option::Some(v),
            _ => std::option::Option::None,
        })
    }

    /// The value of [input_source][crate::model::SynthesisInput::input_source]
    /// if it holds a `Ssml`, `None` if the field is not set or
    /// holds a different branch.
    pub fn get_ssml(&self) -> std::option::Option<&std::string::String> {
        #[allow(unreachable_patterns)]
        self.input_source.as_ref().and_then(|v| match v {
            crate::model::synthesis_input::InputSource::Ssml(v) => std::option::Option::Some(v),
            _ => std::option::Option::None,
        })
    }

    /// The value of [input_source][crate::model::SynthesisInput::input_source]
    /// if it holds a `MultiSpeakerMarkup`, `None` if the field is not set or
    /// holds a different branch.
    pub fn get_multi_speaker_markup(
        &self,
    ) -> std::option::Option<&std::boxed::Box<crate::model::MultiSpeakerMarkup>> {
        #[allow(unreachable_patterns)]
        self.input_source.as_ref().and_then(|v| match v {
            crate::model::synthesis_input::InputSource::MultiSpeakerMarkup(v) => {
                std::option::Option::Some(v)
            }
            _ => std::option::Option::None,
        })
    }

    /// Sets the value of [input_source][crate::model::SynthesisInput::input_source]
    /// to hold a `Text`.
    ///
    /// Note that all the setters affecting `input_source` are
    /// mutually exclusive.
    pub fn set_text<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.input_source =
            std::option::Option::Some(crate::model::synthesis_input::InputSource::Text(v.into()));
        self
    }

    /// Sets the value of [input_source][crate::model::SynthesisInput::input_source]
    /// to hold a `Ssml`.
    ///
    /// Note that all the setters affecting `input_source` are
    /// mutually exclusive.
    pub fn set_ssml<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.input_source =
            std::option::Option::Some(crate::model::synthesis_input::InputSource::Ssml(v.into()));
        self
    }

    /// Sets the value of [input_source][crate::model::SynthesisInput::input_source]
    /// to hold a `MultiSpeakerMarkup`.
    ///
    /// Note that all the setters affecting `input_source` are
    /// mutually exclusive.
    pub fn set_multi_speaker_markup<
        T: std::convert::Into<std::boxed::Box<crate::model::MultiSpeakerMarkup>>,
    >(
        mut self,
        v: T,
    ) -> Self {
        self.input_source = std::option::Option::Some(
            crate::model::synthesis_input::InputSource::MultiSpeakerMarkup(v.into()),
        );
        self
    }
}

impl wkt::message::Message for SynthesisInput {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.SynthesisInput"
    }
}

/// Defines additional types related to SynthesisInput
pub mod synthesis_input {
    #[allow(unused_imports)]
    use super::*;

    /// The input source, which is either plain text or SSML.
    #[derive(Clone, Debug, PartialEq, serde::Deserialize, serde::Serialize)]
    #[serde(rename_all = "camelCase")]
    #[non_exhaustive]
    pub enum InputSource {
        /// The raw text to be synthesized.
        Text(std::string::String),
        /// The SSML document to be synthesized. The SSML document must be valid
        /// and well-formed. Otherwise the RPC will fail and return
        /// [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]. For
        /// more information, see
        /// [SSML](https://cloud.google.com/text-to-speech/docs/ssml).
        Ssml(std::string::String),
        /// The multi-speaker input to be synthesized. Only applicable for
        /// multi-speaker synthesis.
        MultiSpeakerMarkup(std::boxed::Box<crate::model::MultiSpeakerMarkup>),
    }
}

/// Description of which voice to use for a synthesis request.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct VoiceSelectionParams {
    /// Required. The language (and potentially also the region) of the voice
    /// expressed as a [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt)
    /// language tag, e.g. "en-US". This should not include a script tag (e.g. use
    /// "cmn-cn" rather than "cmn-Hant-cn"), because the script will be inferred
    /// from the input provided in the SynthesisInput.  The TTS service
    /// will use this parameter to help choose an appropriate voice.  Note that
    /// the TTS service may choose a voice with a slightly different language code
    /// than the one selected; it may substitute a different region
    /// (e.g. using en-US rather than en-CA if there isn't a Canadian voice
    /// available), or even a different language, e.g. using "nb" (Norwegian
    /// Bokmal) instead of "no" (Norwegian)".
    #[serde(skip_serializing_if = "std::string::String::is_empty")]
    pub language_code: std::string::String,

    /// The name of the voice. If both the name and the gender are not set,
    /// the service will choose a voice based on the other parameters such as
    /// language_code.
    #[serde(skip_serializing_if = "std::string::String::is_empty")]
    pub name: std::string::String,

    /// The preferred gender of the voice. If not set, the service will
    /// choose a voice based on the other parameters such as language_code and
    /// name. Note that this is only a preference, not requirement; if a
    /// voice of the appropriate gender is not available, the synthesizer should
    /// substitute a voice with a different gender rather than failing the request.
    pub ssml_gender: crate::model::SsmlVoiceGender,

    /// The configuration for a custom voice. If [CustomVoiceParams.model] is set,
    /// the service will choose the custom voice matching the specified
    /// configuration.
    #[serde(skip_serializing_if = "std::option::Option::is_none")]
    pub custom_voice: std::option::Option<crate::model::CustomVoiceParams>,

    /// Optional. The configuration for a voice clone. If
    /// [VoiceCloneParams.voice_clone_key] is set, the service will choose the
    /// voice clone matching the specified configuration.
    #[serde(skip_serializing_if = "std::option::Option::is_none")]
    pub voice_clone: std::option::Option<crate::model::VoiceCloneParams>,
}

impl VoiceSelectionParams {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [language_code][crate::model::VoiceSelectionParams::language_code].
    pub fn set_language_code<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.language_code = v.into();
        self
    }

    /// Sets the value of [name][crate::model::VoiceSelectionParams::name].
    pub fn set_name<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.name = v.into();
        self
    }

    /// Sets the value of [ssml_gender][crate::model::VoiceSelectionParams::ssml_gender].
    pub fn set_ssml_gender<T: std::convert::Into<crate::model::SsmlVoiceGender>>(
        mut self,
        v: T,
    ) -> Self {
        self.ssml_gender = v.into();
        self
    }

    /// Sets the value of [custom_voice][crate::model::VoiceSelectionParams::custom_voice].
    pub fn set_custom_voice<
        T: std::convert::Into<std::option::Option<crate::model::CustomVoiceParams>>,
    >(
        mut self,
        v: T,
    ) -> Self {
        self.custom_voice = v.into();
        self
    }

    /// Sets the value of [voice_clone][crate::model::VoiceSelectionParams::voice_clone].
    pub fn set_voice_clone<
        T: std::convert::Into<std::option::Option<crate::model::VoiceCloneParams>>,
    >(
        mut self,
        v: T,
    ) -> Self {
        self.voice_clone = v.into();
        self
    }
}

impl wkt::message::Message for VoiceSelectionParams {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.VoiceSelectionParams"
    }
}

/// Description of audio data to be synthesized.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct AudioConfig {
    /// Required. The format of the audio byte stream.
    pub audio_encoding: crate::model::AudioEncoding,

    /// Optional. Input only. Speaking rate/speed, in the range [0.25, 4.0]. 1.0 is
    /// the normal native speed supported by the specific voice. 2.0 is twice as
    /// fast, and 0.5 is half as fast. If unset(0.0), defaults to the native 1.0
    /// speed. Any other values < 0.25 or > 4.0 will return an error.
    pub speaking_rate: f64,

    /// Optional. Input only. Speaking pitch, in the range [-20.0, 20.0]. 20 means
    /// increase 20 semitones from the original pitch. -20 means decrease 20
    /// semitones from the original pitch.
    pub pitch: f64,

    /// Optional. Input only. Volume gain (in dB) of the normal native volume
    /// supported by the specific voice, in the range [-96.0, 16.0]. If unset, or
    /// set to a value of 0.0 (dB), will play at normal native signal amplitude. A
    /// value of -6.0 (dB) will play at approximately half the amplitude of the
    /// normal native signal amplitude. A value of +6.0 (dB) will play at
    /// approximately twice the amplitude of the normal native signal amplitude.
    /// Strongly recommend not to exceed +10 (dB) as there's usually no effective
    /// increase in loudness for any value greater than that.
    pub volume_gain_db: f64,

    /// Optional. The synthesis sample rate (in hertz) for this audio. When this is
    /// specified in SynthesizeSpeechRequest, if this is different from the voice's
    /// natural sample rate, then the synthesizer will honor this request by
    /// converting to the desired sample rate (which might result in worse audio
    /// quality), unless the specified sample rate is not supported for the
    /// encoding chosen, in which case it will fail the request and return
    /// [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT].
    pub sample_rate_hertz: i32,

    /// Optional. Input only. An identifier which selects 'audio effects' profiles
    /// that are applied on (post synthesized) text to speech. Effects are applied
    /// on top of each other in the order they are given. See
    /// [audio
    /// profiles](https://cloud.google.com/text-to-speech/docs/audio-profiles) for
    /// current supported profile ids.
    #[serde(skip_serializing_if = "std::vec::Vec::is_empty")]
    pub effects_profile_id: std::vec::Vec<std::string::String>,
}

impl AudioConfig {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [audio_encoding][crate::model::AudioConfig::audio_encoding].
    pub fn set_audio_encoding<T: std::convert::Into<crate::model::AudioEncoding>>(
        mut self,
        v: T,
    ) -> Self {
        self.audio_encoding = v.into();
        self
    }

    /// Sets the value of [speaking_rate][crate::model::AudioConfig::speaking_rate].
    pub fn set_speaking_rate<T: std::convert::Into<f64>>(mut self, v: T) -> Self {
        self.speaking_rate = v.into();
        self
    }

    /// Sets the value of [pitch][crate::model::AudioConfig::pitch].
    pub fn set_pitch<T: std::convert::Into<f64>>(mut self, v: T) -> Self {
        self.pitch = v.into();
        self
    }

    /// Sets the value of [volume_gain_db][crate::model::AudioConfig::volume_gain_db].
    pub fn set_volume_gain_db<T: std::convert::Into<f64>>(mut self, v: T) -> Self {
        self.volume_gain_db = v.into();
        self
    }

    /// Sets the value of [sample_rate_hertz][crate::model::AudioConfig::sample_rate_hertz].
    pub fn set_sample_rate_hertz<T: std::convert::Into<i32>>(mut self, v: T) -> Self {
        self.sample_rate_hertz = v.into();
        self
    }

    /// Sets the value of [effects_profile_id][crate::model::AudioConfig::effects_profile_id].
    pub fn set_effects_profile_id<T, V>(mut self, v: T) -> Self
    where
        T: std::iter::IntoIterator<Item = V>,
        V: std::convert::Into<std::string::String>,
    {
        use std::iter::Iterator;
        self.effects_profile_id = v.into_iter().map(|i| i.into()).collect();
        self
    }
}

impl wkt::message::Message for AudioConfig {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.AudioConfig"
    }
}

/// Description of the custom voice to be synthesized.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct CustomVoiceParams {
    /// Required. The name of the AutoML model that synthesizes the custom voice.
    #[serde(skip_serializing_if = "std::string::String::is_empty")]
    pub model: std::string::String,

    /// Optional. Deprecated. The usage of the synthesized audio to be reported.
    pub reported_usage: crate::model::custom_voice_params::ReportedUsage,
}

impl CustomVoiceParams {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [model][crate::model::CustomVoiceParams::model].
    pub fn set_model<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.model = v.into();
        self
    }

    /// Sets the value of [reported_usage][crate::model::CustomVoiceParams::reported_usage].
    pub fn set_reported_usage<
        T: std::convert::Into<crate::model::custom_voice_params::ReportedUsage>,
    >(
        mut self,
        v: T,
    ) -> Self {
        self.reported_usage = v.into();
        self
    }
}

impl wkt::message::Message for CustomVoiceParams {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.CustomVoiceParams"
    }
}

/// Defines additional types related to CustomVoiceParams
pub mod custom_voice_params {
    #[allow(unused_imports)]
    use super::*;

    /// Deprecated. The usage of the synthesized audio. Usage does not affect
    /// billing.
    #[derive(Clone, Debug, PartialEq, serde::Deserialize, serde::Serialize)]
    pub struct ReportedUsage(std::borrow::Cow<'static, str>);

    impl ReportedUsage {
        /// Creates a new ReportedUsage instance.
        pub const fn new(v: &'static str) -> Self {
            Self(std::borrow::Cow::Borrowed(v))
        }

        /// Gets the enum value.
        pub fn value(&self) -> &str {
            &self.0
        }
    }

    /// Useful constants to work with [ReportedUsage](ReportedUsage)
    pub mod reported_usage {
        use super::ReportedUsage;

        /// Request with reported usage unspecified will be rejected.
        pub const REPORTED_USAGE_UNSPECIFIED: ReportedUsage =
            ReportedUsage::new("REPORTED_USAGE_UNSPECIFIED");

        /// For scenarios where the synthesized audio is not downloadable and can
        /// only be used once. For example, real-time request in IVR system.
        pub const REALTIME: ReportedUsage = ReportedUsage::new("REALTIME");

        /// For scenarios where the synthesized audio is downloadable and can be
        /// reused. For example, the synthesized audio is downloaded, stored in
        /// customer service system and played repeatedly.
        pub const OFFLINE: ReportedUsage = ReportedUsage::new("OFFLINE");
    }

    impl std::convert::From<std::string::String> for ReportedUsage {
        fn from(value: std::string::String) -> Self {
            Self(std::borrow::Cow::Owned(value))
        }
    }

    impl std::default::Default for ReportedUsage {
        fn default() -> Self {
            reported_usage::REPORTED_USAGE_UNSPECIFIED
        }
    }
}

/// The configuration of Voice Clone feature.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct VoiceCloneParams {
    /// Required. Created by GenerateVoiceCloningKey.
    #[serde(skip_serializing_if = "std::string::String::is_empty")]
    pub voice_cloning_key: std::string::String,
}

impl VoiceCloneParams {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [voice_cloning_key][crate::model::VoiceCloneParams::voice_cloning_key].
    pub fn set_voice_cloning_key<T: std::convert::Into<std::string::String>>(
        mut self,
        v: T,
    ) -> Self {
        self.voice_cloning_key = v.into();
        self
    }
}

impl wkt::message::Message for VoiceCloneParams {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.VoiceCloneParams"
    }
}

/// The message returned to the client by the `SynthesizeSpeech` method.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct SynthesizeSpeechResponse {
    /// The audio data bytes encoded as specified in the request, including the
    /// header for encodings that are wrapped in containers (e.g. MP3, OGG_OPUS).
    /// For LINEAR16 audio, we include the WAV header. Note: as
    /// with all bytes fields, protobuffers use a pure binary representation,
    /// whereas JSON representations use base64.
    #[serde(skip_serializing_if = "::bytes::Bytes::is_empty")]
    #[serde_as(as = "serde_with::base64::Base64")]
    pub audio_content: ::bytes::Bytes,
}

impl SynthesizeSpeechResponse {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [audio_content][crate::model::SynthesizeSpeechResponse::audio_content].
    pub fn set_audio_content<T: std::convert::Into<::bytes::Bytes>>(mut self, v: T) -> Self {
        self.audio_content = v.into();
        self
    }
}

impl wkt::message::Message for SynthesizeSpeechResponse {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.SynthesizeSpeechResponse"
    }
}

/// Description of the desired output audio data.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct StreamingAudioConfig {
    /// Required. The format of the audio byte stream.
    /// For now, streaming only supports PCM and OGG_OPUS. All other encodings
    /// will return an error.
    pub audio_encoding: crate::model::AudioEncoding,

    /// Optional. The synthesis sample rate (in hertz) for this audio.
    pub sample_rate_hertz: i32,
}

impl StreamingAudioConfig {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [audio_encoding][crate::model::StreamingAudioConfig::audio_encoding].
    pub fn set_audio_encoding<T: std::convert::Into<crate::model::AudioEncoding>>(
        mut self,
        v: T,
    ) -> Self {
        self.audio_encoding = v.into();
        self
    }

    /// Sets the value of [sample_rate_hertz][crate::model::StreamingAudioConfig::sample_rate_hertz].
    pub fn set_sample_rate_hertz<T: std::convert::Into<i32>>(mut self, v: T) -> Self {
        self.sample_rate_hertz = v.into();
        self
    }
}

impl wkt::message::Message for StreamingAudioConfig {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.StreamingAudioConfig"
    }
}

/// Provides configuration information for the StreamingSynthesize request.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct StreamingSynthesizeConfig {
    /// Required. The desired voice of the synthesized audio.
    #[serde(skip_serializing_if = "std::option::Option::is_none")]
    pub voice: std::option::Option<crate::model::VoiceSelectionParams>,

    /// Optional. The configuration of the synthesized audio.
    #[serde(skip_serializing_if = "std::option::Option::is_none")]
    pub streaming_audio_config: std::option::Option<crate::model::StreamingAudioConfig>,
}

impl StreamingSynthesizeConfig {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [voice][crate::model::StreamingSynthesizeConfig::voice].
    pub fn set_voice<
        T: std::convert::Into<std::option::Option<crate::model::VoiceSelectionParams>>,
    >(
        mut self,
        v: T,
    ) -> Self {
        self.voice = v.into();
        self
    }

    /// Sets the value of [streaming_audio_config][crate::model::StreamingSynthesizeConfig::streaming_audio_config].
    pub fn set_streaming_audio_config<
        T: std::convert::Into<std::option::Option<crate::model::StreamingAudioConfig>>,
    >(
        mut self,
        v: T,
    ) -> Self {
        self.streaming_audio_config = v.into();
        self
    }
}

impl wkt::message::Message for StreamingSynthesizeConfig {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.StreamingSynthesizeConfig"
    }
}

/// Input to be synthesized.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct StreamingSynthesisInput {
    #[serde(flatten, skip_serializing_if = "std::option::Option::is_none")]
    pub input_source: std::option::Option<crate::model::streaming_synthesis_input::InputSource>,
}

impl StreamingSynthesisInput {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of `input_source`.
    pub fn set_input_source<
        T: std::convert::Into<
            std::option::Option<crate::model::streaming_synthesis_input::InputSource>,
        >,
    >(
        mut self,
        v: T,
    ) -> Self {
        self.input_source = v.into();
        self
    }

    /// The value of [input_source][crate::model::StreamingSynthesisInput::input_source]
    /// if it holds a `Text`, `None` if the field is not set or
    /// holds a different branch.
    pub fn get_text(&self) -> std::option::Option<&std::string::String> {
        #[allow(unreachable_patterns)]
        self.input_source.as_ref().and_then(|v| match v {
            crate::model::streaming_synthesis_input::InputSource::Text(v) => {
                std::option::Option::Some(v)
            }
            _ => std::option::Option::None,
        })
    }

    /// Sets the value of [input_source][crate::model::StreamingSynthesisInput::input_source]
    /// to hold a `Text`.
    ///
    /// Note that all the setters affecting `input_source` are
    /// mutually exclusive.
    pub fn set_text<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.input_source = std::option::Option::Some(
            crate::model::streaming_synthesis_input::InputSource::Text(v.into()),
        );
        self
    }
}

impl wkt::message::Message for StreamingSynthesisInput {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.StreamingSynthesisInput"
    }
}

/// Defines additional types related to StreamingSynthesisInput
pub mod streaming_synthesis_input {
    #[allow(unused_imports)]
    use super::*;

    #[derive(Clone, Debug, PartialEq, serde::Deserialize, serde::Serialize)]
    #[serde(rename_all = "camelCase")]
    #[non_exhaustive]
    pub enum InputSource {
        /// The raw text to be synthesized. It is recommended that each input
        /// contains complete, terminating sentences, as this will likely result in
        /// better prosody in the output audio. That being said, users are free to
        /// input text however they please.
        Text(std::string::String),
    }
}

/// Request message for the `StreamingSynthesize` method. Multiple
/// `StreamingSynthesizeRequest` messages are sent in one call.
/// The first message must contain a `streaming_config` that
/// fully specifies the request configuration and must not contain `input`. All
/// subsequent messages must only have `input` set.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct StreamingSynthesizeRequest {
    /// The request to be sent, either a StreamingSynthesizeConfig or
    /// StreamingSynthesisInput.
    #[serde(flatten, skip_serializing_if = "std::option::Option::is_none")]
    pub streaming_request:
        std::option::Option<crate::model::streaming_synthesize_request::StreamingRequest>,
}

impl StreamingSynthesizeRequest {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of `streaming_request`.
    pub fn set_streaming_request<
        T: std::convert::Into<
            std::option::Option<crate::model::streaming_synthesize_request::StreamingRequest>,
        >,
    >(
        mut self,
        v: T,
    ) -> Self {
        self.streaming_request = v.into();
        self
    }

    /// The value of [streaming_request][crate::model::StreamingSynthesizeRequest::streaming_request]
    /// if it holds a `StreamingConfig`, `None` if the field is not set or
    /// holds a different branch.
    pub fn get_streaming_config(
        &self,
    ) -> std::option::Option<&std::boxed::Box<crate::model::StreamingSynthesizeConfig>> {
        #[allow(unreachable_patterns)]
        self.streaming_request.as_ref().and_then(|v| match v {
            crate::model::streaming_synthesize_request::StreamingRequest::StreamingConfig(v) => {
                std::option::Option::Some(v)
            }
            _ => std::option::Option::None,
        })
    }

    /// The value of [streaming_request][crate::model::StreamingSynthesizeRequest::streaming_request]
    /// if it holds a `Input`, `None` if the field is not set or
    /// holds a different branch.
    pub fn get_input(
        &self,
    ) -> std::option::Option<&std::boxed::Box<crate::model::StreamingSynthesisInput>> {
        #[allow(unreachable_patterns)]
        self.streaming_request.as_ref().and_then(|v| match v {
            crate::model::streaming_synthesize_request::StreamingRequest::Input(v) => {
                std::option::Option::Some(v)
            }
            _ => std::option::Option::None,
        })
    }

    /// Sets the value of [streaming_request][crate::model::StreamingSynthesizeRequest::streaming_request]
    /// to hold a `StreamingConfig`.
    ///
    /// Note that all the setters affecting `streaming_request` are
    /// mutually exclusive.
    pub fn set_streaming_config<
        T: std::convert::Into<std::boxed::Box<crate::model::StreamingSynthesizeConfig>>,
    >(
        mut self,
        v: T,
    ) -> Self {
        self.streaming_request = std::option::Option::Some(
            crate::model::streaming_synthesize_request::StreamingRequest::StreamingConfig(v.into()),
        );
        self
    }

    /// Sets the value of [streaming_request][crate::model::StreamingSynthesizeRequest::streaming_request]
    /// to hold a `Input`.
    ///
    /// Note that all the setters affecting `streaming_request` are
    /// mutually exclusive.
    pub fn set_input<
        T: std::convert::Into<std::boxed::Box<crate::model::StreamingSynthesisInput>>,
    >(
        mut self,
        v: T,
    ) -> Self {
        self.streaming_request = std::option::Option::Some(
            crate::model::streaming_synthesize_request::StreamingRequest::Input(v.into()),
        );
        self
    }
}

impl wkt::message::Message for StreamingSynthesizeRequest {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.StreamingSynthesizeRequest"
    }
}

/// Defines additional types related to StreamingSynthesizeRequest
pub mod streaming_synthesize_request {
    #[allow(unused_imports)]
    use super::*;

    /// The request to be sent, either a StreamingSynthesizeConfig or
    /// StreamingSynthesisInput.
    #[derive(Clone, Debug, PartialEq, serde::Deserialize, serde::Serialize)]
    #[serde(rename_all = "camelCase")]
    #[non_exhaustive]
    pub enum StreamingRequest {
        /// StreamingSynthesizeConfig to be used in this streaming attempt. Only
        /// specified in the first message sent in a `StreamingSynthesize` call.
        StreamingConfig(std::boxed::Box<crate::model::StreamingSynthesizeConfig>),
        /// Input to synthesize. Specified in all messages but the first in a
        /// `StreamingSynthesize` call.
        Input(std::boxed::Box<crate::model::StreamingSynthesisInput>),
    }
}

/// `StreamingSynthesizeResponse` is the only message returned to the
/// client by `StreamingSynthesize` method. A series of zero or more
/// `StreamingSynthesizeResponse` messages are streamed back to the client.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct StreamingSynthesizeResponse {
    /// The audio data bytes encoded as specified in the request. This is
    /// headerless LINEAR16 audio with a sample rate of 24000.
    #[serde(skip_serializing_if = "::bytes::Bytes::is_empty")]
    #[serde_as(as = "serde_with::base64::Base64")]
    pub audio_content: ::bytes::Bytes,
}

impl StreamingSynthesizeResponse {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [audio_content][crate::model::StreamingSynthesizeResponse::audio_content].
    pub fn set_audio_content<T: std::convert::Into<::bytes::Bytes>>(mut self, v: T) -> Self {
        self.audio_content = v.into();
        self
    }
}

impl wkt::message::Message for StreamingSynthesizeResponse {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.StreamingSynthesizeResponse"
    }
}

/// The top-level message sent by the client for the
/// `SynthesizeLongAudio` method.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct SynthesizeLongAudioRequest {
    /// The resource states of the request in the form of
    /// `projects/*/locations/*`.
    #[serde(skip_serializing_if = "std::string::String::is_empty")]
    pub parent: std::string::String,

    /// Required. The Synthesizer requires either plain text or SSML as input.
    #[serde(skip_serializing_if = "std::option::Option::is_none")]
    pub input: std::option::Option<crate::model::SynthesisInput>,

    /// Required. The configuration of the synthesized audio.
    #[serde(skip_serializing_if = "std::option::Option::is_none")]
    pub audio_config: std::option::Option<crate::model::AudioConfig>,

    /// Required. Specifies a Cloud Storage URI for the synthesis results. Must be
    /// specified in the format: `gs://bucket_name/object_name`, and the bucket
    /// must already exist.
    #[serde(skip_serializing_if = "std::string::String::is_empty")]
    pub output_gcs_uri: std::string::String,

    /// Required. The desired voice of the synthesized audio.
    #[serde(skip_serializing_if = "std::option::Option::is_none")]
    pub voice: std::option::Option<crate::model::VoiceSelectionParams>,
}

impl SynthesizeLongAudioRequest {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [parent][crate::model::SynthesizeLongAudioRequest::parent].
    pub fn set_parent<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.parent = v.into();
        self
    }

    /// Sets the value of [input][crate::model::SynthesizeLongAudioRequest::input].
    pub fn set_input<T: std::convert::Into<std::option::Option<crate::model::SynthesisInput>>>(
        mut self,
        v: T,
    ) -> Self {
        self.input = v.into();
        self
    }

    /// Sets the value of [audio_config][crate::model::SynthesizeLongAudioRequest::audio_config].
    pub fn set_audio_config<
        T: std::convert::Into<std::option::Option<crate::model::AudioConfig>>,
    >(
        mut self,
        v: T,
    ) -> Self {
        self.audio_config = v.into();
        self
    }

    /// Sets the value of [output_gcs_uri][crate::model::SynthesizeLongAudioRequest::output_gcs_uri].
    pub fn set_output_gcs_uri<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.output_gcs_uri = v.into();
        self
    }

    /// Sets the value of [voice][crate::model::SynthesizeLongAudioRequest::voice].
    pub fn set_voice<
        T: std::convert::Into<std::option::Option<crate::model::VoiceSelectionParams>>,
    >(
        mut self,
        v: T,
    ) -> Self {
        self.voice = v.into();
        self
    }
}

impl wkt::message::Message for SynthesizeLongAudioRequest {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.SynthesizeLongAudioRequest"
    }
}

/// The message returned to the client by the `SynthesizeLongAudio` method.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct SynthesizeLongAudioResponse {}

impl SynthesizeLongAudioResponse {
    pub fn new() -> Self {
        std::default::Default::default()
    }
}

impl wkt::message::Message for SynthesizeLongAudioResponse {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.SynthesizeLongAudioResponse"
    }
}

/// Metadata for response returned by the `SynthesizeLongAudio` method.
#[serde_with::serde_as]
#[derive(Clone, Debug, Default, PartialEq, serde::Deserialize, serde::Serialize)]
#[serde(default, rename_all = "camelCase")]
#[non_exhaustive]
pub struct SynthesizeLongAudioMetadata {
    /// Time when the request was received.
    #[serde(skip_serializing_if = "std::option::Option::is_none")]
    pub start_time: std::option::Option<wkt::Timestamp>,

    /// Deprecated. Do not use.
    #[serde(skip_serializing_if = "std::option::Option::is_none")]
    pub last_update_time: std::option::Option<wkt::Timestamp>,

    /// The progress of the most recent processing update in percentage, ie. 70.0%.
    pub progress_percentage: f64,
}

impl SynthesizeLongAudioMetadata {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [start_time][crate::model::SynthesizeLongAudioMetadata::start_time].
    pub fn set_start_time<T: std::convert::Into<std::option::Option<wkt::Timestamp>>>(
        mut self,
        v: T,
    ) -> Self {
        self.start_time = v.into();
        self
    }

    /// Sets the value of [last_update_time][crate::model::SynthesizeLongAudioMetadata::last_update_time].
    pub fn set_last_update_time<T: std::convert::Into<std::option::Option<wkt::Timestamp>>>(
        mut self,
        v: T,
    ) -> Self {
        self.last_update_time = v.into();
        self
    }

    /// Sets the value of [progress_percentage][crate::model::SynthesizeLongAudioMetadata::progress_percentage].
    pub fn set_progress_percentage<T: std::convert::Into<f64>>(mut self, v: T) -> Self {
        self.progress_percentage = v.into();
        self
    }
}

impl wkt::message::Message for SynthesizeLongAudioMetadata {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.texttospeech.v1.SynthesizeLongAudioMetadata"
    }
}

/// Gender of the voice as described in
/// [SSML voice element](https://www.w3.org/TR/speech-synthesis11/#edef_voice).
#[derive(Clone, Debug, PartialEq, serde::Deserialize, serde::Serialize)]
pub struct SsmlVoiceGender(std::borrow::Cow<'static, str>);

impl SsmlVoiceGender {
    /// Creates a new SsmlVoiceGender instance.
    pub const fn new(v: &'static str) -> Self {
        Self(std::borrow::Cow::Borrowed(v))
    }

    /// Gets the enum value.
    pub fn value(&self) -> &str {
        &self.0
    }
}

/// Useful constants to work with [SsmlVoiceGender](SsmlVoiceGender)
pub mod ssml_voice_gender {
    use super::SsmlVoiceGender;

    /// An unspecified gender.
    /// In VoiceSelectionParams, this means that the client doesn't care which
    /// gender the selected voice will have. In the Voice field of
    /// ListVoicesResponse, this may mean that the voice doesn't fit any of the
    /// other categories in this enum, or that the gender of the voice isn't known.
    pub const SSML_VOICE_GENDER_UNSPECIFIED: SsmlVoiceGender =
        SsmlVoiceGender::new("SSML_VOICE_GENDER_UNSPECIFIED");

    /// A male voice.
    pub const MALE: SsmlVoiceGender = SsmlVoiceGender::new("MALE");

    /// A female voice.
    pub const FEMALE: SsmlVoiceGender = SsmlVoiceGender::new("FEMALE");

    /// A gender-neutral voice. This voice is not yet supported.
    pub const NEUTRAL: SsmlVoiceGender = SsmlVoiceGender::new("NEUTRAL");
}

impl std::convert::From<std::string::String> for SsmlVoiceGender {
    fn from(value: std::string::String) -> Self {
        Self(std::borrow::Cow::Owned(value))
    }
}

impl std::default::Default for SsmlVoiceGender {
    fn default() -> Self {
        ssml_voice_gender::SSML_VOICE_GENDER_UNSPECIFIED
    }
}

/// Configuration to set up audio encoder. The encoding determines the output
/// audio format that we'd like.
#[derive(Clone, Debug, PartialEq, serde::Deserialize, serde::Serialize)]
pub struct AudioEncoding(std::borrow::Cow<'static, str>);

impl AudioEncoding {
    /// Creates a new AudioEncoding instance.
    pub const fn new(v: &'static str) -> Self {
        Self(std::borrow::Cow::Borrowed(v))
    }

    /// Gets the enum value.
    pub fn value(&self) -> &str {
        &self.0
    }
}

/// Useful constants to work with [AudioEncoding](AudioEncoding)
pub mod audio_encoding {
    use super::AudioEncoding;

    /// Not specified. Will return result
    /// [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT].
    pub const AUDIO_ENCODING_UNSPECIFIED: AudioEncoding =
        AudioEncoding::new("AUDIO_ENCODING_UNSPECIFIED");

    /// Uncompressed 16-bit signed little-endian samples (Linear PCM).
    /// Audio content returned as LINEAR16 also contains a WAV header.
    pub const LINEAR16: AudioEncoding = AudioEncoding::new("LINEAR16");

    /// MP3 audio at 32kbps.
    pub const MP3: AudioEncoding = AudioEncoding::new("MP3");

    /// Opus encoded audio wrapped in an ogg container. The result will be a
    /// file which can be played natively on Android, and in browsers (at least
    /// Chrome and Firefox). The quality of the encoding is considerably higher
    /// than MP3 while using approximately the same bitrate.
    pub const OGG_OPUS: AudioEncoding = AudioEncoding::new("OGG_OPUS");

    /// 8-bit samples that compand 14-bit audio samples using G.711 PCMU/mu-law.
    /// Audio content returned as MULAW also contains a WAV header.
    pub const MULAW: AudioEncoding = AudioEncoding::new("MULAW");

    /// 8-bit samples that compand 14-bit audio samples using G.711 PCMU/A-law.
    /// Audio content returned as ALAW also contains a WAV header.
    pub const ALAW: AudioEncoding = AudioEncoding::new("ALAW");

    /// Uncompressed 16-bit signed little-endian samples (Linear PCM).
    /// Note that as opposed to LINEAR16, audio will not be wrapped in a WAV (or
    /// any other) header.
    pub const PCM: AudioEncoding = AudioEncoding::new("PCM");
}

impl std::convert::From<std::string::String> for AudioEncoding {
    fn from(value: std::string::String) -> Self {
        Self(std::borrow::Cow::Owned(value))
    }
}

impl std::default::Default for AudioEncoding {
    fn default() -> Self {
        audio_encoding::AUDIO_ENCODING_UNSPECIFIED
    }
}
