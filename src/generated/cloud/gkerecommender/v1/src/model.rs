// Copyright 2025 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     https://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//
// Code generated by sidekick. DO NOT EDIT.

#![allow(rustdoc::redundant_explicit_links)]
#![allow(rustdoc::broken_intra_doc_links)]
#![no_implicit_prelude]
extern crate async_trait;
extern crate bytes;
extern crate gax;
extern crate gaxi;
extern crate lazy_static;
extern crate reqwest;
extern crate serde;
extern crate serde_json;
extern crate serde_with;
extern crate std;
extern crate tracing;
extern crate wkt;

mod debug;
mod deserialize;
mod serialize;

/// Request message for
/// [GkeInferenceQuickstart.FetchModels][google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchModels].
///
/// [google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchModels]: crate::client::GkeInferenceQuickstart::fetch_models
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct FetchModelsRequest {
    /// Optional. The target number of results to return in a single response.
    /// If not specified, a default value will be chosen by the service.
    /// Note that the response may include a partial list and a caller should
    /// only rely on the response's
    /// [next_page_token][google.cloud.gkerecommender.v1.FetchModelsResponse.next_page_token]
    /// to determine if there are more instances left to be queried.
    ///
    /// [google.cloud.gkerecommender.v1.FetchModelsResponse.next_page_token]: crate::model::FetchModelsResponse::next_page_token
    pub page_size: std::option::Option<i32>,

    /// Optional. The value of
    /// [next_page_token][google.cloud.gkerecommender.v1.FetchModelsResponse.next_page_token]
    /// received from a previous `FetchModelsRequest` call.
    /// Provide this to retrieve the subsequent page in a multi-page list of
    /// results. When paginating, all other parameters provided to
    /// `FetchModelsRequest` must match the call that provided the page token.
    ///
    /// [google.cloud.gkerecommender.v1.FetchModelsResponse.next_page_token]: crate::model::FetchModelsResponse::next_page_token
    pub page_token: std::option::Option<std::string::String>,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl FetchModelsRequest {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [page_size][crate::model::FetchModelsRequest::page_size].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchModelsRequest;
    /// let x = FetchModelsRequest::new().set_page_size(42);
    /// ```
    pub fn set_page_size<T>(mut self, v: T) -> Self
    where
        T: std::convert::Into<i32>,
    {
        self.page_size = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [page_size][crate::model::FetchModelsRequest::page_size].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchModelsRequest;
    /// let x = FetchModelsRequest::new().set_or_clear_page_size(Some(42));
    /// let x = FetchModelsRequest::new().set_or_clear_page_size(None::<i32>);
    /// ```
    pub fn set_or_clear_page_size<T>(mut self, v: std::option::Option<T>) -> Self
    where
        T: std::convert::Into<i32>,
    {
        self.page_size = v.map(|x| x.into());
        self
    }

    /// Sets the value of [page_token][crate::model::FetchModelsRequest::page_token].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchModelsRequest;
    /// let x = FetchModelsRequest::new().set_page_token("example");
    /// ```
    pub fn set_page_token<T>(mut self, v: T) -> Self
    where
        T: std::convert::Into<std::string::String>,
    {
        self.page_token = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [page_token][crate::model::FetchModelsRequest::page_token].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchModelsRequest;
    /// let x = FetchModelsRequest::new().set_or_clear_page_token(Some("example"));
    /// let x = FetchModelsRequest::new().set_or_clear_page_token(None::<String>);
    /// ```
    pub fn set_or_clear_page_token<T>(mut self, v: std::option::Option<T>) -> Self
    where
        T: std::convert::Into<std::string::String>,
    {
        self.page_token = v.map(|x| x.into());
        self
    }
}

impl wkt::message::Message for FetchModelsRequest {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.gkerecommender.v1.FetchModelsRequest"
    }
}

/// Response message for
/// [GkeInferenceQuickstart.FetchModels][google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchModels].
///
/// [google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchModels]: crate::client::GkeInferenceQuickstart::fetch_models
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct FetchModelsResponse {
    /// Output only. List of available models. Open-source models follow the
    /// Huggingface Hub `owner/model_name` format.
    pub models: std::vec::Vec<std::string::String>,

    /// Output only. A token which may be sent as
    /// [page_token][FetchModelsResponse.page_token] in a subsequent
    /// `FetchModelsResponse` call to retrieve the next page of results.
    /// If this field is omitted or empty, then there are no more results to
    /// return.
    pub next_page_token: std::string::String,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl FetchModelsResponse {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [models][crate::model::FetchModelsResponse::models].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchModelsResponse;
    /// let x = FetchModelsResponse::new().set_models(["a", "b", "c"]);
    /// ```
    pub fn set_models<T, V>(mut self, v: T) -> Self
    where
        T: std::iter::IntoIterator<Item = V>,
        V: std::convert::Into<std::string::String>,
    {
        use std::iter::Iterator;
        self.models = v.into_iter().map(|i| i.into()).collect();
        self
    }

    /// Sets the value of [next_page_token][crate::model::FetchModelsResponse::next_page_token].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchModelsResponse;
    /// let x = FetchModelsResponse::new().set_next_page_token("example");
    /// ```
    pub fn set_next_page_token<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.next_page_token = v.into();
        self
    }
}

impl wkt::message::Message for FetchModelsResponse {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.gkerecommender.v1.FetchModelsResponse"
    }
}

/// Request message for
/// [GkeInferenceQuickstart.FetchModelServers][google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchModelServers].
///
/// [google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchModelServers]: crate::client::GkeInferenceQuickstart::fetch_model_servers
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct FetchModelServersRequest {
    /// Required. The model for which to list model servers. Open-source models
    /// follow the Huggingface Hub `owner/model_name` format. Use
    /// [GkeInferenceQuickstart.FetchModels][google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchModels]
    /// to find available models.
    ///
    /// [google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchModels]: crate::client::GkeInferenceQuickstart::fetch_models
    pub model: std::string::String,

    /// Optional. The target number of results to return in a single response.
    /// If not specified, a default value will be chosen by the service.
    /// Note that the response may include a partial list and a caller should
    /// only rely on the response's
    /// [next_page_token][google.cloud.gkerecommender.v1.FetchModelServersResponse.next_page_token]
    /// to determine if there are more instances left to be queried.
    ///
    /// [google.cloud.gkerecommender.v1.FetchModelServersResponse.next_page_token]: crate::model::FetchModelServersResponse::next_page_token
    pub page_size: std::option::Option<i32>,

    /// Optional. The value of
    /// [next_page_token][google.cloud.gkerecommender.v1.FetchModelServersResponse.next_page_token]
    /// received from a previous `FetchModelServersRequest` call.
    /// Provide this to retrieve the subsequent page in a multi-page list of
    /// results. When paginating, all other parameters provided to
    /// `FetchModelServersRequest` must match the call that provided the page
    /// token.
    ///
    /// [google.cloud.gkerecommender.v1.FetchModelServersResponse.next_page_token]: crate::model::FetchModelServersResponse::next_page_token
    pub page_token: std::option::Option<std::string::String>,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl FetchModelServersRequest {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [model][crate::model::FetchModelServersRequest::model].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchModelServersRequest;
    /// let x = FetchModelServersRequest::new().set_model("example");
    /// ```
    pub fn set_model<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.model = v.into();
        self
    }

    /// Sets the value of [page_size][crate::model::FetchModelServersRequest::page_size].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchModelServersRequest;
    /// let x = FetchModelServersRequest::new().set_page_size(42);
    /// ```
    pub fn set_page_size<T>(mut self, v: T) -> Self
    where
        T: std::convert::Into<i32>,
    {
        self.page_size = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [page_size][crate::model::FetchModelServersRequest::page_size].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchModelServersRequest;
    /// let x = FetchModelServersRequest::new().set_or_clear_page_size(Some(42));
    /// let x = FetchModelServersRequest::new().set_or_clear_page_size(None::<i32>);
    /// ```
    pub fn set_or_clear_page_size<T>(mut self, v: std::option::Option<T>) -> Self
    where
        T: std::convert::Into<i32>,
    {
        self.page_size = v.map(|x| x.into());
        self
    }

    /// Sets the value of [page_token][crate::model::FetchModelServersRequest::page_token].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchModelServersRequest;
    /// let x = FetchModelServersRequest::new().set_page_token("example");
    /// ```
    pub fn set_page_token<T>(mut self, v: T) -> Self
    where
        T: std::convert::Into<std::string::String>,
    {
        self.page_token = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [page_token][crate::model::FetchModelServersRequest::page_token].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchModelServersRequest;
    /// let x = FetchModelServersRequest::new().set_or_clear_page_token(Some("example"));
    /// let x = FetchModelServersRequest::new().set_or_clear_page_token(None::<String>);
    /// ```
    pub fn set_or_clear_page_token<T>(mut self, v: std::option::Option<T>) -> Self
    where
        T: std::convert::Into<std::string::String>,
    {
        self.page_token = v.map(|x| x.into());
        self
    }
}

impl wkt::message::Message for FetchModelServersRequest {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.gkerecommender.v1.FetchModelServersRequest"
    }
}

/// Response message for
/// [GkeInferenceQuickstart.FetchModelServers][google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchModelServers].
///
/// [google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchModelServers]: crate::client::GkeInferenceQuickstart::fetch_model_servers
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct FetchModelServersResponse {
    /// Output only. List of available model servers. Open-source model servers use
    /// simplified, lowercase names (e.g., `vllm`).
    pub model_servers: std::vec::Vec<std::string::String>,

    /// Output only. A token which may be sent as
    /// [page_token][FetchModelServersResponse.page_token] in a subsequent
    /// `FetchModelServersResponse` call to retrieve the next page of results.
    /// If this field is omitted or empty, then there are no more results to
    /// return.
    pub next_page_token: std::string::String,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl FetchModelServersResponse {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [model_servers][crate::model::FetchModelServersResponse::model_servers].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchModelServersResponse;
    /// let x = FetchModelServersResponse::new().set_model_servers(["a", "b", "c"]);
    /// ```
    pub fn set_model_servers<T, V>(mut self, v: T) -> Self
    where
        T: std::iter::IntoIterator<Item = V>,
        V: std::convert::Into<std::string::String>,
    {
        use std::iter::Iterator;
        self.model_servers = v.into_iter().map(|i| i.into()).collect();
        self
    }

    /// Sets the value of [next_page_token][crate::model::FetchModelServersResponse::next_page_token].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchModelServersResponse;
    /// let x = FetchModelServersResponse::new().set_next_page_token("example");
    /// ```
    pub fn set_next_page_token<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.next_page_token = v.into();
        self
    }
}

impl wkt::message::Message for FetchModelServersResponse {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.gkerecommender.v1.FetchModelServersResponse"
    }
}

/// Request message for
/// [GkeInferenceQuickstart.FetchModelServerVersions][google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchModelServerVersions].
///
/// [google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchModelServerVersions]: crate::client::GkeInferenceQuickstart::fetch_model_server_versions
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct FetchModelServerVersionsRequest {
    /// Required. The model for which to list model server versions. Open-source
    /// models follow the Huggingface Hub `owner/model_name` format. Use
    /// [GkeInferenceQuickstart.FetchModels][google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchModels]
    /// to find available models.
    ///
    /// [google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchModels]: crate::client::GkeInferenceQuickstart::fetch_models
    pub model: std::string::String,

    /// Required. The model server for which to list versions. Open-source model
    /// servers use simplified, lowercase names (e.g., `vllm`). Use
    /// [GkeInferenceQuickstart.FetchModelServers][google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchModelServers]
    /// to find available model servers.
    ///
    /// [google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchModelServers]: crate::client::GkeInferenceQuickstart::fetch_model_servers
    pub model_server: std::string::String,

    /// Optional. The target number of results to return in a single response.
    /// If not specified, a default value will be chosen by the service.
    /// Note that the response may include a partial list and a caller should
    /// only rely on the response's
    /// [next_page_token][google.cloud.gkerecommender.v1.FetchModelServerVersionsResponse.next_page_token]
    /// to determine if there are more instances left to be queried.
    ///
    /// [google.cloud.gkerecommender.v1.FetchModelServerVersionsResponse.next_page_token]: crate::model::FetchModelServerVersionsResponse::next_page_token
    pub page_size: std::option::Option<i32>,

    /// Optional. The value of
    /// [next_page_token][google.cloud.gkerecommender.v1.FetchModelServerVersionsResponse.next_page_token]
    /// received from a previous `FetchModelServerVersionsRequest` call.
    /// Provide this to retrieve the subsequent page in a multi-page list of
    /// results. When paginating, all other parameters provided to
    /// `FetchModelServerVersionsRequest` must match the call that provided the
    /// page token.
    ///
    /// [google.cloud.gkerecommender.v1.FetchModelServerVersionsResponse.next_page_token]: crate::model::FetchModelServerVersionsResponse::next_page_token
    pub page_token: std::option::Option<std::string::String>,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl FetchModelServerVersionsRequest {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [model][crate::model::FetchModelServerVersionsRequest::model].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchModelServerVersionsRequest;
    /// let x = FetchModelServerVersionsRequest::new().set_model("example");
    /// ```
    pub fn set_model<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.model = v.into();
        self
    }

    /// Sets the value of [model_server][crate::model::FetchModelServerVersionsRequest::model_server].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchModelServerVersionsRequest;
    /// let x = FetchModelServerVersionsRequest::new().set_model_server("example");
    /// ```
    pub fn set_model_server<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.model_server = v.into();
        self
    }

    /// Sets the value of [page_size][crate::model::FetchModelServerVersionsRequest::page_size].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchModelServerVersionsRequest;
    /// let x = FetchModelServerVersionsRequest::new().set_page_size(42);
    /// ```
    pub fn set_page_size<T>(mut self, v: T) -> Self
    where
        T: std::convert::Into<i32>,
    {
        self.page_size = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [page_size][crate::model::FetchModelServerVersionsRequest::page_size].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchModelServerVersionsRequest;
    /// let x = FetchModelServerVersionsRequest::new().set_or_clear_page_size(Some(42));
    /// let x = FetchModelServerVersionsRequest::new().set_or_clear_page_size(None::<i32>);
    /// ```
    pub fn set_or_clear_page_size<T>(mut self, v: std::option::Option<T>) -> Self
    where
        T: std::convert::Into<i32>,
    {
        self.page_size = v.map(|x| x.into());
        self
    }

    /// Sets the value of [page_token][crate::model::FetchModelServerVersionsRequest::page_token].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchModelServerVersionsRequest;
    /// let x = FetchModelServerVersionsRequest::new().set_page_token("example");
    /// ```
    pub fn set_page_token<T>(mut self, v: T) -> Self
    where
        T: std::convert::Into<std::string::String>,
    {
        self.page_token = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [page_token][crate::model::FetchModelServerVersionsRequest::page_token].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchModelServerVersionsRequest;
    /// let x = FetchModelServerVersionsRequest::new().set_or_clear_page_token(Some("example"));
    /// let x = FetchModelServerVersionsRequest::new().set_or_clear_page_token(None::<String>);
    /// ```
    pub fn set_or_clear_page_token<T>(mut self, v: std::option::Option<T>) -> Self
    where
        T: std::convert::Into<std::string::String>,
    {
        self.page_token = v.map(|x| x.into());
        self
    }
}

impl wkt::message::Message for FetchModelServerVersionsRequest {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.gkerecommender.v1.FetchModelServerVersionsRequest"
    }
}

/// Response message for
/// [GkeInferenceQuickstart.FetchModelServerVersions][google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchModelServerVersions].
///
/// [google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchModelServerVersions]: crate::client::GkeInferenceQuickstart::fetch_model_server_versions
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct FetchModelServerVersionsResponse {
    /// Output only. A list of available model server versions.
    pub model_server_versions: std::vec::Vec<std::string::String>,

    /// Output only. A token which may be sent as
    /// [page_token][FetchModelServerVersionsResponse.page_token] in a subsequent
    /// `FetchModelServerVersionsResponse` call to retrieve the next page of
    /// results. If this field is omitted or empty, then there are no more results
    /// to return.
    pub next_page_token: std::string::String,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl FetchModelServerVersionsResponse {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [model_server_versions][crate::model::FetchModelServerVersionsResponse::model_server_versions].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchModelServerVersionsResponse;
    /// let x = FetchModelServerVersionsResponse::new().set_model_server_versions(["a", "b", "c"]);
    /// ```
    pub fn set_model_server_versions<T, V>(mut self, v: T) -> Self
    where
        T: std::iter::IntoIterator<Item = V>,
        V: std::convert::Into<std::string::String>,
    {
        use std::iter::Iterator;
        self.model_server_versions = v.into_iter().map(|i| i.into()).collect();
        self
    }

    /// Sets the value of [next_page_token][crate::model::FetchModelServerVersionsResponse::next_page_token].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchModelServerVersionsResponse;
    /// let x = FetchModelServerVersionsResponse::new().set_next_page_token("example");
    /// ```
    pub fn set_next_page_token<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.next_page_token = v.into();
        self
    }
}

impl wkt::message::Message for FetchModelServerVersionsResponse {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.gkerecommender.v1.FetchModelServerVersionsResponse"
    }
}

/// Request message for
/// [GkeInferenceQuickstart.FetchBenchmarkingData][google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchBenchmarkingData].
///
/// [google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchBenchmarkingData]: crate::client::GkeInferenceQuickstart::fetch_benchmarking_data
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct FetchBenchmarkingDataRequest {
    /// Required. The model server configuration to get benchmarking data for. Use
    /// [GkeInferenceQuickstart.FetchProfiles][google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchProfiles]
    /// to find valid configurations.
    ///
    /// [google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchProfiles]: crate::client::GkeInferenceQuickstart::fetch_profiles
    pub model_server_info: std::option::Option<crate::model::ModelServerInfo>,

    /// Optional. The instance type to filter benchmarking data. Instance types are
    /// in the format `a2-highgpu-1g`. If not provided, all instance types for the
    /// given profile's `model_server_info` will be returned. Use
    /// [GkeInferenceQuickstart.FetchProfiles][google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchProfiles]
    /// to find available instance types.
    ///
    /// [google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchProfiles]: crate::client::GkeInferenceQuickstart::fetch_profiles
    pub instance_type: std::string::String,

    /// Optional. The pricing model to use for the benchmarking data. Defaults to
    /// `spot`.
    pub pricing_model: std::string::String,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl FetchBenchmarkingDataRequest {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [model_server_info][crate::model::FetchBenchmarkingDataRequest::model_server_info].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchBenchmarkingDataRequest;
    /// use google_cloud_gkerecommender_v1::model::ModelServerInfo;
    /// let x = FetchBenchmarkingDataRequest::new().set_model_server_info(ModelServerInfo::default()/* use setters */);
    /// ```
    pub fn set_model_server_info<T>(mut self, v: T) -> Self
    where
        T: std::convert::Into<crate::model::ModelServerInfo>,
    {
        self.model_server_info = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [model_server_info][crate::model::FetchBenchmarkingDataRequest::model_server_info].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchBenchmarkingDataRequest;
    /// use google_cloud_gkerecommender_v1::model::ModelServerInfo;
    /// let x = FetchBenchmarkingDataRequest::new().set_or_clear_model_server_info(Some(ModelServerInfo::default()/* use setters */));
    /// let x = FetchBenchmarkingDataRequest::new().set_or_clear_model_server_info(None::<ModelServerInfo>);
    /// ```
    pub fn set_or_clear_model_server_info<T>(mut self, v: std::option::Option<T>) -> Self
    where
        T: std::convert::Into<crate::model::ModelServerInfo>,
    {
        self.model_server_info = v.map(|x| x.into());
        self
    }

    /// Sets the value of [instance_type][crate::model::FetchBenchmarkingDataRequest::instance_type].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchBenchmarkingDataRequest;
    /// let x = FetchBenchmarkingDataRequest::new().set_instance_type("example");
    /// ```
    pub fn set_instance_type<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.instance_type = v.into();
        self
    }

    /// Sets the value of [pricing_model][crate::model::FetchBenchmarkingDataRequest::pricing_model].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchBenchmarkingDataRequest;
    /// let x = FetchBenchmarkingDataRequest::new().set_pricing_model("example");
    /// ```
    pub fn set_pricing_model<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.pricing_model = v.into();
        self
    }
}

impl wkt::message::Message for FetchBenchmarkingDataRequest {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.gkerecommender.v1.FetchBenchmarkingDataRequest"
    }
}

/// Response message for
/// [GkeInferenceQuickstart.FetchBenchmarkingData][google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchBenchmarkingData].
///
/// [google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchBenchmarkingData]: crate::client::GkeInferenceQuickstart::fetch_benchmarking_data
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct FetchBenchmarkingDataResponse {
    /// Output only. List of profiles containing their respective benchmarking
    /// data.
    pub profile: std::vec::Vec<crate::model::Profile>,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl FetchBenchmarkingDataResponse {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [profile][crate::model::FetchBenchmarkingDataResponse::profile].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchBenchmarkingDataResponse;
    /// use google_cloud_gkerecommender_v1::model::Profile;
    /// let x = FetchBenchmarkingDataResponse::new()
    ///     .set_profile([
    ///         Profile::default()/* use setters */,
    ///         Profile::default()/* use (different) setters */,
    ///     ]);
    /// ```
    pub fn set_profile<T, V>(mut self, v: T) -> Self
    where
        T: std::iter::IntoIterator<Item = V>,
        V: std::convert::Into<crate::model::Profile>,
    {
        use std::iter::Iterator;
        self.profile = v.into_iter().map(|i| i.into()).collect();
        self
    }
}

impl wkt::message::Message for FetchBenchmarkingDataResponse {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.gkerecommender.v1.FetchBenchmarkingDataResponse"
    }
}

/// Request message for
/// [GkeInferenceQuickstart.FetchProfiles][google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchProfiles].
///
/// [google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchProfiles]: crate::client::GkeInferenceQuickstart::fetch_profiles
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct FetchProfilesRequest {
    /// Optional. The model to filter profiles by. Open-source models follow the
    /// Huggingface Hub `owner/model_name` format. If not provided, all models are
    /// returned. Use
    /// [GkeInferenceQuickstart.FetchModels][google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchModels]
    /// to find available models.
    ///
    /// [google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchModels]: crate::client::GkeInferenceQuickstart::fetch_models
    pub model: std::string::String,

    /// Optional. The model server to filter profiles by. If not provided, all
    /// model servers are returned. Use
    /// [GkeInferenceQuickstart.FetchModelServers][google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchModelServers]
    /// to find available model servers for a given model.
    ///
    /// [google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchModelServers]: crate::client::GkeInferenceQuickstart::fetch_model_servers
    pub model_server: std::string::String,

    /// Optional. The model server version to filter profiles by. If not provided,
    /// all model server versions are returned. Use
    /// [GkeInferenceQuickstart.FetchModelServerVersions][google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchModelServerVersions]
    /// to find available versions for a given model and server.
    ///
    /// [google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchModelServerVersions]: crate::client::GkeInferenceQuickstart::fetch_model_server_versions
    pub model_server_version: std::string::String,

    /// Optional. The performance requirements to filter profiles. Profiles that do
    /// not meet these requirements are filtered out. If not provided, all profiles
    /// are returned.
    pub performance_requirements: std::option::Option<crate::model::PerformanceRequirements>,

    /// Optional. The target number of results to return in a single response. If
    /// not specified, a default value will be chosen by the service. Note that the
    /// response may include a partial list and a caller should only rely on the
    /// response's
    /// [next_page_token][google.cloud.gkerecommender.v1.FetchProfilesResponse.next_page_token]
    /// to determine if there are more instances left to be queried.
    ///
    /// [google.cloud.gkerecommender.v1.FetchProfilesResponse.next_page_token]: crate::model::FetchProfilesResponse::next_page_token
    pub page_size: std::option::Option<i32>,

    /// Optional. The value of
    /// [next_page_token][google.cloud.gkerecommender.v1.FetchProfilesResponse.next_page_token]
    /// received from a previous `FetchProfilesRequest` call.
    /// Provide this to retrieve the subsequent page in a multi-page list of
    /// results. When paginating, all other parameters provided to
    /// `FetchProfilesRequest` must match the call that provided the page
    /// token.
    ///
    /// [google.cloud.gkerecommender.v1.FetchProfilesResponse.next_page_token]: crate::model::FetchProfilesResponse::next_page_token
    pub page_token: std::option::Option<std::string::String>,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl FetchProfilesRequest {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [model][crate::model::FetchProfilesRequest::model].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchProfilesRequest;
    /// let x = FetchProfilesRequest::new().set_model("example");
    /// ```
    pub fn set_model<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.model = v.into();
        self
    }

    /// Sets the value of [model_server][crate::model::FetchProfilesRequest::model_server].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchProfilesRequest;
    /// let x = FetchProfilesRequest::new().set_model_server("example");
    /// ```
    pub fn set_model_server<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.model_server = v.into();
        self
    }

    /// Sets the value of [model_server_version][crate::model::FetchProfilesRequest::model_server_version].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchProfilesRequest;
    /// let x = FetchProfilesRequest::new().set_model_server_version("example");
    /// ```
    pub fn set_model_server_version<T: std::convert::Into<std::string::String>>(
        mut self,
        v: T,
    ) -> Self {
        self.model_server_version = v.into();
        self
    }

    /// Sets the value of [performance_requirements][crate::model::FetchProfilesRequest::performance_requirements].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchProfilesRequest;
    /// use google_cloud_gkerecommender_v1::model::PerformanceRequirements;
    /// let x = FetchProfilesRequest::new().set_performance_requirements(PerformanceRequirements::default()/* use setters */);
    /// ```
    pub fn set_performance_requirements<T>(mut self, v: T) -> Self
    where
        T: std::convert::Into<crate::model::PerformanceRequirements>,
    {
        self.performance_requirements = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [performance_requirements][crate::model::FetchProfilesRequest::performance_requirements].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchProfilesRequest;
    /// use google_cloud_gkerecommender_v1::model::PerformanceRequirements;
    /// let x = FetchProfilesRequest::new().set_or_clear_performance_requirements(Some(PerformanceRequirements::default()/* use setters */));
    /// let x = FetchProfilesRequest::new().set_or_clear_performance_requirements(None::<PerformanceRequirements>);
    /// ```
    pub fn set_or_clear_performance_requirements<T>(mut self, v: std::option::Option<T>) -> Self
    where
        T: std::convert::Into<crate::model::PerformanceRequirements>,
    {
        self.performance_requirements = v.map(|x| x.into());
        self
    }

    /// Sets the value of [page_size][crate::model::FetchProfilesRequest::page_size].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchProfilesRequest;
    /// let x = FetchProfilesRequest::new().set_page_size(42);
    /// ```
    pub fn set_page_size<T>(mut self, v: T) -> Self
    where
        T: std::convert::Into<i32>,
    {
        self.page_size = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [page_size][crate::model::FetchProfilesRequest::page_size].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchProfilesRequest;
    /// let x = FetchProfilesRequest::new().set_or_clear_page_size(Some(42));
    /// let x = FetchProfilesRequest::new().set_or_clear_page_size(None::<i32>);
    /// ```
    pub fn set_or_clear_page_size<T>(mut self, v: std::option::Option<T>) -> Self
    where
        T: std::convert::Into<i32>,
    {
        self.page_size = v.map(|x| x.into());
        self
    }

    /// Sets the value of [page_token][crate::model::FetchProfilesRequest::page_token].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchProfilesRequest;
    /// let x = FetchProfilesRequest::new().set_page_token("example");
    /// ```
    pub fn set_page_token<T>(mut self, v: T) -> Self
    where
        T: std::convert::Into<std::string::String>,
    {
        self.page_token = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [page_token][crate::model::FetchProfilesRequest::page_token].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchProfilesRequest;
    /// let x = FetchProfilesRequest::new().set_or_clear_page_token(Some("example"));
    /// let x = FetchProfilesRequest::new().set_or_clear_page_token(None::<String>);
    /// ```
    pub fn set_or_clear_page_token<T>(mut self, v: std::option::Option<T>) -> Self
    where
        T: std::convert::Into<std::string::String>,
    {
        self.page_token = v.map(|x| x.into());
        self
    }
}

impl wkt::message::Message for FetchProfilesRequest {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.gkerecommender.v1.FetchProfilesRequest"
    }
}

/// Performance requirements for a profile and or model deployment.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct PerformanceRequirements {
    /// Optional. The target Normalized Time Per Output Token (NTPOT) in
    /// milliseconds. NTPOT is calculated as `request_latency /
    /// total_output_tokens`. If not provided, this target will not be enforced.
    pub target_ntpot_milliseconds: std::option::Option<i32>,

    /// Optional. The target Time To First Token (TTFT) in milliseconds. TTFT is
    /// the time it takes to generate the first token for a request.  If not
    /// provided, this target will not be enforced.
    pub target_ttft_milliseconds: std::option::Option<i32>,

    /// Optional. The target cost for running a profile's model server. If not
    /// provided, this requirement will not be enforced.
    pub target_cost: std::option::Option<crate::model::Cost>,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl PerformanceRequirements {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [target_ntpot_milliseconds][crate::model::PerformanceRequirements::target_ntpot_milliseconds].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::PerformanceRequirements;
    /// let x = PerformanceRequirements::new().set_target_ntpot_milliseconds(42);
    /// ```
    pub fn set_target_ntpot_milliseconds<T>(mut self, v: T) -> Self
    where
        T: std::convert::Into<i32>,
    {
        self.target_ntpot_milliseconds = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [target_ntpot_milliseconds][crate::model::PerformanceRequirements::target_ntpot_milliseconds].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::PerformanceRequirements;
    /// let x = PerformanceRequirements::new().set_or_clear_target_ntpot_milliseconds(Some(42));
    /// let x = PerformanceRequirements::new().set_or_clear_target_ntpot_milliseconds(None::<i32>);
    /// ```
    pub fn set_or_clear_target_ntpot_milliseconds<T>(mut self, v: std::option::Option<T>) -> Self
    where
        T: std::convert::Into<i32>,
    {
        self.target_ntpot_milliseconds = v.map(|x| x.into());
        self
    }

    /// Sets the value of [target_ttft_milliseconds][crate::model::PerformanceRequirements::target_ttft_milliseconds].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::PerformanceRequirements;
    /// let x = PerformanceRequirements::new().set_target_ttft_milliseconds(42);
    /// ```
    pub fn set_target_ttft_milliseconds<T>(mut self, v: T) -> Self
    where
        T: std::convert::Into<i32>,
    {
        self.target_ttft_milliseconds = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [target_ttft_milliseconds][crate::model::PerformanceRequirements::target_ttft_milliseconds].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::PerformanceRequirements;
    /// let x = PerformanceRequirements::new().set_or_clear_target_ttft_milliseconds(Some(42));
    /// let x = PerformanceRequirements::new().set_or_clear_target_ttft_milliseconds(None::<i32>);
    /// ```
    pub fn set_or_clear_target_ttft_milliseconds<T>(mut self, v: std::option::Option<T>) -> Self
    where
        T: std::convert::Into<i32>,
    {
        self.target_ttft_milliseconds = v.map(|x| x.into());
        self
    }

    /// Sets the value of [target_cost][crate::model::PerformanceRequirements::target_cost].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::PerformanceRequirements;
    /// use google_cloud_gkerecommender_v1::model::Cost;
    /// let x = PerformanceRequirements::new().set_target_cost(Cost::default()/* use setters */);
    /// ```
    pub fn set_target_cost<T>(mut self, v: T) -> Self
    where
        T: std::convert::Into<crate::model::Cost>,
    {
        self.target_cost = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [target_cost][crate::model::PerformanceRequirements::target_cost].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::PerformanceRequirements;
    /// use google_cloud_gkerecommender_v1::model::Cost;
    /// let x = PerformanceRequirements::new().set_or_clear_target_cost(Some(Cost::default()/* use setters */));
    /// let x = PerformanceRequirements::new().set_or_clear_target_cost(None::<Cost>);
    /// ```
    pub fn set_or_clear_target_cost<T>(mut self, v: std::option::Option<T>) -> Self
    where
        T: std::convert::Into<crate::model::Cost>,
    {
        self.target_cost = v.map(|x| x.into());
        self
    }
}

impl wkt::message::Message for PerformanceRequirements {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.gkerecommender.v1.PerformanceRequirements"
    }
}

/// Represents an amount of money in a specific currency.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct Amount {
    /// Output only. The whole units of the amount.
    /// For example if `currencyCode` is `"USD"`, then 1 unit is one US dollar.
    pub units: i64,

    /// Output only. Number of nano (10^-9) units of the amount.
    /// The value must be between -999,999,999 and +999,999,999 inclusive.
    /// If `units` is positive, `nanos` must be positive or zero.
    /// If `units` is zero, `nanos` can be positive, zero, or negative.
    /// If `units` is negative, `nanos` must be negative or zero.
    /// For example $-1.75 is represented as `units`=-1 and `nanos`=-750,000,000.
    pub nanos: i32,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl Amount {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [units][crate::model::Amount::units].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::Amount;
    /// let x = Amount::new().set_units(42);
    /// ```
    pub fn set_units<T: std::convert::Into<i64>>(mut self, v: T) -> Self {
        self.units = v.into();
        self
    }

    /// Sets the value of [nanos][crate::model::Amount::nanos].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::Amount;
    /// let x = Amount::new().set_nanos(42);
    /// ```
    pub fn set_nanos<T: std::convert::Into<i32>>(mut self, v: T) -> Self {
        self.nanos = v.into();
        self
    }
}

impl wkt::message::Message for Amount {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.gkerecommender.v1.Amount"
    }
}

/// Cost for running a model deployment on a given instance type. Currently, only
/// USD currency code is supported.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct Cost {
    /// Optional. The cost per million output tokens, calculated as:
    /// $/output token = GPU $/s / (1/output-to-input-cost-ratio * input tokens/s +
    /// output tokens/s)
    pub cost_per_million_output_tokens: std::option::Option<crate::model::Amount>,

    /// Optional. The cost per million input tokens. $/input token = ($/output
    /// token) / output-to-input-cost-ratio.
    pub cost_per_million_input_tokens: std::option::Option<crate::model::Amount>,

    /// Optional. The pricing model used to calculate the cost. Can be one of:
    /// `3-years-cud`, `1-year-cud`, `on-demand`, `spot`. If not provided, `spot`
    /// will be used.
    pub pricing_model: std::string::String,

    /// Optional. The output-to-input cost ratio. This determines how the total GPU
    /// cost is split between input and output tokens. If not provided, `4.0` is
    /// used, assuming a 4:1 output:input cost ratio.
    pub output_input_cost_ratio: std::option::Option<f32>,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl Cost {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [cost_per_million_output_tokens][crate::model::Cost::cost_per_million_output_tokens].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::Cost;
    /// use google_cloud_gkerecommender_v1::model::Amount;
    /// let x = Cost::new().set_cost_per_million_output_tokens(Amount::default()/* use setters */);
    /// ```
    pub fn set_cost_per_million_output_tokens<T>(mut self, v: T) -> Self
    where
        T: std::convert::Into<crate::model::Amount>,
    {
        self.cost_per_million_output_tokens = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [cost_per_million_output_tokens][crate::model::Cost::cost_per_million_output_tokens].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::Cost;
    /// use google_cloud_gkerecommender_v1::model::Amount;
    /// let x = Cost::new().set_or_clear_cost_per_million_output_tokens(Some(Amount::default()/* use setters */));
    /// let x = Cost::new().set_or_clear_cost_per_million_output_tokens(None::<Amount>);
    /// ```
    pub fn set_or_clear_cost_per_million_output_tokens<T>(
        mut self,
        v: std::option::Option<T>,
    ) -> Self
    where
        T: std::convert::Into<crate::model::Amount>,
    {
        self.cost_per_million_output_tokens = v.map(|x| x.into());
        self
    }

    /// Sets the value of [cost_per_million_input_tokens][crate::model::Cost::cost_per_million_input_tokens].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::Cost;
    /// use google_cloud_gkerecommender_v1::model::Amount;
    /// let x = Cost::new().set_cost_per_million_input_tokens(Amount::default()/* use setters */);
    /// ```
    pub fn set_cost_per_million_input_tokens<T>(mut self, v: T) -> Self
    where
        T: std::convert::Into<crate::model::Amount>,
    {
        self.cost_per_million_input_tokens = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [cost_per_million_input_tokens][crate::model::Cost::cost_per_million_input_tokens].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::Cost;
    /// use google_cloud_gkerecommender_v1::model::Amount;
    /// let x = Cost::new().set_or_clear_cost_per_million_input_tokens(Some(Amount::default()/* use setters */));
    /// let x = Cost::new().set_or_clear_cost_per_million_input_tokens(None::<Amount>);
    /// ```
    pub fn set_or_clear_cost_per_million_input_tokens<T>(
        mut self,
        v: std::option::Option<T>,
    ) -> Self
    where
        T: std::convert::Into<crate::model::Amount>,
    {
        self.cost_per_million_input_tokens = v.map(|x| x.into());
        self
    }

    /// Sets the value of [pricing_model][crate::model::Cost::pricing_model].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::Cost;
    /// let x = Cost::new().set_pricing_model("example");
    /// ```
    pub fn set_pricing_model<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.pricing_model = v.into();
        self
    }

    /// Sets the value of [output_input_cost_ratio][crate::model::Cost::output_input_cost_ratio].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::Cost;
    /// let x = Cost::new().set_output_input_cost_ratio(42.0);
    /// ```
    pub fn set_output_input_cost_ratio<T>(mut self, v: T) -> Self
    where
        T: std::convert::Into<f32>,
    {
        self.output_input_cost_ratio = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [output_input_cost_ratio][crate::model::Cost::output_input_cost_ratio].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::Cost;
    /// let x = Cost::new().set_or_clear_output_input_cost_ratio(Some(42.0));
    /// let x = Cost::new().set_or_clear_output_input_cost_ratio(None::<f32>);
    /// ```
    pub fn set_or_clear_output_input_cost_ratio<T>(mut self, v: std::option::Option<T>) -> Self
    where
        T: std::convert::Into<f32>,
    {
        self.output_input_cost_ratio = v.map(|x| x.into());
        self
    }
}

impl wkt::message::Message for Cost {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.gkerecommender.v1.Cost"
    }
}

/// Represents a range of throughput values in tokens per second.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct TokensPerSecondRange {
    /// Output only. The minimum value of the range.
    pub min: i32,

    /// Output only. The maximum value of the range.
    pub max: i32,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl TokensPerSecondRange {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [min][crate::model::TokensPerSecondRange::min].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::TokensPerSecondRange;
    /// let x = TokensPerSecondRange::new().set_min(42);
    /// ```
    pub fn set_min<T: std::convert::Into<i32>>(mut self, v: T) -> Self {
        self.min = v.into();
        self
    }

    /// Sets the value of [max][crate::model::TokensPerSecondRange::max].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::TokensPerSecondRange;
    /// let x = TokensPerSecondRange::new().set_max(42);
    /// ```
    pub fn set_max<T: std::convert::Into<i32>>(mut self, v: T) -> Self {
        self.max = v.into();
        self
    }
}

impl wkt::message::Message for TokensPerSecondRange {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.gkerecommender.v1.TokensPerSecondRange"
    }
}

/// Represents a range of latency values in milliseconds.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct MillisecondRange {
    /// Output only. The minimum value of the range.
    pub min: i32,

    /// Output only. The maximum value of the range.
    pub max: i32,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl MillisecondRange {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [min][crate::model::MillisecondRange::min].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::MillisecondRange;
    /// let x = MillisecondRange::new().set_min(42);
    /// ```
    pub fn set_min<T: std::convert::Into<i32>>(mut self, v: T) -> Self {
        self.min = v.into();
        self
    }

    /// Sets the value of [max][crate::model::MillisecondRange::max].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::MillisecondRange;
    /// let x = MillisecondRange::new().set_max(42);
    /// ```
    pub fn set_max<T: std::convert::Into<i32>>(mut self, v: T) -> Self {
        self.max = v.into();
        self
    }
}

impl wkt::message::Message for MillisecondRange {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.gkerecommender.v1.MillisecondRange"
    }
}

/// Performance range for a model deployment.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct PerformanceRange {
    /// Output only. The range of throughput in output tokens per second. This is
    /// measured as total_output_tokens_generated_by_server /
    /// elapsed_time_in_seconds.
    pub throughput_output_range: std::option::Option<crate::model::TokensPerSecondRange>,

    /// Output only. The range of TTFT (Time To First Token) in milliseconds. TTFT
    /// is the time it takes to generate the first token for a request.
    pub ttft_range: std::option::Option<crate::model::MillisecondRange>,

    /// Output only. The range of NTPOT (Normalized Time Per Output Token) in
    /// milliseconds. NTPOT is the request latency normalized by the number of
    /// output tokens, measured as request_latency / total_output_tokens.
    pub ntpot_range: std::option::Option<crate::model::MillisecondRange>,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl PerformanceRange {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [throughput_output_range][crate::model::PerformanceRange::throughput_output_range].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::PerformanceRange;
    /// use google_cloud_gkerecommender_v1::model::TokensPerSecondRange;
    /// let x = PerformanceRange::new().set_throughput_output_range(TokensPerSecondRange::default()/* use setters */);
    /// ```
    pub fn set_throughput_output_range<T>(mut self, v: T) -> Self
    where
        T: std::convert::Into<crate::model::TokensPerSecondRange>,
    {
        self.throughput_output_range = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [throughput_output_range][crate::model::PerformanceRange::throughput_output_range].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::PerformanceRange;
    /// use google_cloud_gkerecommender_v1::model::TokensPerSecondRange;
    /// let x = PerformanceRange::new().set_or_clear_throughput_output_range(Some(TokensPerSecondRange::default()/* use setters */));
    /// let x = PerformanceRange::new().set_or_clear_throughput_output_range(None::<TokensPerSecondRange>);
    /// ```
    pub fn set_or_clear_throughput_output_range<T>(mut self, v: std::option::Option<T>) -> Self
    where
        T: std::convert::Into<crate::model::TokensPerSecondRange>,
    {
        self.throughput_output_range = v.map(|x| x.into());
        self
    }

    /// Sets the value of [ttft_range][crate::model::PerformanceRange::ttft_range].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::PerformanceRange;
    /// use google_cloud_gkerecommender_v1::model::MillisecondRange;
    /// let x = PerformanceRange::new().set_ttft_range(MillisecondRange::default()/* use setters */);
    /// ```
    pub fn set_ttft_range<T>(mut self, v: T) -> Self
    where
        T: std::convert::Into<crate::model::MillisecondRange>,
    {
        self.ttft_range = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [ttft_range][crate::model::PerformanceRange::ttft_range].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::PerformanceRange;
    /// use google_cloud_gkerecommender_v1::model::MillisecondRange;
    /// let x = PerformanceRange::new().set_or_clear_ttft_range(Some(MillisecondRange::default()/* use setters */));
    /// let x = PerformanceRange::new().set_or_clear_ttft_range(None::<MillisecondRange>);
    /// ```
    pub fn set_or_clear_ttft_range<T>(mut self, v: std::option::Option<T>) -> Self
    where
        T: std::convert::Into<crate::model::MillisecondRange>,
    {
        self.ttft_range = v.map(|x| x.into());
        self
    }

    /// Sets the value of [ntpot_range][crate::model::PerformanceRange::ntpot_range].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::PerformanceRange;
    /// use google_cloud_gkerecommender_v1::model::MillisecondRange;
    /// let x = PerformanceRange::new().set_ntpot_range(MillisecondRange::default()/* use setters */);
    /// ```
    pub fn set_ntpot_range<T>(mut self, v: T) -> Self
    where
        T: std::convert::Into<crate::model::MillisecondRange>,
    {
        self.ntpot_range = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [ntpot_range][crate::model::PerformanceRange::ntpot_range].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::PerformanceRange;
    /// use google_cloud_gkerecommender_v1::model::MillisecondRange;
    /// let x = PerformanceRange::new().set_or_clear_ntpot_range(Some(MillisecondRange::default()/* use setters */));
    /// let x = PerformanceRange::new().set_or_clear_ntpot_range(None::<MillisecondRange>);
    /// ```
    pub fn set_or_clear_ntpot_range<T>(mut self, v: std::option::Option<T>) -> Self
    where
        T: std::convert::Into<crate::model::MillisecondRange>,
    {
        self.ntpot_range = v.map(|x| x.into());
        self
    }
}

impl wkt::message::Message for PerformanceRange {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.gkerecommender.v1.PerformanceRange"
    }
}

/// Response message for
/// [GkeInferenceQuickstart.FetchProfiles][google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchProfiles].
///
/// [google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchProfiles]: crate::client::GkeInferenceQuickstart::fetch_profiles
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct FetchProfilesResponse {
    /// Output only. List of profiles that match the given model server info and
    /// performance requirements (if provided).
    pub profile: std::vec::Vec<crate::model::Profile>,

    /// Output only. The combined range of performance values observed across all
    /// profiles in this response.
    pub performance_range: std::option::Option<crate::model::PerformanceRange>,

    /// Output only. Additional comments related to the response.
    pub comments: std::string::String,

    /// Output only. A token which may be sent as
    /// [page_token][FetchProfilesResponse.page_token] in a subsequent
    /// `FetchProfilesResponse` call to retrieve the next page of results. If this
    /// field is omitted or empty, then there are no more results to return.
    pub next_page_token: std::string::String,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl FetchProfilesResponse {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [profile][crate::model::FetchProfilesResponse::profile].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchProfilesResponse;
    /// use google_cloud_gkerecommender_v1::model::Profile;
    /// let x = FetchProfilesResponse::new()
    ///     .set_profile([
    ///         Profile::default()/* use setters */,
    ///         Profile::default()/* use (different) setters */,
    ///     ]);
    /// ```
    pub fn set_profile<T, V>(mut self, v: T) -> Self
    where
        T: std::iter::IntoIterator<Item = V>,
        V: std::convert::Into<crate::model::Profile>,
    {
        use std::iter::Iterator;
        self.profile = v.into_iter().map(|i| i.into()).collect();
        self
    }

    /// Sets the value of [performance_range][crate::model::FetchProfilesResponse::performance_range].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchProfilesResponse;
    /// use google_cloud_gkerecommender_v1::model::PerformanceRange;
    /// let x = FetchProfilesResponse::new().set_performance_range(PerformanceRange::default()/* use setters */);
    /// ```
    pub fn set_performance_range<T>(mut self, v: T) -> Self
    where
        T: std::convert::Into<crate::model::PerformanceRange>,
    {
        self.performance_range = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [performance_range][crate::model::FetchProfilesResponse::performance_range].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchProfilesResponse;
    /// use google_cloud_gkerecommender_v1::model::PerformanceRange;
    /// let x = FetchProfilesResponse::new().set_or_clear_performance_range(Some(PerformanceRange::default()/* use setters */));
    /// let x = FetchProfilesResponse::new().set_or_clear_performance_range(None::<PerformanceRange>);
    /// ```
    pub fn set_or_clear_performance_range<T>(mut self, v: std::option::Option<T>) -> Self
    where
        T: std::convert::Into<crate::model::PerformanceRange>,
    {
        self.performance_range = v.map(|x| x.into());
        self
    }

    /// Sets the value of [comments][crate::model::FetchProfilesResponse::comments].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchProfilesResponse;
    /// let x = FetchProfilesResponse::new().set_comments("example");
    /// ```
    pub fn set_comments<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.comments = v.into();
        self
    }

    /// Sets the value of [next_page_token][crate::model::FetchProfilesResponse::next_page_token].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::FetchProfilesResponse;
    /// let x = FetchProfilesResponse::new().set_next_page_token("example");
    /// ```
    pub fn set_next_page_token<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.next_page_token = v.into();
        self
    }
}

impl wkt::message::Message for FetchProfilesResponse {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.gkerecommender.v1.FetchProfilesResponse"
    }
}

#[doc(hidden)]
impl gax::paginator::internal::PageableResponse for FetchProfilesResponse {
    type PageItem = crate::model::Profile;

    fn items(self) -> std::vec::Vec<Self::PageItem> {
        self.profile
    }

    fn next_page_token(&self) -> std::string::String {
        use std::clone::Clone;
        self.next_page_token.clone()
    }
}

/// Model server information gives. Valid model server info combinations can
/// be found using
/// [GkeInferenceQuickstart.FetchProfiles][google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchProfiles].
///
/// [google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchProfiles]: crate::client::GkeInferenceQuickstart::fetch_profiles
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct ModelServerInfo {
    /// Required. The model. Open-source models follow the Huggingface Hub
    /// `owner/model_name` format. Use
    /// [GkeInferenceQuickstart.FetchModels][google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchModels]
    /// to find available models.
    ///
    /// [google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchModels]: crate::client::GkeInferenceQuickstart::fetch_models
    pub model: std::string::String,

    /// Required. The model server. Open-source model servers use simplified,
    /// lowercase names (e.g., `vllm`). Use
    /// [GkeInferenceQuickstart.FetchModelServers][google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchModelServers]
    /// to find available servers.
    ///
    /// [google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchModelServers]: crate::client::GkeInferenceQuickstart::fetch_model_servers
    pub model_server: std::string::String,

    /// Optional. The model server version. Use
    /// [GkeInferenceQuickstart.FetchModelServerVersions][google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchModelServerVersions]
    /// to find available versions. If not provided, the latest available version
    /// is used.
    ///
    /// [google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchModelServerVersions]: crate::client::GkeInferenceQuickstart::fetch_model_server_versions
    pub model_server_version: std::string::String,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl ModelServerInfo {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [model][crate::model::ModelServerInfo::model].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::ModelServerInfo;
    /// let x = ModelServerInfo::new().set_model("example");
    /// ```
    pub fn set_model<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.model = v.into();
        self
    }

    /// Sets the value of [model_server][crate::model::ModelServerInfo::model_server].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::ModelServerInfo;
    /// let x = ModelServerInfo::new().set_model_server("example");
    /// ```
    pub fn set_model_server<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.model_server = v.into();
        self
    }

    /// Sets the value of [model_server_version][crate::model::ModelServerInfo::model_server_version].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::ModelServerInfo;
    /// let x = ModelServerInfo::new().set_model_server_version("example");
    /// ```
    pub fn set_model_server_version<T: std::convert::Into<std::string::String>>(
        mut self,
        v: T,
    ) -> Self {
        self.model_server_version = v.into();
        self
    }
}

impl wkt::message::Message for ModelServerInfo {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.gkerecommender.v1.ModelServerInfo"
    }
}

/// Resources used by a model deployment.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct ResourcesUsed {
    /// Output only. The number of accelerators (e.g., GPUs or TPUs) used by the
    /// model deployment on the Kubernetes node.
    pub accelerator_count: i32,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl ResourcesUsed {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [accelerator_count][crate::model::ResourcesUsed::accelerator_count].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::ResourcesUsed;
    /// let x = ResourcesUsed::new().set_accelerator_count(42);
    /// ```
    pub fn set_accelerator_count<T: std::convert::Into<i32>>(mut self, v: T) -> Self {
        self.accelerator_count = v.into();
        self
    }
}

impl wkt::message::Message for ResourcesUsed {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.gkerecommender.v1.ResourcesUsed"
    }
}

/// Performance statistics for a model deployment.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct PerformanceStats {
    /// Output only. The number of queries per second.
    /// Note: This metric can vary widely based on context length and may not be a
    /// reliable measure of LLM throughput.
    pub queries_per_second: f32,

    /// Output only. The number of output tokens per second. This is the throughput
    /// measured as total_output_tokens_generated_by_server /
    /// elapsed_time_in_seconds.
    pub output_tokens_per_second: i32,

    /// Output only. The Normalized Time Per Output Token (NTPOT) in milliseconds.
    /// This is the request latency normalized by the number of output tokens,
    /// measured as request_latency / total_output_tokens.
    pub ntpot_milliseconds: i32,

    /// Output only. The Time To First Token (TTFT) in milliseconds. This is the
    /// time it takes to generate the first token for a request.
    pub ttft_milliseconds: i32,

    /// Output only. The cost of running the model deployment.
    pub cost: std::vec::Vec<crate::model::Cost>,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl PerformanceStats {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [queries_per_second][crate::model::PerformanceStats::queries_per_second].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::PerformanceStats;
    /// let x = PerformanceStats::new().set_queries_per_second(42.0);
    /// ```
    pub fn set_queries_per_second<T: std::convert::Into<f32>>(mut self, v: T) -> Self {
        self.queries_per_second = v.into();
        self
    }

    /// Sets the value of [output_tokens_per_second][crate::model::PerformanceStats::output_tokens_per_second].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::PerformanceStats;
    /// let x = PerformanceStats::new().set_output_tokens_per_second(42);
    /// ```
    pub fn set_output_tokens_per_second<T: std::convert::Into<i32>>(mut self, v: T) -> Self {
        self.output_tokens_per_second = v.into();
        self
    }

    /// Sets the value of [ntpot_milliseconds][crate::model::PerformanceStats::ntpot_milliseconds].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::PerformanceStats;
    /// let x = PerformanceStats::new().set_ntpot_milliseconds(42);
    /// ```
    pub fn set_ntpot_milliseconds<T: std::convert::Into<i32>>(mut self, v: T) -> Self {
        self.ntpot_milliseconds = v.into();
        self
    }

    /// Sets the value of [ttft_milliseconds][crate::model::PerformanceStats::ttft_milliseconds].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::PerformanceStats;
    /// let x = PerformanceStats::new().set_ttft_milliseconds(42);
    /// ```
    pub fn set_ttft_milliseconds<T: std::convert::Into<i32>>(mut self, v: T) -> Self {
        self.ttft_milliseconds = v.into();
        self
    }

    /// Sets the value of [cost][crate::model::PerformanceStats::cost].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::PerformanceStats;
    /// use google_cloud_gkerecommender_v1::model::Cost;
    /// let x = PerformanceStats::new()
    ///     .set_cost([
    ///         Cost::default()/* use setters */,
    ///         Cost::default()/* use (different) setters */,
    ///     ]);
    /// ```
    pub fn set_cost<T, V>(mut self, v: T) -> Self
    where
        T: std::iter::IntoIterator<Item = V>,
        V: std::convert::Into<crate::model::Cost>,
    {
        use std::iter::Iterator;
        self.cost = v.into_iter().map(|i| i.into()).collect();
        self
    }
}

impl wkt::message::Message for PerformanceStats {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.gkerecommender.v1.PerformanceStats"
    }
}

/// A profile containing information about a model deployment.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct Profile {
    /// Output only. The model server configuration. Use
    /// [GkeInferenceQuickstart.FetchProfiles][google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchProfiles]
    /// to find valid configurations.
    ///
    /// [google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchProfiles]: crate::client::GkeInferenceQuickstart::fetch_profiles
    pub model_server_info: std::option::Option<crate::model::ModelServerInfo>,

    /// Output only. The accelerator type. Expected format: `nvidia-h100-80gb`.
    pub accelerator_type: std::string::String,

    /// Output only. The TPU topology (if applicable).
    pub tpu_topology: std::string::String,

    /// Output only. The instance type. Expected format: `a2-highgpu-1g`.
    pub instance_type: std::string::String,

    /// Output only. The resources used by the model deployment.
    pub resources_used: std::option::Option<crate::model::ResourcesUsed>,

    /// Output only. The performance statistics for this profile.
    pub performance_stats: std::vec::Vec<crate::model::PerformanceStats>,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl Profile {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [model_server_info][crate::model::Profile::model_server_info].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::Profile;
    /// use google_cloud_gkerecommender_v1::model::ModelServerInfo;
    /// let x = Profile::new().set_model_server_info(ModelServerInfo::default()/* use setters */);
    /// ```
    pub fn set_model_server_info<T>(mut self, v: T) -> Self
    where
        T: std::convert::Into<crate::model::ModelServerInfo>,
    {
        self.model_server_info = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [model_server_info][crate::model::Profile::model_server_info].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::Profile;
    /// use google_cloud_gkerecommender_v1::model::ModelServerInfo;
    /// let x = Profile::new().set_or_clear_model_server_info(Some(ModelServerInfo::default()/* use setters */));
    /// let x = Profile::new().set_or_clear_model_server_info(None::<ModelServerInfo>);
    /// ```
    pub fn set_or_clear_model_server_info<T>(mut self, v: std::option::Option<T>) -> Self
    where
        T: std::convert::Into<crate::model::ModelServerInfo>,
    {
        self.model_server_info = v.map(|x| x.into());
        self
    }

    /// Sets the value of [accelerator_type][crate::model::Profile::accelerator_type].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::Profile;
    /// let x = Profile::new().set_accelerator_type("example");
    /// ```
    pub fn set_accelerator_type<T: std::convert::Into<std::string::String>>(
        mut self,
        v: T,
    ) -> Self {
        self.accelerator_type = v.into();
        self
    }

    /// Sets the value of [tpu_topology][crate::model::Profile::tpu_topology].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::Profile;
    /// let x = Profile::new().set_tpu_topology("example");
    /// ```
    pub fn set_tpu_topology<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.tpu_topology = v.into();
        self
    }

    /// Sets the value of [instance_type][crate::model::Profile::instance_type].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::Profile;
    /// let x = Profile::new().set_instance_type("example");
    /// ```
    pub fn set_instance_type<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.instance_type = v.into();
        self
    }

    /// Sets the value of [resources_used][crate::model::Profile::resources_used].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::Profile;
    /// use google_cloud_gkerecommender_v1::model::ResourcesUsed;
    /// let x = Profile::new().set_resources_used(ResourcesUsed::default()/* use setters */);
    /// ```
    pub fn set_resources_used<T>(mut self, v: T) -> Self
    where
        T: std::convert::Into<crate::model::ResourcesUsed>,
    {
        self.resources_used = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [resources_used][crate::model::Profile::resources_used].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::Profile;
    /// use google_cloud_gkerecommender_v1::model::ResourcesUsed;
    /// let x = Profile::new().set_or_clear_resources_used(Some(ResourcesUsed::default()/* use setters */));
    /// let x = Profile::new().set_or_clear_resources_used(None::<ResourcesUsed>);
    /// ```
    pub fn set_or_clear_resources_used<T>(mut self, v: std::option::Option<T>) -> Self
    where
        T: std::convert::Into<crate::model::ResourcesUsed>,
    {
        self.resources_used = v.map(|x| x.into());
        self
    }

    /// Sets the value of [performance_stats][crate::model::Profile::performance_stats].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::Profile;
    /// use google_cloud_gkerecommender_v1::model::PerformanceStats;
    /// let x = Profile::new()
    ///     .set_performance_stats([
    ///         PerformanceStats::default()/* use setters */,
    ///         PerformanceStats::default()/* use (different) setters */,
    ///     ]);
    /// ```
    pub fn set_performance_stats<T, V>(mut self, v: T) -> Self
    where
        T: std::iter::IntoIterator<Item = V>,
        V: std::convert::Into<crate::model::PerformanceStats>,
    {
        use std::iter::Iterator;
        self.performance_stats = v.into_iter().map(|i| i.into()).collect();
        self
    }
}

impl wkt::message::Message for Profile {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.gkerecommender.v1.Profile"
    }
}

/// Request message for
/// [GkeInferenceQuickstart.GenerateOptimizedManifest][google.cloud.gkerecommender.v1.GkeInferenceQuickstart.GenerateOptimizedManifest].
///
/// [google.cloud.gkerecommender.v1.GkeInferenceQuickstart.GenerateOptimizedManifest]: crate::client::GkeInferenceQuickstart::generate_optimized_manifest
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct GenerateOptimizedManifestRequest {
    /// Required. The model server configuration to generate the manifest for. Use
    /// [GkeInferenceQuickstart.FetchProfiles][google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchProfiles]
    /// to find valid configurations.
    ///
    /// [google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchProfiles]: crate::client::GkeInferenceQuickstart::fetch_profiles
    pub model_server_info: std::option::Option<crate::model::ModelServerInfo>,

    /// Required. The accelerator type. Use
    /// [GkeInferenceQuickstart.FetchProfiles][google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchProfiles]
    /// to find valid accelerators for a given `model_server_info`.
    ///
    /// [google.cloud.gkerecommender.v1.GkeInferenceQuickstart.FetchProfiles]: crate::client::GkeInferenceQuickstart::fetch_profiles
    pub accelerator_type: std::string::String,

    /// Optional. The kubernetes namespace to deploy the manifests in.
    pub kubernetes_namespace: std::string::String,

    /// Optional. The performance requirements to use for generating Horizontal Pod
    /// Autoscaler (HPA) resources. If provided, the manifest includes HPA
    /// resources to adjust the model server replica count to maintain the
    /// specified targets (e.g., NTPOT, TTFT) at a P50 latency. Cost targets are
    /// not currently supported for HPA generation. If the specified targets are
    /// not achievable, the HPA manifest will not be generated.
    pub performance_requirements: std::option::Option<crate::model::PerformanceRequirements>,

    /// Optional. The storage configuration for the model. If not provided, the
    /// model is loaded from Huggingface.
    pub storage_config: std::option::Option<crate::model::StorageConfig>,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl GenerateOptimizedManifestRequest {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [model_server_info][crate::model::GenerateOptimizedManifestRequest::model_server_info].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::GenerateOptimizedManifestRequest;
    /// use google_cloud_gkerecommender_v1::model::ModelServerInfo;
    /// let x = GenerateOptimizedManifestRequest::new().set_model_server_info(ModelServerInfo::default()/* use setters */);
    /// ```
    pub fn set_model_server_info<T>(mut self, v: T) -> Self
    where
        T: std::convert::Into<crate::model::ModelServerInfo>,
    {
        self.model_server_info = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [model_server_info][crate::model::GenerateOptimizedManifestRequest::model_server_info].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::GenerateOptimizedManifestRequest;
    /// use google_cloud_gkerecommender_v1::model::ModelServerInfo;
    /// let x = GenerateOptimizedManifestRequest::new().set_or_clear_model_server_info(Some(ModelServerInfo::default()/* use setters */));
    /// let x = GenerateOptimizedManifestRequest::new().set_or_clear_model_server_info(None::<ModelServerInfo>);
    /// ```
    pub fn set_or_clear_model_server_info<T>(mut self, v: std::option::Option<T>) -> Self
    where
        T: std::convert::Into<crate::model::ModelServerInfo>,
    {
        self.model_server_info = v.map(|x| x.into());
        self
    }

    /// Sets the value of [accelerator_type][crate::model::GenerateOptimizedManifestRequest::accelerator_type].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::GenerateOptimizedManifestRequest;
    /// let x = GenerateOptimizedManifestRequest::new().set_accelerator_type("example");
    /// ```
    pub fn set_accelerator_type<T: std::convert::Into<std::string::String>>(
        mut self,
        v: T,
    ) -> Self {
        self.accelerator_type = v.into();
        self
    }

    /// Sets the value of [kubernetes_namespace][crate::model::GenerateOptimizedManifestRequest::kubernetes_namespace].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::GenerateOptimizedManifestRequest;
    /// let x = GenerateOptimizedManifestRequest::new().set_kubernetes_namespace("example");
    /// ```
    pub fn set_kubernetes_namespace<T: std::convert::Into<std::string::String>>(
        mut self,
        v: T,
    ) -> Self {
        self.kubernetes_namespace = v.into();
        self
    }

    /// Sets the value of [performance_requirements][crate::model::GenerateOptimizedManifestRequest::performance_requirements].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::GenerateOptimizedManifestRequest;
    /// use google_cloud_gkerecommender_v1::model::PerformanceRequirements;
    /// let x = GenerateOptimizedManifestRequest::new().set_performance_requirements(PerformanceRequirements::default()/* use setters */);
    /// ```
    pub fn set_performance_requirements<T>(mut self, v: T) -> Self
    where
        T: std::convert::Into<crate::model::PerformanceRequirements>,
    {
        self.performance_requirements = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [performance_requirements][crate::model::GenerateOptimizedManifestRequest::performance_requirements].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::GenerateOptimizedManifestRequest;
    /// use google_cloud_gkerecommender_v1::model::PerformanceRequirements;
    /// let x = GenerateOptimizedManifestRequest::new().set_or_clear_performance_requirements(Some(PerformanceRequirements::default()/* use setters */));
    /// let x = GenerateOptimizedManifestRequest::new().set_or_clear_performance_requirements(None::<PerformanceRequirements>);
    /// ```
    pub fn set_or_clear_performance_requirements<T>(mut self, v: std::option::Option<T>) -> Self
    where
        T: std::convert::Into<crate::model::PerformanceRequirements>,
    {
        self.performance_requirements = v.map(|x| x.into());
        self
    }

    /// Sets the value of [storage_config][crate::model::GenerateOptimizedManifestRequest::storage_config].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::GenerateOptimizedManifestRequest;
    /// use google_cloud_gkerecommender_v1::model::StorageConfig;
    /// let x = GenerateOptimizedManifestRequest::new().set_storage_config(StorageConfig::default()/* use setters */);
    /// ```
    pub fn set_storage_config<T>(mut self, v: T) -> Self
    where
        T: std::convert::Into<crate::model::StorageConfig>,
    {
        self.storage_config = std::option::Option::Some(v.into());
        self
    }

    /// Sets or clears the value of [storage_config][crate::model::GenerateOptimizedManifestRequest::storage_config].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::GenerateOptimizedManifestRequest;
    /// use google_cloud_gkerecommender_v1::model::StorageConfig;
    /// let x = GenerateOptimizedManifestRequest::new().set_or_clear_storage_config(Some(StorageConfig::default()/* use setters */));
    /// let x = GenerateOptimizedManifestRequest::new().set_or_clear_storage_config(None::<StorageConfig>);
    /// ```
    pub fn set_or_clear_storage_config<T>(mut self, v: std::option::Option<T>) -> Self
    where
        T: std::convert::Into<crate::model::StorageConfig>,
    {
        self.storage_config = v.map(|x| x.into());
        self
    }
}

impl wkt::message::Message for GenerateOptimizedManifestRequest {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.gkerecommender.v1.GenerateOptimizedManifestRequest"
    }
}

/// A Kubernetes manifest.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct KubernetesManifest {
    /// Output only. Kubernetes resource kind.
    pub kind: std::string::String,

    /// Output only. Kubernetes API version.
    pub api_version: std::string::String,

    /// Output only. YAML content.
    pub content: std::string::String,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl KubernetesManifest {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [kind][crate::model::KubernetesManifest::kind].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::KubernetesManifest;
    /// let x = KubernetesManifest::new().set_kind("example");
    /// ```
    pub fn set_kind<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.kind = v.into();
        self
    }

    /// Sets the value of [api_version][crate::model::KubernetesManifest::api_version].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::KubernetesManifest;
    /// let x = KubernetesManifest::new().set_api_version("example");
    /// ```
    pub fn set_api_version<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.api_version = v.into();
        self
    }

    /// Sets the value of [content][crate::model::KubernetesManifest::content].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::KubernetesManifest;
    /// let x = KubernetesManifest::new().set_content("example");
    /// ```
    pub fn set_content<T: std::convert::Into<std::string::String>>(mut self, v: T) -> Self {
        self.content = v.into();
        self
    }
}

impl wkt::message::Message for KubernetesManifest {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.gkerecommender.v1.KubernetesManifest"
    }
}

/// Response message for
/// [GkeInferenceQuickstart.GenerateOptimizedManifest][google.cloud.gkerecommender.v1.GkeInferenceQuickstart.GenerateOptimizedManifest].
///
/// [google.cloud.gkerecommender.v1.GkeInferenceQuickstart.GenerateOptimizedManifest]: crate::client::GkeInferenceQuickstart::generate_optimized_manifest
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct GenerateOptimizedManifestResponse {
    /// Output only. A list of generated Kubernetes manifests.
    pub kubernetes_manifests: std::vec::Vec<crate::model::KubernetesManifest>,

    /// Output only. Comments related to deploying the generated manifests.
    pub comments: std::vec::Vec<std::string::String>,

    /// Output only. Additional information about the versioned dependencies used
    /// to generate the manifests. See [Run best practice inference with GKE
    /// Inference Quickstart
    /// recipes](https://cloud.google.com/kubernetes-engine/docs/how-to/machine-learning/inference/inference-quickstart)
    /// for details.
    pub manifest_version: std::string::String,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl GenerateOptimizedManifestResponse {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [kubernetes_manifests][crate::model::GenerateOptimizedManifestResponse::kubernetes_manifests].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::GenerateOptimizedManifestResponse;
    /// use google_cloud_gkerecommender_v1::model::KubernetesManifest;
    /// let x = GenerateOptimizedManifestResponse::new()
    ///     .set_kubernetes_manifests([
    ///         KubernetesManifest::default()/* use setters */,
    ///         KubernetesManifest::default()/* use (different) setters */,
    ///     ]);
    /// ```
    pub fn set_kubernetes_manifests<T, V>(mut self, v: T) -> Self
    where
        T: std::iter::IntoIterator<Item = V>,
        V: std::convert::Into<crate::model::KubernetesManifest>,
    {
        use std::iter::Iterator;
        self.kubernetes_manifests = v.into_iter().map(|i| i.into()).collect();
        self
    }

    /// Sets the value of [comments][crate::model::GenerateOptimizedManifestResponse::comments].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::GenerateOptimizedManifestResponse;
    /// let x = GenerateOptimizedManifestResponse::new().set_comments(["a", "b", "c"]);
    /// ```
    pub fn set_comments<T, V>(mut self, v: T) -> Self
    where
        T: std::iter::IntoIterator<Item = V>,
        V: std::convert::Into<std::string::String>,
    {
        use std::iter::Iterator;
        self.comments = v.into_iter().map(|i| i.into()).collect();
        self
    }

    /// Sets the value of [manifest_version][crate::model::GenerateOptimizedManifestResponse::manifest_version].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::GenerateOptimizedManifestResponse;
    /// let x = GenerateOptimizedManifestResponse::new().set_manifest_version("example");
    /// ```
    pub fn set_manifest_version<T: std::convert::Into<std::string::String>>(
        mut self,
        v: T,
    ) -> Self {
        self.manifest_version = v.into();
        self
    }
}

impl wkt::message::Message for GenerateOptimizedManifestResponse {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.gkerecommender.v1.GenerateOptimizedManifestResponse"
    }
}

/// Storage configuration for a model deployment.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct StorageConfig {
    /// Optional. The Google Cloud Storage bucket URI to load the model from. This
    /// URI must point to the directory containing the model's config file
    /// (`config.json`) and model weights. A tuned GCSFuse setup can improve
    /// LLM Pod startup time by more than 7x. Expected format:
    /// `gs://<bucket-name>/<path-to-model>`.
    pub model_bucket_uri: std::string::String,

    /// Optional. The URI for the GCS bucket containing the XLA compilation cache.
    /// If using TPUs, the XLA cache will be written to the same path as
    /// `model_bucket_uri`. This can speed up vLLM model preparation for repeated
    /// deployments.
    pub xla_cache_bucket_uri: std::string::String,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl StorageConfig {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [model_bucket_uri][crate::model::StorageConfig::model_bucket_uri].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::StorageConfig;
    /// let x = StorageConfig::new().set_model_bucket_uri("example");
    /// ```
    pub fn set_model_bucket_uri<T: std::convert::Into<std::string::String>>(
        mut self,
        v: T,
    ) -> Self {
        self.model_bucket_uri = v.into();
        self
    }

    /// Sets the value of [xla_cache_bucket_uri][crate::model::StorageConfig::xla_cache_bucket_uri].
    ///
    /// # Example
    /// ```
    /// # use google_cloud_gkerecommender_v1::model::StorageConfig;
    /// let x = StorageConfig::new().set_xla_cache_bucket_uri("example");
    /// ```
    pub fn set_xla_cache_bucket_uri<T: std::convert::Into<std::string::String>>(
        mut self,
        v: T,
    ) -> Self {
        self.xla_cache_bucket_uri = v.into();
        self
    }
}

impl wkt::message::Message for StorageConfig {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.gkerecommender.v1.StorageConfig"
    }
}
