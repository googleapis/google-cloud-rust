// Copyright 2025 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     https://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//
// Code generated by sidekick. DO NOT EDIT.

#![allow(rustdoc::redundant_explicit_links)]
#![allow(rustdoc::broken_intra_doc_links)]
#![no_implicit_prelude]
extern crate std;
extern crate bytes;
extern crate serde;
extern crate serde_json;
extern crate serde_with;
extern crate wkt;

mod debug;
mod deserialize;
mod serialize;

/// Prediction model parameters for Image Classification.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct ImageClassificationPredictionParams {

    /// The Model only returns predictions with at least this confidence score.
    /// Default value is 0.0
    pub confidence_threshold: f32,

    /// The Model only returns up to that many top, by confidence score,
    /// predictions per instance. If this number is very high, the Model may return
    /// fewer predictions. Default value is 10.
    pub max_predictions: i32,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl ImageClassificationPredictionParams {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [confidence_threshold][crate::model::ImageClassificationPredictionParams::confidence_threshold].
    pub fn set_confidence_threshold<T: std::convert::Into<f32>>(mut self, v: T) -> Self {
        self.confidence_threshold = v.into();
        self
    }

    /// Sets the value of [max_predictions][crate::model::ImageClassificationPredictionParams::max_predictions].
    pub fn set_max_predictions<T: std::convert::Into<i32>>(mut self, v: T) -> Self {
        self.max_predictions = v.into();
        self
    }
}

impl wkt::message::Message for ImageClassificationPredictionParams {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.aiplatform.v1.schema.predict.params.ImageClassificationPredictionParams"
    }
}

/// Prediction model parameters for Image Object Detection.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct ImageObjectDetectionPredictionParams {

    /// The Model only returns predictions with at least this confidence score.
    /// Default value is 0.0
    pub confidence_threshold: f32,

    /// The Model only returns up to that many top, by confidence score,
    /// predictions per instance. Note that number of returned predictions is also
    /// limited by metadata's predictionsLimit. Default value is 10.
    pub max_predictions: i32,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl ImageObjectDetectionPredictionParams {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [confidence_threshold][crate::model::ImageObjectDetectionPredictionParams::confidence_threshold].
    pub fn set_confidence_threshold<T: std::convert::Into<f32>>(mut self, v: T) -> Self {
        self.confidence_threshold = v.into();
        self
    }

    /// Sets the value of [max_predictions][crate::model::ImageObjectDetectionPredictionParams::max_predictions].
    pub fn set_max_predictions<T: std::convert::Into<i32>>(mut self, v: T) -> Self {
        self.max_predictions = v.into();
        self
    }
}

impl wkt::message::Message for ImageObjectDetectionPredictionParams {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.aiplatform.v1.schema.predict.params.ImageObjectDetectionPredictionParams"
    }
}

/// Prediction model parameters for Image Segmentation.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct ImageSegmentationPredictionParams {

    /// When the model predicts category of pixels of the image, it will only
    /// provide predictions for pixels that it is at least this much confident
    /// about. All other pixels will be classified as background. Default value is
    /// 0.5.
    pub confidence_threshold: f32,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl ImageSegmentationPredictionParams {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [confidence_threshold][crate::model::ImageSegmentationPredictionParams::confidence_threshold].
    pub fn set_confidence_threshold<T: std::convert::Into<f32>>(mut self, v: T) -> Self {
        self.confidence_threshold = v.into();
        self
    }
}

impl wkt::message::Message for ImageSegmentationPredictionParams {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.aiplatform.v1.schema.predict.params.ImageSegmentationPredictionParams"
    }
}

/// Prediction model parameters for Video Action Recognition.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct VideoActionRecognitionPredictionParams {

    /// The Model only returns predictions with at least this confidence score.
    /// Default value is 0.0
    pub confidence_threshold: f32,

    /// The model only returns up to that many top, by confidence score,
    /// predictions per frame of the video. If this number is very high, the
    /// Model may return fewer predictions per frame. Default value is 50.
    pub max_predictions: i32,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl VideoActionRecognitionPredictionParams {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [confidence_threshold][crate::model::VideoActionRecognitionPredictionParams::confidence_threshold].
    pub fn set_confidence_threshold<T: std::convert::Into<f32>>(mut self, v: T) -> Self {
        self.confidence_threshold = v.into();
        self
    }

    /// Sets the value of [max_predictions][crate::model::VideoActionRecognitionPredictionParams::max_predictions].
    pub fn set_max_predictions<T: std::convert::Into<i32>>(mut self, v: T) -> Self {
        self.max_predictions = v.into();
        self
    }
}

impl wkt::message::Message for VideoActionRecognitionPredictionParams {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.aiplatform.v1.schema.predict.params.VideoActionRecognitionPredictionParams"
    }
}

/// Prediction model parameters for Video Classification.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct VideoClassificationPredictionParams {

    /// The Model only returns predictions with at least this confidence score.
    /// Default value is 0.0
    pub confidence_threshold: f32,

    /// The Model only returns up to that many top, by confidence score,
    /// predictions per instance. If this number is very high, the Model may return
    /// fewer predictions. Default value is 10,000.
    pub max_predictions: i32,

    /// Set to true to request segment-level classification. Vertex AI returns
    /// labels and their confidence scores for the entire time segment of the
    /// video that user specified in the input instance.
    /// Default value is true
    pub segment_classification: bool,

    /// Set to true to request shot-level classification. Vertex AI determines
    /// the boundaries for each camera shot in the entire time segment of the
    /// video that user specified in the input instance. Vertex AI then
    /// returns labels and their confidence scores for each detected shot, along
    /// with the start and end time of the shot.
    /// WARNING: Model evaluation is not done for this classification type,
    /// the quality of it depends on the training data, but there are no metrics
    /// provided to describe that quality.
    /// Default value is false
    pub shot_classification: bool,

    /// Set to true to request classification for a video at one-second intervals.
    /// Vertex AI returns labels and their confidence scores for each second of
    /// the entire time segment of the video that user specified in the input
    /// WARNING: Model evaluation is not done for this classification type, the
    /// quality of it depends on the training data, but there are no metrics
    /// provided to describe that quality. Default value is false
    pub one_sec_interval_classification: bool,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl VideoClassificationPredictionParams {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [confidence_threshold][crate::model::VideoClassificationPredictionParams::confidence_threshold].
    pub fn set_confidence_threshold<T: std::convert::Into<f32>>(mut self, v: T) -> Self {
        self.confidence_threshold = v.into();
        self
    }

    /// Sets the value of [max_predictions][crate::model::VideoClassificationPredictionParams::max_predictions].
    pub fn set_max_predictions<T: std::convert::Into<i32>>(mut self, v: T) -> Self {
        self.max_predictions = v.into();
        self
    }

    /// Sets the value of [segment_classification][crate::model::VideoClassificationPredictionParams::segment_classification].
    pub fn set_segment_classification<T: std::convert::Into<bool>>(mut self, v: T) -> Self {
        self.segment_classification = v.into();
        self
    }

    /// Sets the value of [shot_classification][crate::model::VideoClassificationPredictionParams::shot_classification].
    pub fn set_shot_classification<T: std::convert::Into<bool>>(mut self, v: T) -> Self {
        self.shot_classification = v.into();
        self
    }

    /// Sets the value of [one_sec_interval_classification][crate::model::VideoClassificationPredictionParams::one_sec_interval_classification].
    pub fn set_one_sec_interval_classification<T: std::convert::Into<bool>>(mut self, v: T) -> Self {
        self.one_sec_interval_classification = v.into();
        self
    }
}

impl wkt::message::Message for VideoClassificationPredictionParams {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.aiplatform.v1.schema.predict.params.VideoClassificationPredictionParams"
    }
}

/// Prediction model parameters for Video Object Tracking.
#[derive(Clone, Default, PartialEq)]
#[non_exhaustive]
pub struct VideoObjectTrackingPredictionParams {

    /// The Model only returns predictions with at least this confidence score.
    /// Default value is 0.0
    pub confidence_threshold: f32,

    /// The model only returns up to that many top, by confidence score,
    /// predictions per frame of the video. If this number is very high, the
    /// Model may return fewer predictions per frame. Default value is 50.
    pub max_predictions: i32,

    /// Only bounding boxes with shortest edge at least that long as a relative
    /// value of video frame size are returned. Default value is 0.0.
    pub min_bounding_box_size: f32,

    pub(crate) _unknown_fields: serde_json::Map<std::string::String, serde_json::Value>,
}

impl VideoObjectTrackingPredictionParams {
    pub fn new() -> Self {
        std::default::Default::default()
    }

    /// Sets the value of [confidence_threshold][crate::model::VideoObjectTrackingPredictionParams::confidence_threshold].
    pub fn set_confidence_threshold<T: std::convert::Into<f32>>(mut self, v: T) -> Self {
        self.confidence_threshold = v.into();
        self
    }

    /// Sets the value of [max_predictions][crate::model::VideoObjectTrackingPredictionParams::max_predictions].
    pub fn set_max_predictions<T: std::convert::Into<i32>>(mut self, v: T) -> Self {
        self.max_predictions = v.into();
        self
    }

    /// Sets the value of [min_bounding_box_size][crate::model::VideoObjectTrackingPredictionParams::min_bounding_box_size].
    pub fn set_min_bounding_box_size<T: std::convert::Into<f32>>(mut self, v: T) -> Self {
        self.min_bounding_box_size = v.into();
        self
    }
}

impl wkt::message::Message for VideoObjectTrackingPredictionParams {
    fn typename() -> &'static str {
        "type.googleapis.com/google.cloud.aiplatform.v1.schema.predict.params.VideoObjectTrackingPredictionParams"
    }
}
